{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2AFg4fRwgrzX"
   },
   "source": [
    "# LLama2-Like LM\n",
    "We implement a LLama2-like language model, using a few modifications to the decoder part of the transformer architecture:\n",
    "- Rotary position embeddings (RoPE): available in Keras library.\n",
    "- Grouped Query Attention: available in the Keras library, but without RoPE support. We'll add that.\n",
    "- SwiGLU activation and gating feed-forward network: not available, we'll build a custom layer.\n",
    "- RMS rather than full layer normalization.  \n",
    "\n",
    "We then pre-train it on the simplebooks corpus (English only, about 100M tokens) and tune it to respond to instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyzrCquiyl-W"
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yhd5YvqRFdhc",
    "outputId": "efebc8e4-a3c7-4a28-c138-367e252380b4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in ./.local/lib/python3.10/site-packages (3.10.0)\n",
      "Requirement already satisfied: keras-hub in ./.local/lib/python3.10/site-packages (0.20.0)\n",
      "Requirement already satisfied: tensorflow-cpu in ./.local/lib/python3.10/site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py in ./.local/lib/python3.10/site-packages (from keras) (2.2.2)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from keras) (2.1.3)\n",
      "Requirement already satisfied: rich in ./.local/lib/python3.10/site-packages (from keras) (14.0.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
      "Requirement already satisfied: optree in ./.local/lib/python3.10/site-packages (from keras) (0.15.0)\n",
      "Requirement already satisfied: h5py in ./.local/lib/python3.10/site-packages (from keras) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes in ./.local/lib/python3.10/site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: namex in ./.local/lib/python3.10/site-packages (from keras) (0.0.9)\n",
      "Requirement already satisfied: tensorflow-text in ./.local/lib/python3.10/site-packages (from keras-hub) (2.19.0)\n",
      "Requirement already satisfied: regex in ./.local/lib/python3.10/site-packages (from keras-hub) (2024.11.6)\n",
      "Requirement already satisfied: kagglehub in ./.local/lib/python3.10/site-packages (from keras-hub) (0.3.12)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.local/lib/python3.10/site-packages (from tensorflow-cpu) (1.71.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./.local/lib/python3.10/site-packages (from tensorflow-cpu) (1.17.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.local/lib/python3.10/site-packages (from tensorflow-cpu) (4.13.2)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in ./.local/lib/python3.10/site-packages (from tensorflow-cpu) (2.19.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.local/lib/python3.10/site-packages (from tensorflow-cpu) (0.6.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.local/lib/python3.10/site-packages (from tensorflow-cpu) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.local/lib/python3.10/site-packages (from tensorflow-cpu) (3.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow-cpu) (71.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.local/lib/python3.10/site-packages (from tensorflow-cpu) (0.37.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./.local/lib/python3.10/site-packages (from tensorflow-cpu) (4.25.7)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow-cpu) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./.local/lib/python3.10/site-packages (from tensorflow-cpu) (25.2.10)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.local/lib/python3.10/site-packages (from tensorflow-cpu) (3.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.local/lib/python3.10/site-packages (from tensorflow-cpu) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.local/lib/python3.10/site-packages (from tensorflow-cpu) (18.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.37.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2020.6.20)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow-cpu) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.local/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow-cpu) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.local/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow-cpu) (3.1.3)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.10/site-packages (from kagglehub->keras-hub) (4.67.1)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from kagglehub->keras-hub) (5.4.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.local/lib/python3.10/site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.local/lib/python3.10/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19.0 in ./.local/lib/python3.10/site-packages (from tensorflow-text->keras-hub) (2.19.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow-cpu) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U keras keras-hub tensorflow-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MFjGRv__Fwlw",
    "outputId": "c75ffd62-af42-4cec-ce8e-00e03c065caa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorboard-plugin-profile in ./.local/lib/python3.10/site-packages (2.19.6)\n",
      "Requirement already satisfied: fsspec[gcs]>=2024.10.0 in ./.local/lib/python3.10/site-packages (from tensorboard-plugin-profile) (2025.3.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in ./.local/lib/python3.10/site-packages (from tensorboard-plugin-profile) (3.1.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard-plugin-profile) (71.0.0)\n",
      "Requirement already satisfied: gviz_api>=1.9.0 in ./.local/lib/python3.10/site-packages (from tensorboard-plugin-profile) (1.10.0)\n",
      "Requirement already satisfied: cheroot>=10.0.1 in ./.local/lib/python3.10/site-packages (from tensorboard-plugin-profile) (10.0.1)\n",
      "Requirement already satisfied: etils[epath]>=1.0.0 in ./.local/lib/python3.10/site-packages (from tensorboard-plugin-profile) (1.12.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from tensorboard-plugin-profile) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in ./.local/lib/python3.10/site-packages (from tensorboard-plugin-profile) (4.25.7)\n",
      "Requirement already satisfied: more-itertools>=2.6 in /usr/lib/python3/dist-packages (from cheroot>=10.0.1->tensorboard-plugin-profile) (8.10.0)\n",
      "Requirement already satisfied: jaraco.functools in ./.local/lib/python3.10/site-packages (from cheroot>=10.0.1->tensorboard-plugin-profile) (4.1.0)\n",
      "Requirement already satisfied: typing_extensions in ./.local/lib/python3.10/site-packages (from etils[epath]>=1.0.0->tensorboard-plugin-profile) (4.13.2)\n",
      "Requirement already satisfied: importlib_resources in ./.local/lib/python3.10/site-packages (from etils[epath]>=1.0.0->tensorboard-plugin-profile) (6.5.2)\n",
      "Requirement already satisfied: zipp in /usr/lib/python3/dist-packages (from etils[epath]>=1.0.0->tensorboard-plugin-profile) (1.0.0)\n",
      "Requirement already satisfied: gcsfs in ./.local/lib/python3.10/site-packages (from fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (2025.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.local/lib/python3.10/site-packages (from werkzeug>=0.11.15->tensorboard-plugin-profile) (3.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (2.32.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.local/lib/python3.10/site-packages (from gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (3.11.18)\n",
      "Requirement already satisfied: google-auth>=1.2 in ./.local/lib/python3.10/site-packages (from gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (2.40.2)\n",
      "Requirement already satisfied: google-cloud-storage in ./.local/lib/python3.10/site-packages (from gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (3.1.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in ./.local/lib/python3.10/site-packages (from gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (1.2.2)\n",
      "Requirement already satisfied: decorator>4.1.2 in ./.local/lib/python3.10/site-packages (from gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (5.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (1.20.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (2.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (0.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (6.4.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth>=1.2->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (0.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.local/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (5.5.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.local/lib/python3.10/site-packages (from google-auth>=1.2->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.10/site-packages (from google-auth-oauthlib->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (2.0.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in ./.local/lib/python3.10/site-packages (from google-cloud-storage->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (1.7.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in ./.local/lib/python3.10/site-packages (from google-cloud-storage->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (2.7.2)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in ./.local/lib/python3.10/site-packages (from google-cloud-storage->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (2.24.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.4.2 in ./.local/lib/python3.10/site-packages (from google-cloud-storage->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (2.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (3.3.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.local/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (1.70.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in ./.local/lib/python3.10/site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (1.26.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (3.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth>=1.2->gcsfs->fsspec[gcs]>=2024.10.0->tensorboard-plugin-profile) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorboard-plugin-profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyarrow in ./.local/lib/python3.10/site-packages (20.0.0)\n",
      "Requirement already satisfied: fastparquet in ./.local/lib/python3.10/site-packages (2024.11.0)\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.10/site-packages (3.6.0)\n",
      "Requirement already satisfied: cramjam>=2.3 in ./.local/lib/python3.10/site-packages (from fastparquet) (2.10.0)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.10/site-packages (from fastparquet) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.5.0 in ./.local/lib/python3.10/site-packages (from fastparquet) (2.2.3)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.10/site-packages (from fastparquet) (2025.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet) (24.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.local/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.32.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.local/lib/python3.10/site-packages (from fsspec->fastparquet) (3.11.18)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.10/site-packages (from pandas>=1.5.0->fastparquet) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.10/site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.5.0->fastparquet) (2022.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->fastparquet) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->fastparquet) (1.6.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->fastparquet) (5.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->fastparquet) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->fastparquet) (0.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->fastparquet) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->fastparquet) (1.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->fastparquet) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow fastparquet datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpsKeXUZyl-X"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0-MD3HqYFDY6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C94rvcCNhn1h"
   },
   "source": [
    "We use the Keras library with a JAX backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-DPTYEoaKC8z"
   },
   "outputs": [],
   "source": [
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "# default behavior is to allocate 75% of GPU memory. We need not do that.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Fl3OwgkARvtd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gimarchetti/.local/lib/python3.10/site-packages/jax/_src/cloud_tpu_init.py:82: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
      "  warnings.warn(\n",
      "2025-05-25 06:50:16.734968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748155816.749777  827394 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748155816.754199  827394 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748155816.768613  827394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748155816.768649  827394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748155816.768651  827394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748155816.768653  827394 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "/home/gimarchetti/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# if the GPU supports bfloat16 format and flash attention, uncomment the following 2 lines.\n",
    "# Note: The T4 GPU in Kaggle and Colab does not.\n",
    "keras.mixed_precision.set_global_policy(\"mixed_bfloat16\")\n",
    "keras.config.enable_flash_attention()\n",
    "import keras_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pwASMB1KFDY6"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import string\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K78P8CsYiPFO"
   },
   "source": [
    "Tensorflow data is still useful for building a data pre-processing pipeline, even if we do not use Tensorflow as the main computation framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NszCZ2usFDY6"
   },
   "outputs": [],
   "source": [
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "m0pAd2poFDY7"
   },
   "outputs": [],
   "source": [
    "from keras import layers, models, losses, callbacks, ops, Layer\n",
    "from keras.layers import Dense, Layer, Dropout,  RMSNormalization, LayerNormalization, Multiply\n",
    "from keras.ops import softmax, silu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Nxf85Cb-u6WA"
   },
   "outputs": [],
   "source": [
    "from keras_hub.layers import RotaryEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmzY-F0_yl-Y"
   },
   "source": [
    "## Set Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiYUOSXl9St5",
    "outputId": "a028312c-9fd1-46d2-9d9b-ddbc8e74519e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  8\n"
     ]
    }
   ],
   "source": [
    "gpus=keras.distribution.list_devices()\n",
    "num_gpus = len(gpus)\n",
    "\n",
    "print(\"Num GPUs Available: \", num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HPwHG22hpTQn"
   },
   "source": [
    "**Note:** The number of attention heads and blocks must be a multiple of the number of GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "o4Y5o4cLFDY7"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000 # 50000 is the size of the vocabulary for gpt2 on common corpus. Simplebooks is smaller\n",
    "MAX_LEN = 1024 # the maximum length of the input sequences,\n",
    "EMBEDDING_DIM = 768 # the dimension of the word embeddings\n",
    "N_HEADS = 8 #  the number of attention heads\n",
    "N_KV_HEADS= 8 # N_HEADS//2 # KV heads in GQA , 1 per GPU\n",
    "NUM_BLOCKS = 8 # Number of transformer blocks 12 in gpt2, 3 in gpt nano\n",
    "# The hidden dimension of the feed-forward network in the FF block = 4 * embedding with ReLU activation,\n",
    "# 8/3 * embedding with SwiGLU to keep n. of computations constant\n",
    "FEED_FORWARD_DIM = int(EMBEDDING_DIM * 8/3)\n",
    "VALIDATION_SPLIT = 0.2 # the fraction of data to be used for validation\n",
    "SEED = 42 # the random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "f3GE57lzFDY7"
   },
   "outputs": [],
   "source": [
    "MIN_STRING_LEN = 256  # Strings shorter than this will be discarded\n",
    "SEQ_LEN = 512 # 512  # Length of training sequences, in tokens, aka the CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PxrugpsDO-_J"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE_PER_GPU=64 #@param {\"type\":\"integer\"}\n",
    "BATCH_SIZE = BATCH_SIZE_PER_GPU * num_gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WwGuxxGOyl-Y"
   },
   "source": [
    "## Data ingestion and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yeUfizpPyl-Y"
   },
   "outputs": [],
   "source": [
    "BASE_DIR=\"./working\" #@param {\"type\":\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "9VEmxprXFDY7",
    "outputId": "5b010757-c67f-486d-87f8-06aac2d7e016"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gimarchetti/.keras/./working/keras/simplebooks.zip'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.get_file(\n",
    "    origin=\"https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip\",\n",
    "    extract=True,\n",
    "    cache_subdir=BASE_DIR+\"/keras/\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cYulth1jFDY7"
   },
   "outputs": [],
   "source": [
    "dir = BASE_DIR+\"/keras/simplebooks.zip/simplebooks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YxJ6yhmGFDY7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 06:50:51.078417: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Load simplebooks-92 train set and filter out short lines.\n",
    "raw_train_ds = (\n",
    "    tf_data.TextLineDataset(dir + \"simplebooks-92-raw/train.txt\")\n",
    "    .filter(lambda x: tf_strings.length(x) > MIN_STRING_LEN)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .shuffle(buffer_size=256)\n",
    ")\n",
    "\n",
    "# Load simplebooks-92 validation set and filter out short lines.\n",
    "raw_val_ds = (\n",
    "    tf_data.TextLineDataset(dir + \"simplebooks-92-raw/valid.txt\")\n",
    "    .filter(lambda x: tf_strings.length(x) > MIN_STRING_LEN)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vWV15agAyl-Z",
    "outputId": "a713e02f-434e-424c-b6be-340e513d837a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=TensorSpec(shape=(512,), dtype=tf.string, name=None)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e92HLEMlDTJ5",
    "outputId": "085df879-fa7c-4820-9640-c307de692035",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'\"I am glad of it,\" said a woolly Lamb on Wheels, who stood on the floor, just under the edge of the toy counter. She was rather too large to be up among the smaller toys. \"Yes, I am glad of it,\" went on the Lamb. \"I have kept still all day, and now I have something to tell you all, my friends.\"'\n",
      " b'For it was one of the rules of Toyland, as you know, that none of the folk who lived there could do anything while human eyes were watching them. The Dolls, Soldiers, Clowns, Rocking Horses, Lambs were not able to move, talk, or make believe come to life if a boy or a girl or any one at all looked at them.'\n",
      " b'\"Yes, you are always ready to jump out of your box as soon as the cover is taken off,\" remarked the Lamb on Wheels. \"But the rest of us are not such high kickers as you are. I cannot jump at all. I can only run around on my wheels, just as the White Rocking Horse, who used to live here, could only go on his rockers.\"'\n",
      " b'\"Do you mean the Sawdust Doll who used to live here with us?\" asked the Calico Clown. \"Excuse me for interrupting you,\" he said politely, \"but I just couldn\\'t help it. I was thinking of the Sawdust Doll myself. And I was wondering if you meant the same one that used to be here.\"'\n",
      " b'\"And did this little girl buy you -- or did her mother?\" asked the Calico Clown. \"I should hate to see you leave us,\" he went on. \"Of course we want you to get a nice home, but it will be lonesome if you, too, go away.\" \"That\\'s so,\" said the Bold Tin Soldier. \"We have lost our Sawdust Doll and our White Rocking Horse, and now, if the Lamb on Wheels goes away from us -- dear me!\"'\n",
      " b'\"I have no idea of going away!\" answered the Lamb. \"All I was going to say was that a beautiful little girl came to the toy department to-day with her mother, and she admired me very much -- the little girl did. She patted my back so softly, and she rubbed my head and she asked her mother to buy me.\"'\n",
      " b'\"Excuse me, but I should think it would make a great deal of difference,\" went on the Monkey. \"A big pig under a small gate would make more noise than a little pig under a big gate. If we only knew the size of the gate and what kind of pig it was, we might guess the riddle.\"'\n",
      " b'\"Hello! Hello there, my toy friends!\" cried the Elephant through his trunk. \"How are you all? And where is the White Rocking Horse? I\\'ll have a race with him. I tried to the other night, but one of my roller skates jiggled off and then the watchman came and the race could not be run. Where is the Rocking Horse?\"'\n",
      " b'\"Didn\\'t I hear what?\" asked the Elephant, sliding around on his roller skates. \"I hear a lot of things,\" he went on, \"but these skates make so much racket I can\\'t hear very well when I have them on. They don\\'t really belong to me,\" he said, looking at the Candy Rabbit. \"I just borrowed them from the sporting section, as I did before, to race with the White Rocking Horse.\"'\n",
      " b'The Bold Tin Soldier and his men soon cleared a place on the toy counter so that the Jack, the Monkey and the Rabbit would have plenty of room. The building blocks, the checkers and the dominoes were moved out of the way, and then the Calico Clown took his place, ready to count \"One! Two! Three!\" so the three toys would know when it was time to jump.'\n",
      " b'So the Jack jumped out of his box and took his place next to the Monkey, who also came down off his stick. I wish you could have seen how nimble they were, but, really, it is not allowed. The minute you looked at any of the toys they stopped moving at once.'\n",
      " b'Away jumped the Candy Rabbit! Away jumped the Monkey! Away leaped the Jack who lived in a Box. At the far end of the toy counter the Bold Tin Soldier and his men had placed some sofa cushions from the upholstery department. That was in case either of the three might stumble and fall.'\n",
      " b'And really the Rabbit was the best jumper of the three. In fact, he jumped so far that he sailed over the edge of the counter. And only that a sofa cushion fell, at the same time, to the floor, so that the Candy Rabbit landed on the soft, feathery thing, he might have hurt himself.'\n",
      " b'Soon the people began coming in to look at the toys. The Lamb on Wheels stood on the floor just under the counter. She was rather a large lamb, over a foot high -- that is, she was large for a toy lamb, though of course real ones are larger than that when they grow up.'\n",
      " b'She stood up straight and stiff, on her legs, did the Lamb. Her feet were fast to a wooden platform, and under that were wheels, so the Lamb could be rolled along from place to place. At night, when no one was looking at her, the Lamb could move along on the wheels by herself. But now she was very still and quiet, staring straight ahead as the dolls stared.'\n",
      " b'\"What kind of toy?\" asked the girl behind the counter. \"We have many kinds here,\" and she smiled at the sailor. He was so jolly no one could help smiling at him. \"We have Bold Tin Soldiers,\" went on the girl. \"We have Calico Clowns, Candy Rabbits, a Monkey on a Stick, and a Lamb on Wheels, and lots of things.\"'\n",
      " b'The jolly sailor held in his hands the Lamb on Wheels. He looked her over carefully, and rubbed her warm, woolly sides. Though his hand was not as soft as was that of the little girl who had stroked the Lamb the day before, yet the sailor was gentle in his touch.'\n",
      " b'\"Well, I suppose there is no use thinking any longer of having a home like the one the Sawdust Doll got, with her little girl mistress to love her,\" said the Lamb on Wheels to herself. \"I am to be taken away by this sailor -- away out to sea. I never could stand sailing, anyhow. Oh, dear! why do I have to go?\"'\n",
      " b'And while the clerk was gone the sailor walked about, looking at some bicycles and velocipedes at the far end of the toy department. Thus the Lamb and her friends were left by themselves for a moment or two, with no one to look at them. This was just the chance the Lamb wanted. She could talk now.'\n",
      " b'\"Nonsense! It isn\\'t anything of the sort!\" cried the Calico Clown, and he tried to wink at the Monkey from behind a pile of building blocks. \"The ocean is as safe as the shore. Why, look at the English and French dolls,\" he said, waving his cymbals in the direction of the imported toys in the next aisle. \"They came over the ocean in a ship, and they did not even have a headache. And look at the Japanese dolls -- they came much farther, over another ocean, too, and their hair was not even mussed.\"'\n",
      " b'Then the sailor came back from having looked at the velocipedes, and the girl clerk brought a large sheet of paper. In this the Lamb was wrapped. She had a last look at her friends of the toy shelves and counters, and then she felt herself being lifted up by the sailor.'\n",
      " b'Up the steps he went and rang the bell. There was a hole in the paper wrapped about the Lamb, and through this hole she could look out. She saw that she was on the piazza of a fine, large house. There was another house next door, and at the window stood a little girl with a doll in her arms.'\n",
      " b'\"The very same one!\" declared Mirabell. \"I was in the store once with Dorothy, the little girl who lives next door. She has a Sawdust Doll that came from the same store. And we were there the other day, before I was taken ill, and I saw a woolly lamb -- this very same one, I\\'m sure -- and I wanted it so much! But Mother said I must wait, and I\\'m glad I did, for now you gave it to me.\"'\n",
      " b'Mirabell stroked the soft wool of her new toy Lamb. She wheeled it across the floor again, and the sailor watched her. Then, all of a sudden, the door of the playroom was opened with such a bang that it struck the Lamb and sent her spinning across the floor, upside down, into a corner.'\n",
      " b'\"Oh, I didn\\'t mean to do that,\" said Arnold, who was sorry enough for the accident. \"I didn\\'t know you were in here,\" he went on. \"I came to get my toy fire engine. I\\'m going to play with Dick and his express wagon. Where\\'d you get your Lamb on Wheels, Mirabell?\"'\n",
      " b'Mirabell carefully looked at her plaything. And she was very glad to find out that no damage seemed to have been done. None of the four wheels was broken, the little wooden platform on which the Lamb stood was not splintered, and there was not so much as a bruise on the little black nose of the Lamb herself.'\n",
      " b'Arnold looked at what Uncle Tim gave him. It was a puzzle, made of some wooden rings on a stick, and the trick was to get the rings off the stick. Arnold tried and tried but could not do it until his uncle showed him how the trick was done. Then it was easy.'\n",
      " b\"And when the Lamb heard this, though just then she dared not move by herself or speak, she felt very happy. For, as I have told you, though she dared not move when human eyes were looking at her, there was nothing to stop her from hearing what was said. The Lamb had ears, and what good would they be if she could not hear through them, I'd like to know?\"\n",
      " b\"While Arnold hurried next door with his toy fire engine, that pumped real water, to play with Dick and to show his puzzle, Uncle Tim went downstairs to talk to Mirabell's mother. Then Mirabell got her best doll's comb and brush, which were just the right size, and not a bit too small or too large, and with this comb and brush she smoothed the kinks and snarls out of the Lamb's wool.\"\n",
      " b'\"Oh, I\\'m afraid something dreadful will happen to me! I never coasted downhill before, though I have heard some of the sleds and toboggans in the toy department speak of it. Oh, he\\'s letting go of me!\" she cried to herself, as she felt Arnold taking off his hands by which he had been holding her at the top of the ironing-board hill. \"He\\'s going to let me go!\"'\n",
      " b'Slowly at first, the Lamb on Wheels began to roll down the long, smooth, sloping board. Then she began to go faster and faster. At the bottom she could see the shiny oilcloth on the kitchen floor. Beyond the end of the ironing board the kitchen floor stretched out a long way.'\n",
      " b'\"It\\'s the wheels on her that make her coast so nice,\" explained Arnold, when the Lamb was half way down the ironing-board hill. \"If she didn\\'t have them she wouldn\\'t roll down at all. A Sawdust Doll can\\'t do it, nor a Rocking Horse. It\\'s got to be something with wheels.\"'\n",
      " b\"Once more the Lamb was lifted to the high part of the ironing board and allowed to coast down on her wheels. But, alas! this time, just as she was rolling over the kitchen floor, one of the wheels hit against Arnold's foot. Instead of going in a straight line the Lamb swung off to one side. Straight toward the outside door she rolled, and just then Susan, the cook, came in from out-of-doors.\"\n",
      " b\"So the board was hung away, and soon the Lamb was put in a little stable Mirabell made for her out of a pasteboard box. The stable was set in a corner of the playroom, near a little Wooden Lion that had once lived in a Noah's Ark. He was the only one of the Ark animals left. Arnold or Mirabell had lost all the others.\"\n",
      " b'\"I am glad to see you,\" said the Noah\\'s Ark Lion. \"I have been quite lonesome. There used to be a number of us -- there was a Tiger, a Camel, a Monkey, a Hippopotamus, and, oh! ever so many others, besides the Elephant. But we are all scattered. I am the only one left. Tell me, were you ever in a Noah\\'s Ark?\"'\n",
      " b'\"Well, yes, only it\\'s a bit crowded,\" answered the Wooden Lion. \"But it has to be that way, I suppose. I like it better in this playroom, as I can move about more. But still I was lonesome until you came. Let us be friends, and tell each other our adventures.\"'\n",
      " b'\"Well, those of us who couldn\\'t swim could float, so none of us was drowned,\" the Lion answered. \"Only being soaked in the water, as I was, made some of the paint come off my tail. I really haven\\'t been the same Lion since,\" he added, with a sorrowful sigh.'\n",
      " b'\"Of course Arnold was smaller than he is now, and he was not so kind to his toys as he has since learned to be,\" resumed the Wooden Lion. \"He really meant no harm. But, as I say, I am the only one of the Noah\\'s Ark animals left, and really I am very glad to have you to talk to.\"'\n",
      " b'Mirabell and Arnold had been told to be very careful whenever they played in the sitting room, if a fire were burning on the open hearth. But, for the moment, the little girl forgot about this. All she thought of was that her Lamb on Wheels might be burned by the blazing paper, which had been set on fire by a spark popping out from the blazing logs on the hearth.'\n",
      " b'The Lamb was wishing Mirabell would take her next door, to see the Sawdust Doll, but, as it happened, Dorothy was ill, and it was not thought best for Mirabell to go in for a few days. However, Mirabell could look from her windows over to those in the house where Dick and Dorothy lived. And though Dorothy was too ill to be out of bed, Dick was not.'\n",
      " b'The Horse wished the same thing, and he even thought perhaps he might get a chance to run over some evening after dark and talk to the Lamb. But the doors of both houses were locked each night, and though the Horse and Lamb could roam about and seem to come to life when no one was watching them, they could not unlock doors. So they had to be content to look at each other through the windows.'\n",
      " b\"At Dorothy's house the coal bin was partly under the pavement, and to put in coal a round, iron cover was lifted up from a hole in the sidewalk, and the coal was dumped through this hole. As the children watched, and as Dorothy, who was now better, stood at the window with her brother Dick, also looking on, the coal man took the cover off the hole in the sidewalk, so he could dump the black lumps through the opening into the bin.\"\n",
      " b'The coal man, after opening the large, round hole in the sidewalk, climbed back on his wagon to shovel off his load. And just then Carlo, the dog belonging to Dorothy, ran barking out of the side entrance of the house where he lived. Carlo always became excited when coal was being put in the sidewalk hole.'\n",
      " b'And, as he spoke, Carlo gave a big jump to get the tangling string off his legs. The string broke, but, as it did so, the Lamb started to roll toward the open coal hole. And, at the same moment, the driver of the wagon began shoveling some of the black lumps down the opening.'\n",
      " b'Mirabell and Arnold were so surprised for a moment at what had happened that they could only stand, looking at the hole in the sidewalk down which the Lamb on Wheels had fallen. Carlo, the fuzzy little dog, seemed to know he had done something wrong in getting tangled in the string, breaking it off, and so sending the Lamb wheeling along until she slid into the coal hole. And the dog gave a howl and ran back toward the house, having finally managed to get his legs loose from the cord.'\n",
      " b\"Perhaps he feared that he, too, might slip down that black, dark hole which led into the coal bin of Dorothy's house. Then as Mirabell and Arnold stood, looking with wide-opened eyes at the place where they had last seen the Lamb, the man on the wagon threw another shovelful of coal down the hole.\"\n",
      " b\"Dorothy's mother waited on the front porch, and Mirabell and Arnold waited on the sidewalk near the coal hole. A little while after the colored man had gone in the side entrance, through the cellar and into the coal bin, the two children heard him calling, as if from the ground beneath them.\"\n",
      " b'Mirabell and Arnold could hear him walking around on the coal under the sidewalk. In another half minute a black hand was thrust up through the hole, and in the hand was a white, woolly Lamb on Wheels. Wait a minute! Did I say white? Well, I meant to have said a BLACK Lamb.'\n",
      " b\"And she soon found out. For when the colored man had come out of the cellar, and was again shoveling the coal down the hole, Mirabell and Arnold took the black Lamb on Wheels into Dorothy's house. Dorothy and her brother Dick were glad to see the children from next door.\"\n",
      " b'Then she told her different adventures, and the Sawdust Doll told hers, so the two toys had a nice time together. Soon the warm fire made the Lamb nice and dry and fluffy again. And she was as clean as when jolly Uncle Tim, the sailor, had bought her in the store.'\n",
      " b\"Mirabell had been out in the street near Dorothy's house drawing her Lamb up and down by means of a string. And Mirabell kept watch to see that Carlo did not run along and get tangled in the string. The little girl also made sure that no sidewalk coal holes were open. She did not want the Lamb to fall into another one.\"\n",
      " b'\"Oh, I want to see it!\" cried Mirabell, and she was in such a hurry that she let go of the string by which she had been by herself on the sidewalk for a little way, and finally rolled out toward the gutter. For once in her life Mirabell forgot all about her toy, pulling her Lamb. The Lamb rolled along.'\n",
      " b'The Lamb on Wheels was so frightened when the dog took her up in his mouth that she did not know what to do. If she could, she would have rolled away as fast as a toy railroad train, such a train as Arnold and Dick played with. But the dog had the Lamb in his mouth before she knew what was happening.'\n",
      " b'Besides, across the street was a man, and, as he happened to be looking at the Lamb, of course she dared not make believe come to life and trundle along as she sometimes did in the toy store. It was against the rules, you know, for any of the toys to do anything by themselves when any human eyes saw them. And so the Lamb had to let herself be carried away by the dog.'\n",
      " b'Now you might think that when the man saw the dog run away with the Lamb on Wheels in his mouth the man would have stopped the dog. But the man was thinking of something else. He was looking for a certain house, and he had forgotten the number, and he was thinking so much about that, and other things, that he never gave the Lamb a second thought.'\n",
      " b'Away ran the dog with the Lamb on Wheels in his mouth down the street, over a low fence, and soon he was in the vacant lots where the weeds grew high. And then, as there were no human eyes in the vacant lots to see her, the Lamb thought it time to do something. She began to wiggle her legs, though she could not get them loose from the platform with wheels on, and she cried out:'\n",
      " b'\"Ill leave you here now,\" barked the dog, \"and when it gets dark I\\'ll come and get you. I\\'ll carry you back to the porch of the house, from in front of which I carried you off. Then you can roll in and get back to Mirabell, as you call her. Shall I do that?\"'\n",
      " b'\"Dear me! this surely is an adventure,\" said the Lamb on Wheels to herself, as she was left alone. \"Being taken away in a rag bag, as the Sawdust Doll was, couldn\\'t be any worse than this. And though none of my legs is broken, as was one of the White Rocking Horse\\'s, still I am almost as badly off, for I dare not move. I wonder what will happen to me next!\"'\n",
      " b'\"We can play Noah\\'s Ark over in the brook,\" explained the small boy. \"There are some boards over there. I was making a raft of them the other day. We can make another raft now, and we can get on and sail down the brook. And we can take the Lamb on board with us and make believe we\\'re in a Noah\\'s Ark and that there\\'s a flood and all like that! Won\\'t that be fun?\"'\n",
      " b'\"All aboard!\" cried the big boy, when the raft had been finished. \"All aboard! Come on!\" He picked up the Lamb again, and walked out on the raft. The smaller boy went with his chum. With long poles, cut from a near-by tree, the boys shoved the raft out into the middle of the brook.'\n",
      " b\"Now while the Lamb on Wheels was being carried away by the dog, and after she had been dropped in the lot, where she was picked up by the boys and put on a Noah's Ark raft -- while all this was happening to the toy, Mirabell, the little girl who owned the Lamb, was almost heart-broken. After she had admired the trunk Dorothy had had given to her for the Sawdust Doll, Mirabell ran back to get her pet toy.\"\n",
      " b'\"Maybe Dick took the Lamb,\" suggested Dorothy to Mirabell, when they had looked up and down the street, in front of and behind the fence, and even in the yard, and had not found the toy. \"Dick sometimes takes my things and hides them just for fun,\" Dorothy said.'\n",
      " b'\"I really must be at sea, as that jolly sailor was,\" thought the Lamb. \"I am on a voyage at last! Oh, I hope I shall not be seasick! Oh, how wet the ocean is!\" she thought, as some water splashed up near her, when the little boy shoved the raft along with his pole.'\n",
      " b'\"Though I wish some of the toys were here with me,\" she thought to herself. \"I wonder if the Sawdust Doll would get seasick if she were on board here. I don\\'t believe the Bold Tin Soldier would, and the Calico Clown would be trying to think of new jokes and riddles, so I don\\'t believe he would be ill. But I wonder what is going to happen to me? What will be the end of this adventure?\"'\n",
      " b'The two boys poled their raft down to a broader part of the brook, where it flowed at the bottom of a garden. At the upper end of the garden was a large house, and not far away was another house. The Lamb on Wheels could see the houses from where she stood on the raft, and she wondered if any little boys or girls lived in them.'\n",
      " b'\"Dear me! how fast things do happen,\" said the Lamb, speaking out loud to herself, as there was no one near just then. \"A little while ago Mirabell was pulling me along the sidewalk with a string. Then she left me and the dog ran off with me. Then he left me, and the boys carried me off on the raft. Now they have left me. I wonder who will take me next?\"'\n",
      " b'\"Whoa!\" called the real man, and it was to his real horse he was speaking, and not to the White Rocking Horse. \"Whoa now, Dobbin!\" went on the man, \"and I\\'ll let you have a drink here if the water is clean. I know you are thirsty, and there is a brook here somewhere.\"'\n",
      " b'\"Well, I do declare!\" the man cried. \"There is a white woolly Lamb toy! I must take that, too, though I don\\'t know what I can do with it. Maybe I can sell it. I am in luck to-day, getting a load of wood and a toy. Now come on, Dobbin!\" he called to his horse. \"The brook is nice and clean for you to drink from, and while you are drinking I will load the wood on my wagon and take the Lamb on Wheels. Come on, Dobbin!\"'\n",
      " b\"The man who had picked up the pieces of the boys' raft to take home to be chopped up for firewood, did all sorts of odd jobs in the neighborhood. He would cut grass, beat rugs, cart away rubbish, and do things like that for people who lived near the brook. And soon after loading his wagon with wood and taking away the Lamb on Wheels the man said to himself:\"\n",
      " b'\"A little girl who lives next door,\" explained Patrick, the gardener. \"She plays with our Dorothy, and Mirabell\\'s Uncle Tim brought her a Lamb on Wheels. Mirabell had her Lamb out in the street, but she left it for a moment and then it disappeared. Now here it is!\"'\n",
      " b'\"That will be fun!\" said Arnold, who liked games of that sort. \"I wish I had some toy soldiers,\" he went on. \"I saw some in the same store where your Rocking Horse came from, Dick. I wish I had a set of tin soldiers, with a captain and a flag and everything!\"'\n",
      " b'\"Well, let\\'s make-believe you\\'re sick and I can be a Red Cross nurse, like some of those we saw in the drugstore window down the street, making bandages for the soldiers. You could be a soldier, Ted, and I could be the nurse, and I\\'d make some sugar pills for you, if you don\\'t like the rolled-up bread ones you gave my doll.\"'\n",
      " b\"The day was a rainy one. There was no school, for it was Saturday, and staying in the house was no great fun. Janet wanted her brother to stay and play with her and she knew she must do something to make him. For a while he had been content to play that he was Dr. Thompson, come to give medicine to Jan's sick doll. But Teddy had become tired of this after paying half a dozen visits and leaving pills made by rolling bread crumbs together.\"\n",
      " b'Both children had the same curly hair. It was really beautiful, but they did not quite appreciate it, even though many of their friends, and some persons who saw them for the first time, called them \"Curlytops.\" Indeed the tops of their heads were very curly.'\n",
      " b'\"Play the soldier game. You can pretend you were caught by the enemy and your gun and uniform were taken away. Then you can be hurt and I\\'ll be the Red Cross nurse and take care of you in the tent. I\\'ll get some real sugar for pills, too! Nora\\'ll give me some. She\\'s in the kitchen now making a cake.\"'\n",
      " b'She and her brother played this game for a while, and Teddy liked it -- as long as the chocolate pills were given him. But when Janet had only a few left and Teddy was about to say he was tired of lying down, someone came into the playroom and a voice asked:'\n",
      " b\"He hunched himself forward on his hands and knees, and before he knew it he was at the head of the stairs. Then, just how no one could say, Trouble gave a yell, toppled off Teddy's back and the next instant went rolling down the flight, bump, bump, bumping at every step.\"\n",
      " b'\"Oh, Nora!\" cried Mrs. Martin, as she hurried into the dining-room with her little boy in her arms. \"Trouble fell downstairs! Get ready to telephone for his father and the doctor in case he\\'s badly hurt,\" and then she and the maid began looking over Baby William to find out just what was the matter with him, while Ted and Janet, much frightened and very quiet, stood around waiting.'\n",
      " b'The first book is named \"The Curlytops at Cherry Farm,\" and in that I had the pleasure of telling you about Ted and Janet and Trouble Martin and their father and mother, when they went to Grandpa Martin\\'s place, called Cherry Farm, which was near the village of Elmburg, not far from Clover Lake.'\n",
      " b'There the children found a goat, which they named Nicknack, and they kept him as a pet. When hitched to a wagon he gave them many nice rides. There were many cherry trees on Grandpa Martin\\'s farm, and when some of the other crops failed the cherries were a great help, especially when the Lollypop Man turned them into \"Chewing Cherry Candy.\"'\n",
      " b'After a good time on the farm the children had more fun when, as told in the second book, named \"The Curlytops on Star Island,\" they went camping with grandpa. On Star Island in Clover Lake they saw a strange blue light which greatly puzzled them, and it was some time before they knew what caused it.'\n",
      " b'The summer and fall passed and Ted and Janet went home to Cresco, where they lived, to spend the winter. What happened then is told in the third volume, called \"The Curlytops Snowed In.\" The big storm was so severe that no one could get out and even Nicknack was lost wandering about in the big drifts.'\n",
      " b'You have already met Ted, Jan and Trouble. Ted\\'s real name was Theodore, but his mother seldom called him that unless she was quite serious about something he had done that was wrong. So he was more often spoken to as Ted or Teddy, and his sister Janet was called Jan. Though oftener still they were called the \"Curlytops,\" or, if one was speaking to one or the other he would say \"Curlytop.\" That was because both Teddy and Janet had such very, very curly hair.'\n",
      " b\"Sometimes, when Mother Martin was combing the hair of the children, the comb would get tangled and she would have to pull a little to get it loose. That is one reason Ted never liked to have his hair combed. Janet's was a little longer than his, but just as curly.\"\n",
      " b\"Nora Jones, a cheerful, helpful maid-of-all-work had been in the Martin family a long while, and dearly loved the children, who were very fond of her. The Martins had many relatives besides the children's grandfather and grandmother, but I will only mention two now. They were Aunt Josephine Miller, called Aunt Jo, who lived at Clayton and who had a summer bungalow at Mt. Hope, near Ruby Lake. She was a sister of Mrs. Martin's. Uncle Frank Barton owned a large ranch near Rockville, Montana. He was Mr. Martin's uncle, but Ted and Janet also called him their uncle.\"\n",
      " b'\"Oh, we weren\\'t playing it then,\" put in Ted. \"We\\'d changed to another game. I was a wild Western bronco, like those on Uncle Frank\\'s ranch, and I was giving Trouble a ride on my back. I gave a jump when I was near the stairs, and I guess he must have slipped off.\"'\n",
      " b'\"There isn\\'t any guessing about it -- he did slip off,\" said Mrs. Martin with a smile, as she put Trouble in a chair, having made sure he was not hurt, and that there was no need of telephoning for his father or the doctor. \"You must be more careful, Teddy. You might have hurt your little brother.\"'\n",
      " b'Ted, Jan and Trouble ran up and down in front of the house while the rain fell softly and the big drops dripped from the trees. Then the clouds broke away, the sun came out, the rain stopped and with shouts and laughter the children ran to the barn next to which, in a little stable of his own, Nicknack, the goat, was kept.'\n",
      " b'\"Oh, he\\'s been pretending he was a bucking bronco, like those Uncle Frank has on his ranch, and he tossed Trouble downstairs. But the baby didn\\'t get hurt, fortunately. Now Ted\\'s playing Wild West stagecoach with Nicknack and Janet got frightened and wouldn\\'t ride.\"'\n",
      " b'\"This is an invitation from Uncle Frank for all of us to come out to his ranch in Montana for the summer,\" was the answer. \"We have been talking of going, you know, and now is a good chance. I can leave the store for a while, and I think it would do us all good -- the children especially -- to go West. So if you\\'d like it, well pack up and go.\"'\n",
      " b'\"Then I can just about guess what has happened,\" said Daddy Martin. \"Trouble heard as talking about taking Nicknack over to Mr. Newton\\'s house, where he would be kept while we are at Uncle Frank\\'s ranch, and the little fellow has just about taken the goat over himself.\"'\n",
      " b'\"Oh, yes he could, Mother!\" said Teddy. \"He\\'s seen me and Janet hitch Nicknack up lots of times, and he\\'s helped, too. At first he got the straps all crooked, but I showed him how to do it, and I guess he could \\'most hitch the goat up himself now all alone.\"'\n",
      " b'\"Our goat and little boy seem to have gone off together,\" explained Mr. Martin to Mrs. Newton who came out on the porch just then. \"We\\'d been talking before Trouble about bringing Nicknack over here, and now that both are missing we thought maybe Baby William had brought the goat over himself.\"'\n",
      " b'\"I don\\'t think that can have happened,\" returned Mr. Martin, \"Nicknack is a very gentle goat, and Trouble is used to playing with him all alone. He never yet has been hurt. Of course we are not sure that the two went away together. Trouble disappeared from the house, and he was last seen going toward the stable.'\n",
      " b'\"Yes, I think it likely that the two went away together,\" said Mrs. Newton; \"but they\\'re not here. Bob, put away that kite of yours and help Mr. Martin and the Curlytops look for Trouble. He may have gone to Mrs. Simpson\\'s,\" she went on. \"He\\'s often there you know.\"'\n",
      " b'There was a barn on the Newton place -- a barn in which Bob was counting on keeping Nicknack -- and this place was first searched lest, perchance, Trouble might have slipped in there with the goat without anyone having seen him, having come up through a back alley.'\n",
      " b'\"I\\'ll tell you what we\\'d better do,\" said Bob\\'s mother. \"Ted, you come with Bob and me. You know Trouble\\'s ways, and where he would be most likely to go. Let Janet go with her father, and we\\'ll go up and down the street, inquiring in all the houses we come to. Your little brother is sure to be near one of them.\"'\n",
      " b'So the two parties started on the search, one up and the other down the street. Bob, Teddy and Mrs. Newton inquired at a number of houses, but no one in them had seen Trouble and Nicknack that day. Nor did Janet and her father get any trace of the missing ones.'\n",
      " b'\"Let\\'s go down the back street,\" suggested Bob. \"You know there\\'s quite a lot of wagons and automobiles go along this main street where we\\'ve been looking. Maybe if Trouble hitched up Nicknack and went for a ride he\\'d turn down the back street \\'cause it\\'s quieter.\"'\n",
      " b'\"Oh, I see what he means!\" exclaimed Teddy, after thinking over what his little brother said. \"He heard us talking about bringing Nicknack over to your house, Bob, to keep him for us. Trouble likes the goat and I guess he didn\\'t want to leave him behind. Maybe he thought he could drive him away out to Montana, to Uncle Frank\\'s ranch.\"'\n",
      " b\"Nicknack really wasn't harnessed. The leather straps and the buckles were all tangled up on him, but Trouble had managed to make enough of them stick on the goat's back, and had somehow got part of the harness fast to the wagon, so Nicknack could pull it along.\"\n",
      " b'The next few days were filled with busy preparations toward going West. Daddy Martin bought the tickets, the packing was completed, last visits to their playmates were paid by Janet and Teddy, whose boy and girl friends all said that they wished they too were going out West to a big ranch.'\n",
      " b'Then came the last day in Cresco -- that is the last day for some time for the Curlytops. The house was closed, Nora going to stay with friends. Skyrocket, the dog, and Turnover, the cat, were sent to kind neighbors, who promised to look after them. Bob had already started to take care of Nicknack.'\n",
      " b\"The Curlytops were talking as they sat together in the railroad car which was being pulled rapidly by the engine out toward the big West, where Uncle Frank's ranch was. In the seat behind them was Mother Martin, holding Trouble, who was asleep, while Daddy Martin was also slumbering.\"\n",
      " b'It was quite a long ride from Cresco to Rockville, which was in Montana. It would take the Curlytops about four days to make the trip, perhaps longer if the trains were late. But they did not mind, for they had comfortable coaches in which to travel. When they were hungry there was the dining-car where they could get something to eat, and when they were sleepy there was the sleeping-car, in which the colored porter made such funny little beds out of the seats.'\n",
      " b'Jan and Ted thought it quite wonderful. For, though they had traveled in a sleeping-car before, and had seen the porter pull out the seats, let down the shelf overhead and take out the blankets and pillows to make the bed, still they never tired of watching.'\n",
      " b\"There were many other things to interest the Curlytops and Trouble on this journey to Uncle Frank's ranch. Of course there was always something to see when they looked out of the windows of the cars. At times the train would pass through cities, stopping at the stations to let passengers get off and on. But it was not the cities that interested the children most. They liked best to see the fields and woods through which they passed.\"\n",
      " b'\"You\\'ll see some real ones after a while,\" her mother told her, and then the children stopped pressing their noses flat against the car windows, for the train had come out of the wood and was nearing a large city. There, Jan and Ted felt sure, no Indians would be seen.'\n",
      " b'Something else that gave the children enjoyment was the passage through the train, every now and then, of the boy who sold candy, books and magazines. He would pass along between the seats, dropping into them, or into the laps of the passengers, packages of candy, or perhaps a paper or book. This was to give the traveler time to look at it, and make up his or her mind whether or not to buy it.'\n",
      " b'A little later the boy would come along to collect the things he had left, and get the money for those the people kept for themselves. Ted and Jan were very desirous, each time, that the boy should sell something, and once, when he had gone through the car and had taken in no money, he looked so disappointed that Jan whispered to her father:'\n",
      " b'\"Yes, I have some nice ones,\" answered the boy, and with a smile on his face he went into the baggage car, where he kept his papers, candy and other things, and soon came back with a gaily colored book, at the sight of which Ted and Jan uttered sighs of delight.'\n",
      " b'Trouble slipped out of his seat between his brother and sister and went to a vacant window himself. For a time he had good fun playing with the window catch, and Mrs. Martin let him do this, having made sure, at first, that he could not open the sash. Then they all forgot Trouble for a while and he played by himself, all alone in one of the seats.'\n",
      " b'A little later, when Teddy and Janet were tired of looking for the Indians which they never saw, they were talking about the good times they had had with Nicknack, and wondering if Uncle Frank would have a goat, or anything like it, when Trouble came toddling up to their seat.'\n",
      " b'\"Isn\\'t it just wonderful,\" said Mother Martin, \"to think of sitting down to a nice meal which is being cooked for us while the train goes so fast? Imagine, children, how, years ago, the cowboys and hunters had to go on horses all the distance out West, and carry their food on their pony\\'s back or in a wagon called a prairie schooner. How much easier and quicker and more comfortable it is to travel this way.\"'\n",
      " b'There were many travelers going West -- not all as far as the Curlytops though -- and as there was not room in the dining-car for all of them to sit down at once they had to take turns. That is why the waiter made one, two, and sometimes three calls for each meal, as he went through the different coaches.'\n",
      " b\"Supper over, the Martins went back to their place in the coach in which they had ridden all day. They would soon go into the beds, or berths, as they are called, to sleep all night. In the morning they would be several hundred miles nearer Uncle Frank's ranch.\"\n",
      " b'Indeed after the first day Ted and Janet found it so. They wished, more than once, that they could get out and run about, but they could not except when the train stopped longer than usual in some big city. Then their father would take them to the platform for a little run up and down.'\n",
      " b'All that anyone knew was that there had been a severe jolt -- a \"bunk\" Teddy called it -- and that the train had come to a sudden stop. So quickly had it stopped, in fact, that a fat man, who was asleep in a berth just behind Mr. Martin, had tumbled out and now sat in the aisle of the car, gazing about him, a queer look on his sleepy face, for he was not yet fully awake.'\n",
      " b'\"Thank goodness, no,\" said Mrs. Martin, who, as had some of the other women, had on a dressing gown. Mrs. Martin was looking at Trouble, whom she had taken up in her arms. \"He hasn\\'t a scratch on him,\" she said, \"though I heard him slam right against the side of the car. He was next to the window.\"'\n",
      " b'Mr. Martin, after making sure his family was all right, partly dressed and went out with some of the other men. The train had come to a standstill, and Jan and Ted, looking out of the windows of their berths, could see men moving about in the darkness outside with flaring torches.'\n",
      " b'\"It isn\\'t a bad collision,\" said Daddy Martin. \"Our engine hit a freight car that was on a side track, but too close to our rails to be passed safely. It jarred up our engine and the front cars quite a bit, and our engine is off the track, but no one is hurt.\"'\n",
      " b'Then there was much puffing and whistling of the engine. The Curlytops, looking out of the window again, saw more men hurrying here and there with flaring torches which flickered and smoked. These were the trainmen helping to get the engine back on the rails, which they did by using iron wedges or \"jumpers,\" much as a trolley car in your city streets is put back on the rails once it slips off.'\n",
      " b'I will not tell you all that happened on the journey to the West. Truth to say there was not much except the collision. The Curly-tops ate their meals, drank cupful after cupful of water, and Trouble did the same, for children seem to get very thirsty when they travel -- much more so than at home.'\n",
      " b'\"We call it Circle O,\" explained the ranchman. \"Each place in the West that raises cattle or horses has a certain sign with which the animals are branded, or marked, so their owners can tell them from others in case they get mixed up. My mark is a circle around an O.\"'\n",
      " b'\"Oh, that\\'s over among the hills,\" said Uncle Frank, waving his hand toward some low hills that were at the foot of some high mountains. \"It wouldn\\'t do,\" he went on, \"to have a ranch too near a railroad station. The trains might scare the horses and cattle. You will soon be there, Curlytops. We\\'ll begin to travel in a minute.\"'\n",
      " b'She snuggled closer to her brother. Then Teddy saw where Janet pointed. A big man, whose face was the color of a copper cent, was walking along the station platform. He was wrapped in a dirty blanket, but enough of him could be seen to show that he was a Redman.'\n",
      " b'\"Ha! Ha! That was pretty good!\" exclaimed the ranchman when Ted and Janet, by turns, had told of Trouble\\'s being found asleep in the goat-wagon. \"Well, it\\'s too bad you couldn\\'t bring Nicknack with you. He\\'d like it out on the ranch, I\\'m sure, but it would be too long a journey for him. You\\'ll have rides enough -- never fear!\"'\n",
      " b'When the Curlytops drew closer to the ranch they could see that one of the buildings was a house, almost like their own in the East, only not so tall. It was all one story, as were the other buildings, some of which were stables for the horses and some sleeping places, or \"bunk houses,\" for the cowboys, while from one building, as they approached closer, there came the good smell of something cooking.'\n",
      " b'All at once there came a lot of wild yells, and sounds as if a Fourth-of-July celebration of the old-fashioned sort were going on. There was a popping and a banging, and then around the corner of the house rode a lot of roughly-dressed men on ponies which kicked up a cloud of dust.'\n",
      " b'On came the cowboys, yelling, shouting and shooting off their big revolvers which made noises like giant firecrackers. The men, some of whom wore big leather \"pants,\" as Teddy said afterward, and some of whom had on trousers that seemed to be made from the fleece of sheep, swung their hats in the air. Some of them even stood up in their saddles, \"just like circus riders!\" as Janet sent word to Aunt Jo, who was spending the summer at Mt. Hope.'\n",
      " b'\"Well, sometimes it\\'s to scare away bad men who might try to steal my cattle or horses, and again it\\'s to scare the cattle themselves. You see,\" explained Uncle Frank, while the cowboys jumped from their horses and went to the bunk house to wash and get ready for supper, \"a ranch is just like a big pasture that your Grandfather Martin has at Cherry Farm. Only my ranch is ever so much bigger than his pastures, even all of them put together. And there are very few fences around any of my fields, so the cattle or horses might easily stray off, or be taken.'\n",
      " b'\"But sometimes the cattle take it into their heads to run away themselves. They get frightened -- \\'stampeded\\' we call it -- and they don\\'t care which way they run. Sometimes a prairie fire will make them run and again it may be bad men -- thieves. The cowboys have to stop the cattle from running away, and they do it by firing revolvers in front of them. So it wouldn\\'t do to have real bullets in their guns when the cowboys are firing that way. They use blank cartridges, just as they did now to salute you when they came in.\"'\n",
      " b'\"A soft-foot? Oh, ho! I see!\" he laughed. \"You mean a tenderfoot! Well, that\\'s what the Western cowboys call anybody from the East -- where you came from. It means, I guess, that their feet are tender because they walk so much and don\\'t ride a horse the way cowboys do. You see out here we folks hardly ever walk. If we\\'ve only got what you might call a block to go we hop on a horse and ride. So we get out of the way of walking.'\n",
      " b'\"No, I haven\\'t a goat,\" laughed Uncle Frank, \"though there might be some sheep on some of the ranches here. But I guess ponies will suit you children better. When you Curlytops learn to ride you can take Trouble up on the saddle with you and give him a ride. He\\'s too small to ride by himself yet.\"'\n",
      " b'\"Bless your heart, no!\" exclaimed Aunt Millie. \"We wouldn\\'t want them, for they\\'re dirty and not at all nice, though some of them do look like pictures when they wrap themselves around in a red blanket and stick feathers in their hair. We don\\'t want any Indians. Now tell me about your trip.\"'\n",
      " b'\"It\\'s a nice name,\" said Aunt Millie. \"And now let me see you Curlytops -- and Trouble, too -- though his hair isn\\'t frizzy like Ted\\'s and Janet\\'s -- let me see you eat until you get as fat as a Ring Rosy yourselves. If you don\\'t eat as much as you can of everything, Hop Sing will feel as though he was not a good cook.\"'\n",
      " b'After supper the Curlytops and the others sat out on the broad porch of the ranch house. Off to one side were the other buildings, some where the farming tools were kept, for Uncle Frank raised some grain as well as cattle, and some where the cowboys lived, as well as others where they stabled their horses.'\n",
      " b'\"What can we do?\" asked Teddy. Very often he let Jan plan some fun, and I might say that she got into trouble doing this as many times as her brother did. Jan was a regular boy, in some things. But then I suppose any girl is who has two nice brothers, even if one is little enough to be called \"Baby.\"'\n",
      " b\"So while Trouble climbed up into his mother's lap, and the older folks were talking among themselves, the two Curlytops, not being noticed by the others, slipped off the porch and walked toward the ranch buildings, out near the corrals, or the fenced-in places, where the horses were kept.\"\n",
      " b'There were too many horses to keep them all penned in, or fenced around, just as there are too many cattle on a cattle ranch. But the cowboys who do not want their horses which they ride to get too far away put them in a corral. This is just as good as a barn, except in cold weather.'\n",
      " b'\"So\\'m I. Oh, look at the lots of ponies!\" she cried, as she and Ted turned a corner of one of the ranch buildings and came in sight of a new corral. In it were a number of little horses, some of which hung their heads over the fence and watched the Curlytops approaching.'\n",
      " b'And this the Curlytops did. When the big horse was chewing the grass Janet gave him, Ted held out some to the little horse at the other end of the corral, And he ate it, but only just in time, for the big pony saw what was going on and trotted up to shove the small animal out of the way. But it was too late.'\n",
      " b'Evening was coming on. The sun had set, but there was still a golden glow in the sky. Far off in one of the big fields a number of horses and cattle could be seen, and riding out near them were some of the cowboys who, after their supper, had gone out to see that all was well for the night.'\n",
      " b'\"Yes, as far as you can see, and farther. If you Curlytops get lost, which I hope you won\\'t, you\\'ll have to go a good way to get off my ranch. But let me tell you now, not to go too far away from the house, unless your father or some of us grown folks are with you.\"'\n",
      " b'\"Well, I would have done that if I knew where to go,\" said the foreman. \"But I didn\\'t hear until a little while ago, when one of the cowboys I sent to see if the ponies were all right came in. He got there to find \\'em all gone, so I came right over to tell you.\"'\n",
      " b'\"Yes, to find out if they took any of my ponies. You see,\" went on Uncle Frank, speaking to Daddy and Mother Martin as well as to the Curlytops, \"the Indians are kept on what is called a \\'reservation\\' That is, the government gives them certain land for their own and they are told they must stay there, though once in a while some of them come off to sell blankets and bark-work at the railroad stations.'\n",
      " b'\"And, sometimes, maybe once a year, a lot of the Indians get tired of staying on the reservation and some of them will get together and run off. Sometimes they ride away on their own horses, and again they may take some from the nearest ranch. I guess this time they took some of mine.\"'\n",
      " b'\"Well, I don\\'t know. I\\'m afraid you\\'re too little. But, speaking of riding a pony, to-morrow I\\'ll have one of the cowboys start in to teach you and Janet to ride. Now I guess I\\'ll have to go see this Henry Jensen and ask him about the Indians and my stolen ponies.\"'\n",
      " b'The children wandered about among the ranch buildings, looking in the bunk house where the cowboys slept. There was only one person in there, and he was an old man to be called a \"boy,\" thought Janet. But all men, whether young or old, who look after the cattle on a ranch, are called \"cowboys\" so age does not matter.'\n",
      " b'In a little while he came riding into the yard in front of the bunk house on a lively little pony. He made the animal race up and down and, while doing this, the cowboy swung his coiled rope, or lasso, about his head, and sent it in curling rings toward posts and benches, hauling the latter after him by winding the rope around the horn of his saddle after he had lassoed them.'\n",
      " b\"He leaped from the saddle and lifted Teddy up to it, while Janet and Trouble looked on in wonder. Then holding Ted to his seat by putting an arm around him, while he walked beside the pony and guided it, the cowboy gave the little fellow a ride, much to Teddy's delight.\"\n",
      " b'They spent the morning playing about the ranch near the house. They made a sea-saw from a board and a barrel, and played some of the games they had learned on Cherry Farm or while camping with Grandpa Martin. Then dinner time came, but Uncle Frank and the cowboys did not come back to it.'\n",
      " b'But the day was so pleasant, and it was so nice to walk over the soft grass that, before they knew it, Teddy and Janet had wandered farther than they meant to. As the land was rolling -- here hills and there hollows -- they were soon out of sight of the ranch buildings, but they were not afraid, as they knew by going to a high part of the prairie they could see their way back home -- or they thought they could. There were no woods around them, though there were trees and a little stream of water farther off.'\n",
      " b'Suddenly, as the Curlytops were walking along together, they came to a place where there were a lot of rocks piled up in a sort of shelter. Indeed one place looked as though it might be a cave. And as Teddy and Janet were looking at this they heard a strange noise, which came from among the rocks.'\n",
      " b'Teddy Martin did not run away as Jan started to leave the pile of rocks from which the queer sound had come. Instead he stood still and looked as hard as he could toward the hole among the stones -- a hole that looked a little like the cave on Star Island, but not so large.'\n",
      " b'But the man kept on as if he had not heard, as indeed he had not. For on the prairies the air is so clear that people and things look much nearer than they really are. So, though the man seemed to be only a little distance away, he was more than a mile off, and you know it is quite hard to call so as to be heard a mile away; especially if you are a little boy.'\n",
      " b'But the man on the horse gave no sign that he had heard. As a matter of fact, he had not, being too far away, and the wind was blowing from him toward Teddy and Jan. If the wind had been blowing the other way it might have carried the voices of the children toward the man. But it did not.'\n",
      " b'Janet, not feeling that she ought to run on home and leave Teddy there and yet not feeling brave enough to go close to the cave among the rocks with him, hardly knew what to do. She walked back a little way and then, suddenly, the noise came, more loudly than at first.'\n",
      " b'Water is not very plentiful on the prairies. In fact, it is so scarce that often men and horses get very thirsty. But the Curlytops were lucky in finding a spring among the rocks on Ring Rosy Ranch. It was not a very large spring, and it was well hidden among the big stones, which, is, perhaps, why it was not visited by many of the ponies and cattle. They come in large numbers to every water-hole they can find.'\n",
      " b'She went straight to the spring, following the sound of the dripping water, and found where it bubbled up in a split in the rock. The water fell into a little hollow, rocky basin and there was enough for Ted and his sister to fill their hats. First they each took a drink themselves, though, for the day was warm.'\n",
      " b'The pony smelled the water when Janet was yet a little way from him, and raised his head and part of his body by his forefeet. Though clear, cold water has no smell to us, animals can smell it sometimes a long way off, and can find their way to it when their masters would not know where to go for a drink.'\n",
      " b'\"\\'Cause I heard Uncle Frank say so. Mother asked where a doctor lived, and Uncle Frank showed her that white house. I was on the porch and I heard him. He said if ever we needed a doctor we only had to go there and Doctor Bond would come right away. He\\'s the only doctor around here.\"'\n",
      " b'\"Yes, these Curlytop children found one in the cave among the rocks. It\\'s on Circle O Ranch -- I should say Ring Rosy,\" and the doctor gave Uncle Frank\\'s place the new name. \"These are Mr. Barton\\'s nephew\\'s children,\" he went on, for Ted and Janet had told the doctor that it was their father\\'s uncle, and not theirs, at whose home they were visiting. Though, as a matter of fact, Ted and Janet thought Uncle Frank was as much theirs as he was their father\\'s and, very likely, Uncle Frank thought so himself.'\n",
      " b'Jim Mason jumped on his own swift pony, saying he could make as good time over the rough prairie as Doctor Bond could in his automobile. The Curlytops rode in the machine with the physician. Uncle Frank and Daddy Martin went along, for they, too, were interested in the sick pony.'\n",
      " b'\"Looks that way,\" replied the foreman. \"I guess he must have drunk some water that had a bit of poisoned meat in it. You see,\" he went on to the doctor, Mr. Martin and the children, \"we have a lot of wolves and other pesky animals around here. They\\'re too tricky to catch in traps or shoot, so we poison \\'em by putting a white powder in some meat. Sometimes the wolves will drag a piece of the poisoned meat to a spring of water, and they must have done it this time. Then the pony drank the water and it made him sick.\"'\n",
      " b'\"Oh, no!\" exclaimed the foreman. \"But I\\'ll send one of the men over with some straw to make him a soft bed, and we\\'ll see that he has water to drink. He won\\'t want anything to eat until he gets better. The doctor will come to see him to-morrow. Won\\'t you?\" he went on to Doctor Bond.'\n",
      " b'\"No, it isn\\'t one of my brand,\" said the owner of Ring Rosy Ranch. \"It\\'s a strange pony that must have wandered into this cave after he found he was poisoned. I reckon the poor thing thought he\\'d die in there, and maybe he would if the children hadn\\'t found him.\"'\n",
      " b'\"Yes, I guess he can,\" answered Uncle Frank. \"If nobody comes to claim him you children may have him. And if anyone does come after him I\\'ll give you another. I was going to give you each a pony, anyhow, as soon as you got used to the ranch, and I\\'ll do it. If Ted wants to keep Clipclap, as he calls him, I\\'ll give Janet another.\"'\n",
      " b'There was nothing more that could be done just then for the sick pony, so the Curlytops and the others left him in the cave. The children were glad he did not groan any more. A little later Jim Mason sent one of the cowboys with some clean straw to make a bed for the little horse, and a pail of the cool, spring water was put where the animal could reach it.'\n",
      " b'For two days the pony stayed in the cave, and then Doctor Bond said he was much better and could be led to the ranch. Uncle Frank took Ted and Janet out to the rocks to bring back their pet, but he had to walk very slowly, for he was still weak from the poison.'\n",
      " b'\"Why don\\'t you try something else besides a post?\" asked one of Uncle Frank\\'s men, as he, too, noticed Teddy. \"Throwing a rope over a post is all right to start, but if you want to be a real cowboy you\\'ll have to learn to lasso something that\\'s running on its four legs. That\\'s what most of our lassoing is -- roping ponies or steers, and they don\\'t very often stand still for you, the way the post does.\"'\n",
      " b'The little boy and girl -- Teddy carrying his small lasso -- went out to a field not far from the house, and there they played cowboy. As they had planned, Teddy was the cowboy and Janet the wild pony, and she ran around until she was tired. Teddy ran after her, now and then throwing the coil of rope at her.'\n",
      " b'\"Course not!\" cried Teddy. \"I\\'ll only lasso him a little. Now you come and hold him by the rope that\\'s on his neck, Jan. And when I tell you to let go, why, you let go. Then he\\'ll run and I can lasso him. I\\'ve got to lasso something that\\'s running, else it isn\\'t real wild-wester.\"'\n",
      " b'\"Oh, my, Teddy!\" cried the ranchman. \"You mustn\\'t do that, Curlytop! The little calf might fall and break a leg. Wait until you get bigger before you try to lasso anything that\\'s alive. Come on, we\\'ll have other fun than this. I\\'m going to drive into town and you Curly tops can come with me.\"'\n",
      " b'Aunt Millie smoothed out its feathers and got it some water. The rooster drank a little and seemed to feel better. Then it ran off to join the other roosters and the cackling hens that had been watching what Trouble did, doubtless wondering what had gotten into the lassoed rooster to make it run around the way it did on the end of a rope. But it was Baby William who made all the trouble.'\n",
      " b'\"No more lasso!\" exclaimed Mrs. Barton, trying not to smile, for the sight of the rooster, caught the way he had been, made even the older folks want to laugh. Ted and Janet did laugh, but they did not let Trouble see them. If he had he might have thought he had done something smart or cute, and he would try it over again the first chance he had. So they had to pretend to be sharp with him. The rooster was not hurt by being lassoed.'\n",
      " b\"Afterward Trouble told how he did it. With the slip-noose of the rope in one hand and holding the rope's end in the other, Baby William walked quietly up behind the rooster and tossed the loop over its head. Then he pulled it tight and started to run, as he had seen the cow ponies galloping to pull down a horse or steer that needed to be branded or marked with the sign of the Ring Rosy Ranch. The rooster was very tame, often eating out of Aunt Millie's hand, so he was not afraid to let Trouble come up quite close to him.\"\n",
      " b\"Janet's pony, Star Face, certainly seemed to like her. For he came when she called him and took lumps of sugar from her hand. He liked Teddy, too. In fact both ponies were very pretty and friendly and it would be hard to say which was the better. Janet liked hers and Teddy liked his, and that is the best thing I can say about them.\"\n",
      " b'By this time Teddy and Janet had learned to ride quite well for such little children. They knew how to sit in a saddle, up straight like an arrow, and not slouched down or all humped up \"like a bag of meal,\" as Uncle Frank was wont to say. They knew how to guide their ponies by pulling on the reins to left or to right, according to which way they wanted to go.'\n",
      " b'Of course they could not ride very fast yet, and Mother Martin was just as glad they could not, for she was afraid, if they did, they might fall off and get hurt. But Teddy and Janet were careful, and they knew how to sit in the saddle with their feet in the stirrups.'\n",
      " b\"They would often come riding and swooping in from the distant fields after their day's work, yelling and shouting as well as firing off their big revolvers. But neither the Curlytops nor their mother were as frightened at this play of the cowboys as they had been at first.\"\n",
      " b'Teddy generally won these races, for Janet, who was very tender-hearted, did not like to make her pony go as fast as it could go. Often, perhaps, if Janet had urged Star Face on she would have beaten her brother, for Clipclap still felt a little weak, now and then, from his illness.'\n",
      " b'\"A bucking bronco jumps up in the air with all four feet off the ground at once, and comes down as stiff as a board,\" explained Uncle Frank. \"That isn\\'t nice for the man that\\'s in the saddle, though the cowboys know how to ride most bucking broncos, that are really sort of wild horses.\"'\n",
      " b'They would have called for him to \"Look out!\" and the cowboy would have kept away from the animal. But it was different with Trouble. To him one horse was like another. He liked them all, and he never thought any of them would kick or bite him. The bucking bronco was most dangerous of all.'\n",
      " b'\"No, don\\'t call, Janet,\" said the foreman. \"You might make the bronco give a jump, and then he\\'d step on your little brother. That horse is a savage one, and he\\'s so excited now, from so many of the cowboys having tried to ride him, that he might break loose and kick Trouble. We\\'ve got to keep quiet.\"'\n",
      " b'\"Maybe I get a horse wide,\" he said to himself, for he was about as eager over horses as his sister or brother, and, so far, the only rides he had had were when he sat in the saddle in front with them or with his father, and went along very slowly indeed. For they dared not let the horse go fast when Trouble was with them, and Trouble wanted to go fast.'\n",
      " b'Nearer and nearer he came to the bronco. The animal, without turning its head, knew that someone was coming up behind. Many a time a cowboy had tried to fool the savage horse that way, and leap into the saddle without being seen. But Imp, as the bronco was named, knew all those tricks.'\n",
      " b'The bronco heard the sound of running feet. He turned his head around to see who else was coming to bother him and then, before Imp could do anything and before Trouble could reach and put his little hands on the dangerous heels, the foreman caught up Baby William and jumped back with him, out of the way in case Imp should kick.'\n",
      " b'\"No you don\\'t! Not this time!\" cried Jim Mason, as he ran back to the fence with Trouble. \"And you must never go into the corral or near horses again, Trouble! Do you hear?\" and the foreman spoke to Baby William as though very angry indeed. But he had to do this, for the little fellow must learn not to go into danger.'\n",
      " b'Jim watched Imp, and as soon as the bronco stopped rolling and stood up again the foreman jumped into the saddle. This was too much for Imp. He made up his mind he could not get rid of such a good rider, so the horse settled down and galloped around the corral as he ought to do.'\n",
      " b'So they went out to the stable where their ponies were kept, and there one of the cowboys kindly saddled Clipclap and Star Face for the little Curlytops. Uncle Frank had given orders to his men that they were to let the children have the ponies whenever it was safe to ride, and this was one of the nicest days of the summer.'\n",
      " b'Teddy pointed. His sister saw several men on horseback -- at least that is what they looked like -- coming toward them. Something about the figures seemed a bit strange to the children. Ted and Jan looked at one another and then back toward the ranch houses, which, they made sure, were not out of sight this time.'\n",
      " b\"And there was no doubt about it. As the group of riders came closer to the children, whose ponies did not go as fast as the larger horses, it was seen that they were indeed Indians, many of them wrapped in blankets. There were men, women, boys and girls, and some of the smaller children were carried wrapped tightly to their mothers' backs.\"\n",
      " b'For a time there was some little excitement on the ranch, until one of the cowboys, riding out to see the Indians, came back and said they were not \"wild\" ones, but a band that went about selling baskets and other things they made. They did no harm, and for a time camped near the ranch, the children, even Trouble, going over to see them. But for some time the Curlytops did not forget the fright their first view of the Indians gave them.'\n",
      " b'In the days that followed Teddy and Janet had many rides on Clipclap and Star Face, their two nice ponies. Sometimes they were allowed to go a little way over the prairies by themselves. But when they went for a long ride Uncle Frank, Jim Mason, their father or some of the cowboys were with them.'\n",
      " b'And then, a few days later, more bad news came to Uncle Frank. With his cowboys he was getting some cattle ready to ship away to a distant city, from where they were to be sent still farther away in a train of cattle cars, when a cowboy, who seemed much excited, came riding up to the corral.'\n",
      " b'\"That\\'s right!\" laughed Uncle Frank. \"I guess we won\\'t bring any Indians here, Curlytop, even if we catch \\'em, which we may not do as they have a good start of us. Anyhow we\\'ll have to turn the Redmen back to their reservation where they belong if we get any of them. We\\'ll just take my cattle and horses away, if we can, and tell the Indians to go home and be good.\"'\n",
      " b'Brother and sister went to the place where Clipclap had stumbled. There they saw a little hole in the ground. It was the front, or maybe the back, door of the home of a little animal called a gopher, which burrows under the earth. A gopher is a sort of squirrel-like rat, and on the prairies they make many holes which are dangerous if a horse suddenly steps into them. Prairie dogs are another species of animal that burrow on the Western plains, making holes into which horses or ponies often step, breaking their legs and throwing their riders.'\n",
      " b'Janet and Teddy sat beside the gopher hole, while their ponies, not far from them, ate the sweet grass of the prairie. Clipclap and Star Face did not wander away, even if they were not tied to a hitching post. For Western horses and cow ponies are trained to stand where their master leaves them, if he will but toss the reins over their heads and let them rest on the ground.'\n",
      " b'When a pony sees that this has been done he will never run away, unless perhaps something frightens him very much. It may be that he thinks, when the reins are over his head and down on the ground, they are tied to something, so he could not run away if he wanted to.'\n",
      " b\"Teddy whistled for his pony and Clipclap came slowly up to his little master. Janet held out a bunch of grass to Star Face and her pony, just as he had been taught, came up to her. Teddy helped his sister get up in the saddle. It was not hard for them, as the ponies were small, and Jim Mason had showed them how to put one foot in the stirrup, and then, with one hand on the saddle and the other grasping both the bridle and the pony's mane, give a jump that carried them up. But though Janet could mount her pony alone Teddy always helped her when he was with her by holding the stirrup.\"\n",
      " b'\"Oh, no! Don\\'t you remember I told you they always take something to eat with them when they go out this way? They are used to camping on the prairies, and they know how to make a fire, broil the bacon and make their coffee,\" answered Aunt Millie. \"You need never worry about Uncle Frank and his cowboys. They\\'ll be all right.\"'\n",
      " b'\"Yes, they had a lot of my best animals. I guess they must be hiding away somewhere among the hills and mountains. We came pretty close to them at one time, and they suddenly disappeared. It seems as if they must have gone into a big hole or cave. We couldn\\'t find them.\"'\n",
      " b'Teddy, however, did not have much better luck making the bow than his sister had had. The trouble was that the sticks Janet had picked up were not the right kind. They would not bend, and to make a bow that shoots arrows a piece of wood that springs, or bends, is needed. For it is the springy action of the wood that shoots the arrow on its way.'\n",
      " b\"Teddy thought for a few moments. Playing out at Uncle Frank's ranch was different from playing at home. In some ways it was not so easy, for at home if the Curly-tops could not think up any way to have fun by themselves, they could run down the street and find some other boys and girls. But here there were no streets, and no other boys or girls unless Teddy and Janet went a long way to look for them, and they could not do that.\"\n",
      " b'\"Oh, that\\'ll be fun!\" cried Janet, and then she and Ted rolled themselves up in the old quilts and pretended to go to sleep on the soft grass of the prairie, making believe it was night, though of course it was not, for the sun was shining. Then they ate the cookies, pretending they were bacon, sandwiches, cake and other things that cowboys like.'\n",
      " b'Two or three days later Uncle Frank and the cowboys went out again to look for the Indians, but they did not find them. From other ranches word came of cattle and horses that had been stolen; and more cowboys were hired to keep watch over the animals that had to be left out in the big fields to eat their fill of grass. No barn was large enough to hold them.'\n",
      " b'Ted and Janet climbed up on the corral fence to look at the ponies. A few were somewhat tame, and allowed the Curlytops to pat them. But others were very wild, and ran about as though looking for a place to jump the fence or get out through a hole. But the fence was good and strong. It was high and had no holes in it.'\n",
      " b'The corral, or yard where the half-tamed horses were kept while they were being got ready to send away, was closed by a large gate, but one easy to open if you knew how. All one had to do was to pull on a little handle, which snapped a spring and the gate would swing open.'\n",
      " b'\"He didn\\'t mean to be bad,\" said his mother, as she carried him back to the house, \"but he has made a lot of work. I\\'ll have to punish him by not letting him out to play for an hour or so. Then he\\'ll remember not to open gates again, whether he thinks he is helping horses or not.\"'\n",
      " b'So the cowboys rode up on their own swift ponies, that seemed to be having a good time, and then the other ponies nearest the corral gate were turned in through it. Then as the rest were driven up they did as the first ones had done and galloped back where they had been before Trouble let them out.'\n",
      " b'One after another the ponies ran back into the corral until every one was there. Then Uncle Frank closed the gate, and this time he locked it so that no one could open it without the key. But no one would try, not even Trouble, for, crying and sobbing to be allowed to go out and play, he had been given a lesson that he would not soon forget.'\n",
      " b'\"I\\'m sorry I had to punish him,\" said Mother Martin to the Curlytops, when they came in after the ponies were once more in the corral, \"but I just had to. Work on a ranch is hard enough without little boys letting the horses run wild after they have once been caught.\"'\n",
      " b'This was what Trouble liked, and he soon dried his tears and sat on the saddle in front of Uncle Frank as happy as could be. Janet and Ted got out their ponies, and rode with Uncle Frank and Trouble around the outside of the corral, looking at the little horses inside the fence. They were quieter now, and were eating some oats the cowboys had put out for them.'\n",
      " b'Two or three days after this, when the ponies had been driven away to the railroad station to be shipped to a far-off state, a cowboy came riding in with news that he had seen a band of two or three Indians pass along the prairie near the rocks where Teddy and Janet had found Clipclap.'\n",
      " b'\"Why, what\\'s the matter?\" asked Baldy with a laugh, as he limped to the bench and sat down near the two children. \"You act as sad and gloomy as if there wasn\\'t a Christmas or a New Year\\'s any more, to say nothing of Fourth of July and birthdays! What\\'s the matter? Seems to me, if I had all the nice, curly hair you two have, I\\'d be as happy as a horned toad and I\\'d go around singing all day long,\" and Baldy rubbed his hand over his own smooth head and laughed.'\n",
      " b'\"Yes, you\\'re getting to be pretty good riders,\" admitted Baldy. \"But that isn\\'t saying you\\'re big enough to go on a trail after Indians. Of course these Indians may not be very bad, and maybe they aren\\'t the ones that took our horses. But riding on a trail takes a long while, and maybe the boys will be out all night in the open. You wouldn\\'t like that.\"'\n",
      " b'\"Well, of course, having a pony makes it easier to keep on the trail. You couldn\\'t go very far walking over the prairies -- at least none of us do. We all ride. But I\\'ll tell you some stories about cowboys and Indians and that will amuse you for a while. Like to hear \\'em?\"'\n",
      " b'So Baldy, sitting on the bench in front of the bunkhouse and resting his lame foot on a saddle on the ground, told the Curlytops stories of his cowboy life -- of sleeping out on the prairies keeping watch over the cattle, of Indians or other bad men who would come and try to steal them, and how he and his friends had to give chase to get the steers or ponies back.'\n",
      " b'\"And you don\\'t have to take Teddy out behind the barn to tell him the scary one,\" put in Janet. \"You could stay here, and I could cover up my ears with my hands when you came to the terrible parts, couldn\\'t I? Is there any parts in it that isn\\'t scary? I\\'d like to hear them, Mr. Baldy.\"'\n",
      " b'\"No, I wasn\\'t much afraid, or if I was I\\'ve forgotten it now, as it was quite a while ago. Anyhow, one day I was out on the prairie, picking flowers, I think, for I know I used to like flowers, and, all of a sudden, along came a lot of Indians on horses, and one of them picked me up and took me right away with him, on the horse in front of him.'\n",
      " b'\"The horse was a strong one, and could easily carry both of us, and though I wiggled around a good bit and yelled, the Indian didn\\'t let go of me. On and on he rode, carrying me off, and the other Indians rode ahead of us, and on either side. I couldn\\'t get away, no matter how I tried.'\n",
      " b'\"Yes,\" answered Baldy, and there was a queer smile on his face, \"but I guess I forgot to tell you that the time I was captured by the Indians I was a little boy, not as big as you, Curlytop. And the reason they picked me up off the prairie was that I had wandered away from my home and was lost. So the nice squaw kept me until one of the Indian men had time to take me home.\"'\n",
      " b'The Curlytops said they would, and they were soon taking turns riding Trouble on the saddles in front of them. Clipclap and Star Face liked the children and were well-behaved ponies, so there was no danger in putting Trouble on the back of either as long as Ted or Janet held him.'\n",
      " b\"Teddy and Janet knew what that meant. They had learned this kind of fun at Grandpa Martin's Cherry Farm. Here, on Ring Rosy Ranch, there was a large barn filled with hay, and there was plenty of room to slide down in the mow, or place where the hay was put away.\"\n",
      " b'Clipclap and Star Face, the two sturdy little ponies, trotted bravely along, carrying Teddy and Janet on their backs. The ponies did not wonder where they were going -- they hardly ever did that. They were satisfied to go wherever their master or mistress guided them, for they knew the children would be good to them.'\n",
      " b'On and on the ponies trotted, carrying the Curlytops farther and farther from the Ring Rosy Ranch house. But the children were not afraid. The sun was shining brightly, and they had often before ridden this far alone. They could look back at the ranch buildings when they got on top of the little hills with which the prairie was dotted, and they were not lonesome.'\n",
      " b'Indeed the little animals were thirsty, and after they had rested a while -- for Uncle Frank had told the children it was not wise to let a horse or pony drink when it was too warm -- Clipclap and Star Face had some of the cool water that bubbled up among the rocks.'\n",
      " b'After Clipclap had been found at the spring, the time he was hidden in the cave, one of the cowboys had brought a tin cup to the spring, leaving it there, so if anyone passed the spring it would be easy to get a drink without having to use a hat or kneel down on the ground. For horses and cattle there was a little rocky basin into which the cool water flowed.'\n",
      " b\"Neither of the Curlytops stopped to think that their father, Uncle Frank and the cowboys had started off early that morning, and must have ridden on many miles ahead. The cowboys' horses, too, could go faster than the ponies Star Pace and Clipclap, for the larger horses had longer legs.\"\n",
      " b'This made Janet feel better and once more she and her brother looked around to see what made the queer whistling sound, that still kept up. It was just like a boy calling to another, and Teddy was quite puzzled over it until he suddenly saw what was doing it.'\n",
      " b'Perched on a small mound of earth near a hole in the ground, was a little animal, about as big as a large rat, though, as Janet said, he was \"nicer looking.\" And as Ted and his sister looked, they saw this little animal move, and then they knew he it was that was whistling.'\n",
      " b'As they started off, the prairie dog, which really did make a whistling sound, suddenly darted down inside his burrow or hole. Perhaps he thought Teddy and Janet were coming to carry him off, but they were not. The children saw many more of the little animals as they rode over the prairies.'\n",
      " b\"For a while they could see many marks in the soft ground -- the marks of horses' feet, some shod with iron shoes and others bare, for on the prairie grass there is not the same need of iron shoes on the hoofs of horses as in the city, with its hard, paved streets. Then the marks were not so plain; and pretty soon, about a mile from the spring amid the rocks where the ground was quite hard, Teddy and Janet could see no marks at all.\"\n",
      " b'But the sun did not stay high in the sky all the afternoon. Presently the bright ball of fire began to go down in the west, and the shadows of Teddy and Janet grew long on the prairie. They knew what those long shadows meant -- that it was getting late afternoon.'\n",
      " b'But they did not reach the rocks. Up the hollows and across the hills they rode, over the broad prairies, but no rocks did they see. At last the ponies began to go more slowly, for they were tired. It grew darker. Ted looked anxiously about. Janet spoke softly to him.'\n",
      " b'\"Pooh! No!\" he exclaimed, and he talked loudly, perhaps just so he would not be afraid. You know a boy always whistles very loudly at night when he is walking along a dark place alone. And if there are two boys they both whistle. What girls do when they walk through a dark place alone I do not know. Maybe they sing.'\n",
      " b\"He turned his pony's head and the tired little animal walked slowly on and Janet's Star Face followed. But the truth of the matter was, Ted did not know in which direction to guide his little horse. He could not remember where the rocks lay. But Janet was trusting to him, and he felt he must do his best.\"\n",
      " b'Wearily the two Curlytops slipped from their saddles. The ponies seemed glad of this, and at once began to eat the grass that grew all about. Teddy and Janet looked at them awhile. It was not so dark but what they could see things close to them, and the stars were twinkling brightly overhead.'\n",
      " b'Then they sat and watched the ponies eating in the darkness. Clipclap was wandering farther off than Teddy liked and he jumped up and hurried after his animal. As he caught him Teddy saw something on the ground a little way off. It was something round and black, and, now that the moon had come up, he could see more plainly.'\n",
      " b\"Janet took the pony's reins, and her brother walked toward the bundle. He could see now that it was something wrapped in a blanket, and as he came closer he saw that the blanket was one of the kind the cowboys at Uncle Frank's ranch carried when they went out to spend the night on the prairie.\"\n",
      " b'\"I spect so,\" her brother answered. \"I don\\'t know the way back to the ranch house. We can\\'t even find the rocks. We\\'ll stay here all night. It isn\\'t cold, and now we have a blanket we can wrap up in it like the cowboys do. And we\\'ve something to eat and drink.\"'\n",
      " b\"And so the animals had. Teddy and Janet slipped from their ponies' backs at the edge of the stream and then Star Face and Clipclap took long drinks. Ted emptied the canteen, filled it with the cooler water, and he and Janet drank again. Then they felt much better.\"\n",
      " b'Then, throwing the reins over the heads f their ponies, and knowing the animals would not stray far, Ted and Janet, taking another drink from the canteen, rolled up in the blanket and went to sleep on the prairie just outside the hidden valley that held a secret of which they did not even dream.'\n",
      " b'\"Oh, lots of little things might happen,\" said Aunt Millie. \"The children may have ridden farther than they meant to. It\\'s such a nice day for riding you couldn\\'t blame them for going. Or one of their ponies may have gone lame and have to walk slowly. That would make them get here late.\"'\n",
      " b'\"It\\'s a stream of water quite a way off,\" Baldy answered. \"It isn\\'t on our ranch, and we don\\'t very often go there. But if the Curlytops\\' ponies were thirsty in the night they might go to Silver Creek, even if Jan and Ted didn\\'t want them to. I think the ponies went the nearest way to water.\"'\n",
      " b'\"That\\'s just what I mean! These are the horses and cattle the Indians drove away. The Redmen put the animals in this valley and made a fence at this end so they couldn\\'t get out. They knew the horses and cattle would have water to drink and grass to eat, and they\\'d stay here a long while -- until the Indians would have a chance to drive \\'em farther away and sell \\'em.'\n",
      " b'\"Yes, that\\'s just what they did. I never thought of this valley, though I saw it quite a few years ago. I\\'ve never been here since. The Indians knew it would be a good place to hide the horses they stole, and we might never have found \\'em if it hadn\\'t been for you Curlytops.\"'\n",
      " b'And Baldy was right. Some hours after the Curlytops were back at Ring Rosy Ranch, in rode Uncle Frank and the others. They had not found what they had gone after, and you can imagine how surprised they all were when told that Ted and Janet had, by accident, found the lost cattle and horses in the hidden valley.'\n",
      " b\"That afternoon the stolen horses and cattle were driven in from the hidden valley; so the Indians did not get them after all. And a little later some soldiers came to keep guard over the Redmen so they could not again go off their reservation to make trouble. All of Uncle Frank's animals, except a few that the Indians had sold, were found, and the Curlytops were the pride of Ring Rosy Ranch as long as they remained there.\"\n",
      " b'\"Wha -- what\\'s matter?\" sleepily mumbled little Bunny Brown, making his words all run together, like molasses candy that has been out in the hot sun. \"What\\'s the matter, Sue?\" Bunny asked, now that he had his eyes open. He looked over the side of his small bed to see his sister standing beside it. She had left her own little room and had run into her brother\\'s.'\n",
      " b'Bunny Brown was a great one for asking questions. So was his sister Sue; but Sue would often wait a while and find things out for herself, instead of asking strangers what certain things meant. Bunny always seemed in a hurry, and his mother used to say he could ask more questions than several grown folks could answer.'\n",
      " b'\"We\\'ll take both!\" exclaimed the blue-eyed, chubby little chap. Then he began to dress. Sue, who had gone back into her own little room, had almost finished putting on her clothes, but, as her dress buttoned up the back, she had to come in and ask Bunny to fasten it for her. This he was ready to do as soon as he had pulled on his stockings and little knickerbockers.'\n",
      " b\"The children went to the dining room, where the table was set for breakfast, and Sue was cutting off a rather large slice from a cake she had found in the pantry, while Bunny was putting twice as much butter on a slice of bread as was needed, when their mother's voice exclaimed:\"\n",
      " b'\"Oh, you children!\" she said, when she had wiped the tears from her eyes with the corner of her apron. She was not exactly crying, you know. Only she laughed so hard that tears came into her eyes. \"You queer, dear little children!\" she said. \"What are you going to do next?\"'\n",
      " b'\"No, no! You musn\\'t give away my cake like that,\" said Mrs. Brown. \"Now listen to me. It will be hours before Aunt Lu will get here. Then, perhaps, I may take you to the station to meet her. But now I must dress you right and give you your breakfast. Papa had his some time ago, as he had to go down to the bay to see about some boats. I wondered why you were getting up so early. Now put back the bread and cake and wait until I give you something to eat.\"'\n",
      " b'Bunny Brown and his sister Sue lived with their father and mother, Mr. and Mrs. Walter Brown, in the town of Bellemere. That town was on Sandport Bay, which was part of the Atlantic Ocean, and the bay was a good place to catch fish, lobsters, crabs and other things that live in salt water.'\n",
      " b'Mr. Brown was in the boat business. That is he owned many boats, some that sailed, some that went by steam or gasoline, and some that had to be rowed with oars. These boats he hired out, or rented, to fishermen, and others who had to go on the bay, or even out on the ocean, when it was not too rough.'\n",
      " b\"Mr. Brown had a number of men to help him in his boat business; and one of the men, or, rather, an extra-large size boy, was Bunker Blue, of whom Bunny and Sue were very fond. And Bunker liked the two children' fully as much as they liked him. He often took them out in a boat, or went on little land-trips with them. Mr. and Mrs. Brown did not worry when Bunny and Sue were with Bunker.\"\n",
      " b'The two Brown children were good company for each other. You seldom saw Bunny without seeing Sue not far away. They played together nearly all the while, though often they would bring other children to their yard, or would go to theirs, to play games, and have jolly times. Bunny was a boy full of fun and one who sometimes took chances of getting into mischief, just to have a \"good time.\" And Sue was not far behind him. But they never meant to do wrong, and everyone loved them.'\n",
      " b\"Uncle Tad lived with the Browns. He was an old soldier, rather stiff with the rheumatism at times, but still often able to take walks with the children. He was their father's uncle, but Bunny and Sue thought of Uncle Tad as more their relation than their father's.\"\n",
      " b\"In the distant city of New York lived Miss Lulu Baker, who was Mrs. Brown's maiden sister, and the Aunt Lu whom the children were so eagerly expecting this morning. She had written that she was coming to spend a few weeks at the seashore place, and, later on, she intended to have Bunny and Sue and their mother visit her in the big city. Bunny and Sue looked eagerly forward to this. But just now they wanted most to go to the depot, and watch for the train to come in, bringing dear Aunt Lu to them.\"\n",
      " b\"Bunny and Sue went out in the yard, where they had a little play-tent, made of some old pieces of sails from one of Mr. Brown's boats. It was a warm spring day, and, as Bunny had said, there was no kindergarten school for them to go to, as it had closed, to allow a new roof to be put on the school building.\"\n",
      " b'\"Here, come back!\" cried Bunker, reaching out a hand to catch Sue. He was afraid she might go too near the train. But he was too late. Sue raced forward, and then, suddenly, she slipped and fell right into a puddle of water, left from a rain-storm the night before. Down into the muddy pool went Sue, all in her clean white dress.'\n",
      " b\"Aunt Lu saw what had happened, and, before any one else could reach Sue, she had picked up the little girl, in whose eyes were tears all ready to fall. And with her handkerchief Aunt Lu wiped the tears away. As she did this Bunny saw a ring on his aunt's hand -- a ring with a stone that sparkled like snow in the sun -- red, green, golden and purple colors.\"\n",
      " b'\"That\\'s very kind of you,\" his aunt remarked. \"We\\'ll be all right soon. Bunker, will you see after my trunk, please?\" she asked as she gave him the brass check. \"It can be sent up later,\" she went on, \"as I guess there is hardly room for it in the pony cart.\"'\n",
      " b'\"Well, Sue,\" she went on, as she finished scrubbing away at the muddy dress. \"I think that is the best I can do. It will need washing to make it clean again. But here comes Bunker with the pony cart, so we will start for your house. Your mother will be wondering what has become of us.\"'\n",
      " b\"Aunt Lu had been on a visit to the Brown's several times before, and as she sat in the pony cart with the children, with Bunker driving, she bowed to several persons whom she knew and who knew her. There was Mr. Sam Gordon, who kept the grocery, Jacob Reinberg, who sold drygoods and notions, and little Mrs. Redden, who kept a candy and toy store.\"\n",
      " b'\"Oh, yes, let\\'s take her down to the dock and see the fish boats come in!\" exclaimed Sue, for this was one of their delights. Some of the boats were those which the fishermen hired from Mr. Brown, and it was at his dock, where he had an office, that the boats landed, the fish being taken out, put in barrels, with ice, and sent to the city.'\n",
      " b'\"No, Bunny, they\\'re not in yet, but maybe they will be coming soon after we get to the dock,\" Bunker answered. And so it happened. Bunny and Sue went into their father\\'s office for a moment, to tell him that Aunt Lu had arrived, and then, with Bunker to look after them, they went out on the end of the dock.'\n",
      " b'Soon one of the big fish boats came in. It was loaded with several kinds of fish, some big flat ones, white on one side, and black on the other. These were flounders. There were some blue fish, large and small, and some long-legged \"fiddler\" crabs. But they were not the kind that is good to eat.'\n",
      " b'Lobsters have two big claws, and a number of little ones, and with these claws they walk around, backward, on the bottom of the ocean or bay, and pick up things to eat. In some inland rivers and streams there are what are called crayfish, or crabs. They are very much like lobsters, only, of course, a lobster is much larger.'\n",
      " b'The lobster was still alive and the fisherman picked it up just back of the big, pinching claws, so he would not get nipped, and put the lobster in a basket for Mr. Brown to carry. Bunny and Sue leaned over, looking at the green shellfish, when a voice behind them asked:'\n",
      " b'\"Pooh! I\\'m not afraid of him,\" George declared. \"I\\'ll let him pinch this stick,\" he went on, picking up one, and holding it out toward the lobster, which was slowly waving its \"feelers\" to and fro, and moving its big eyes, that looked like shoe buttons sticking out from its head.'\n",
      " b'Bunker did not stop to say: \"I told you so!\" He took out his big knife, and put the blade between the teeth of the lobster\\'s claw, forcing it open so George could pull out his finger. Then, with a howl of pain and fright, the boy ran home. He was not much hurt, as a lobster can not shut his claws very tightly when out of water. Just as does a fish, a lobster soon dies when taken from the ocean.'\n",
      " b\"A lobster's claw, I might say, is filled with meat that is very good to eat. When the lobster is boiled and the meat picked out with a fork, the claw is hollow. It is shaped just like the nose of Mr. Punch, with a sort of hook on the end of it, where the claw curves downward. Bunny and Sue often played with empty lobster claws.\"\n",
      " b'\"An engagement ring, my dear,\" said Sue\\'s mother, \"is a ring that means a promise. A very dear friend of Aunt Lu\\'s has promised to marry her, and he gave her the diamond ring to be a sort of reminder -- a most beautiful present. Now we must help her find it.\"'\n",
      " b'But it was not so easy to do that as it was to say it. They looked all over the kitchen -- on the floor, under the table, among the dishes, the pots and pans -- but no diamond ring could be found. Papa Brown came in from the front porch, where he had been reading the evening paper, and he helped search, but it seemed of no use.'\n",
      " b'They did so, looking in the dish that held the chopped-up bits of lobster meat, but no diamond ring was to be found. Then the floor was looked over again, most carefully, the empty dishes were turned upside down in the hope that the ring might drop out of one of them. But it did not.'\n",
      " b'But even after supper, the ring was not found. The whole family searched. Aunt Lu did not eat much supper, much as she liked lobster salad. She was too worried, I guess. Even Bunny did not feel like playing Mr. Punch with the big hollow lobster claw that fitted over his nose in such a funny way. Neither he nor Sue felt like making jokes when their aunt felt so unhappy.'\n",
      " b'They had each a penny that Aunt Lu had given them the day before, and now they wandered toward the little candy store kept by Mrs. Redden. She smiled at Bunny and Sue as they entered. Nearly every one did smile at the two children, who wandered about, hand in hand.'\n",
      " b\"Standing in front of a window was an elderly woman, wearing glasses which, just now, hung down over one ear. But, stranger still, there was a monkey, perched up on the pole over the window. One of the monkey's brown, hairy paws was entangled in the lady's hair, and the monkey seemed to be pulling hard, while the lady was screaming and trying to reach the fuzzy creature.\"\n",
      " b'Bunny Brown and his sister Sue hardly knew what to do. They just stood there, looking at the monkey pulling and tugging on the rather thin hair of Miss Winkler, and she, poor lady, could not reach up high enough to get hold of Wango, who was perched quite high up, on the window pole.'\n",
      " b'\"No, no!\" exclaimed Miss Winkler, as she heard what Bunny said. \"You musn\\'t go near him, Bunny. He might bite or scratch you. He is very bad and ugly to-day. I don\\'t know what ails him. Stop it, Wango!\" she ordered. \"Stop it at once! Come down from there, and stop pulling my hair!\"'\n",
      " b'Wango was very tame, however. The way he acted, after he saw the good things to eat, would have made anyone think he was always kind and gentle. For he carefully took the peanuts from Bunny in one paw, and a caramel from Sue in another, and then, making a bow, as the old sailor had taught him, the mischievous monkey scrambled into his cage in one corner of the room.'\n",
      " b'\"I don\\'t know, child,\" the elderly lady answered, as she began to coil up her hair. \"He is usually good, though he minds my brother better than he does me. When Jed was here, a while ago, he was playing with Wango out in the room, and, I suppose, when he put the saucy creature back in the cage, the door did not fasten well.'\n",
      " b'\"I don\\'t know what I would have done if you children hadn\\'t come along,\" went on Miss Winkler, \"for I had called and called, and no one heard me. I\\'ll make Jed put a good lock on the monkey-cage after this. Now come out to the kitchen and I\\'ll give you each a cookie.\"'\n",
      " b'The front door was open a little way, as the two children could see as they went up the walk. Bunny and Sue knew every house in that part of town, and also knew the persons who lived in them. All the neighbors knew the children, making them welcome every time they saw them.'\n",
      " b'\"Oh, but sometimes they don\\'t want us to make a noise,\" went on Sue. \"And if we were here all alone we could yell and holler, and slide down the banister, all we wanted to. Let\\'s slide down now,\" she said, as she went to the head of the stairs, and looked at the long, smooth hand-rail.'\n",
      " b'It did not take much to cause Bunny to change his mind or his plans when there was any fun to be had. For a while he forgot about looking for red paint to put on his face to make him look funny when he played Mr. Punch, with the hollow lobster claw on his nose. Just now the joy of sliding down the banister rail seemed to be the best in the world.'\n",
      " b'\"Now it\\'s my turn,\" Sue said, and down she came. Though she was a girl Sue could slide down a rail almost as well as could Bunny. In fact, she had played with her brother so much that she could do many of the things that small boys do. And Bunny surely thought that Sue was as good a chum as any of his boy playmates.'\n",
      " b'\"Now it\\'s my turn again!\" exclaimed the little blue-eyed chap, as he went up the stairs, his feet making a loud noise in the empty house. For some time Bunny and Sue played at sliding down the banister rail, and then Bunny remembered what they had first come into the house for.'\n",
      " b'\"We\\'ll pay him for it, if he wants money,\" Bunny replied, as though he had plenty. \"Mother or Aunt Lu will give us pennies soon,\" he said, \"and I can give the man mine. I only want about a penny\\'s worth of red paint Come on, we\\'ll go out, Sue, and get some.\"'\n",
      " b'Of course Bunny and Sue could not read, though the little boy knew some of his letters. So when he said \"read\" he meant look at the pictures. The books were some old magazines that the family, in moving away from the house, had left behind. Bunny and Sue made each a little pile of the paper books for seats and then they sat there looking at the pictures in another pile of magazines on the floor beside them.'\n",
      " b'Bunny stood up and looked. He had fallen on a pile of cloth bags which the painters had left inside the house. It was lucky for Bunny that the bags were there, or he might have been badly bruised. As it was he and Sue were not hurt, and, having picked themselves up, and brushed off their clothes, they were ready to go back home.'\n",
      " b'\"Maybe I can open a window,\" Bunny said. But he was not tall enough to reach more than past the window sill. The middle of the sash was far away, and he could see that the catch was on. If there had been a chair in the house, perhaps Bunny might have stood on it and opened a window, but there was none.'\n",
      " b'\"Why, when you didn\\'t come back your mother was worried,\" the old soldier said. \"So your Aunt Lu started out one way after you, and I went the other. As I passed this old house I saw a blue ribbon down by the gate and I thought it looked like yours, Sue. So I thought you might have come in here.\"'\n",
      " b'And my, how Bunny and Sue were kissed and cuddled by their mother and Aunt Lu when Uncle Tad brought them back! \"I was beginning to be afraid,\" said Mrs. Brown, \"that you had gone down to the boat-dock, after I told you not to, and I was going to have your father and Bunker Blue look for you.\"'\n",
      " b'For a few days after this Bunny and Sue did nothing to make any trouble. They went on little trips with Aunt Lu, showing her the many wonderful sights at the seaside. With her they watched the fish boats come in, and once they went sailing with her and their mother, Bunker Blue taking charge of the boat. They gathered pretty shells and pebbles on the beach and had many good times.'\n",
      " b\"Not far from the Brown's house was a small river that flowed into the bay. Part of the Brown land was right on the edge of this river and at a small dock Mr. Brown kept, tied up, a rowboat which he sometimes used to go fishing in, or to go after crabs, which are something like lobsters, only smaller. They are just as good to eat when they are cooked, and they turn red when you boil them.\"\n",
      " b'Neither of the children meant to do wrong, for they thought it would be all right to sit in the boat as long as it was tied fast. So into it they climbed. Then such fun as they had! They took sticks and made believe to row. They tied their handkerchiefs on other sticks and pretended to be sailing. They rocked the boat gently to and fro, and Bunny called this \"being out in a storm.\"'\n",
      " b'Bunny Brown and his sister Sue really were sailing down the river and the boat was bobbing up and down and swinging from side to side, for it was not steered. And it was not exactly \"sailing\" either, for it was only a row-boat and there was no sail to hoist.'\n",
      " b'\"Let\\'s look,\" proposed Sue, so the two children looked under the boat seats and lifted the oars over to one side. Sometimes they were allowed to go with their father or mother for a row or sail, and, once in a while, Mrs. Brown would take with her some sandwiches or cake for a little lunch. Bunny and Sue thought something to eat might have been left over since the last time, but there was nothing.'\n",
      " b'\"I have a piece of string,\" and Sue put her chubby hand in her pocket. She had had her mother sew two pockets in her dress, almost like the ones Bunny had in his little trousers. For Sue said she wanted to carry things in her pockets, just as her brother and the other boys did.'\n",
      " b'Bunny had the piece of string untangled now and he bent the pin into a sort of hook. All this while the boat was slowly drifting down the river, but Bunny Brown and his sister Sue had talked so much about fishing that they had not noticed where they were going. They were not so frightened as they had been at first.'\n",
      " b'\"I could give you a button from my dress,\" Sue said. \"One\\'s almost off, and I could pull it the rest of the way. Only I haven\\'t another pin to fasten me up with. This is an old dress, anyhow. That\\'s what makes it have one button gone and another almost off,\" she explained.'\n",
      " b'\"Never mind. Don\\'t pull off the button, Sue,\" Bunny said. \"I guess it wouldn\\'t be heavy enough to sink. Maybe I can find a regular sinker. Oh, yes, here\\'s one!\" he cried, as he picked up from the bottom of the boat a piece of lead. It had been dropped there when Mr. Brown, or perhaps Bunker Blue, had used the boat for fishing a few days before.'\n",
      " b'\"This will be just the thing!\" cried Bunny, as he fastened it to his line. \"Now I can fish real,\" and he tossed the bent pin over the side of the drifting boat into the water. The bent pin sank out of sight, and both children watched eagerly, wondering how long it would be before they would catch a fish.'\n",
      " b'There were a number of islands in the river, some small and some larger, and it was at one of the larger ones that Bunny and Sue now found themselves. Their boat swung around in the shallow water, and did not move any more. It was fast aground on the edge of the island.'\n",
      " b\"Bunny's father was in the boat business and the little fellow had often heard how needful it was to tie boats fast so they would not drift away or be taken out by the tide. So it was one of the first things he thought of when he and Sue landed on the island.\"\n",
      " b'\"Guess I\\'ll have to fish without any bait,\" he said, after a while. But, as I suppose you all know, fish hardly ever bite on an empty hook, especially when it is made from a bent pin; so, after he had dangled the line in the water for quite a while, Bunny said:'\n",
      " b'However Sue did not mind fishing without any worms on the pin-hook, and she sat down on a log, near the water and let the line dangle in it, while Bunny walked about the island. He had never been on this one before, though there was a larger one, farther down the river, where he and his sister Sue had often gone on little picnics with their mother and father.'\n",
      " b'Walking back a little way from the edge of the water, Bunny saw a place where a tangle of vines, growing over an old stump, had made a place like a little tent, or bower. All at once Bunny remembered a story his mother had read to him. Back he ran to where Sue was fishing.'\n",
      " b'\"But we aren\\'t shipwrecked,\" Sue said. Living near the sea the children had often heard of shipwrecks, and had once seen one, when a big sail boat had beep blown up on the beach and broken to pieces by the heavy waves. The sailors were taken off by the life-savers. \"We\\'re not shipwrecked,\" said Sue. \"There\\'s our boat all right,\" and she pointed to the one in which they had gone adrift.'\n",
      " b'\"We\\'ll have to pretend that, too. You\\'ll be my man Friday, and we\\'ll go to live in the little tent over there,\" and Bunny pointed toward the leafy bower he had found. \"And you can be colored, too, if you want, Sue,\" he said. \"You could rub some mud on your face and hands.\"'\n",
      " b'\"Yes,\" said Bunny. \"Now I\\'ll go over to my cave -- we\\'ll call the place where the vines grow over the stump a cave,\" he went on, \"and I\\'ll be there just like Robinson Crusoe Was in the cave on his island. Then I\\'ll come out and find you, all blacked up with mud, and I\\'ll call you Friday.\"'\n",
      " b'Then the two children played the Robinson Crusoe game; that is, as much of it as Bunny could remember, which was not a great deal. But they had good fun, walking about the island, and going into the green vine-bower now and then to get out of the sun, which was very hot.'\n",
      " b'Bunny had often seen his father, or Bunker Blue, or sometimes his mother, row a boat, so he knew how it was done. But he knew the oars in the boat in which he and Sue had gone adrift were heavy, and he was not very strong, though a sturdy little chap for his years.'\n",
      " b\"The dog jumped about the children, but he kept nearer to Sue. Maybe he thought she belonged to him, now that he had pulled her from the water. Perhaps he had saved Sue's life, though the little girl might have gotten out herself, or Bunny might have pulled her from the water.\"\n",
      " b'Getting into the boat was easy enough for Bunny and Sue, for they only had to step over the side, the boat being partly on shore. And the dog jumped in after them. He seemed very glad Indeed that he had found two such nice children to love, and who would love him.'\n",
      " b'\"Bunny! Sue!\" called the voice again, and the big dog barked. Perhaps he was also glad that \"somebody\" had come for him, as glad as were the children. But, though Bunny Brown and his sister Sue looked all about, they could see no one. Then, all of a sudden, Sue thought of something.'\n",
      " b'Bunny was also glad, and a few seconds later, while the dog kept on barking, and running here and there, Bunny and Sue raw, coming around the end of the island, a boat, and in it was Jed Winkler, the old sailor who owned Wango, the monkey. Only, of course, the old sailor did not have the monkey with him this time.'\n",
      " b'\"Yes, and I guess your folks will be glad to see YOU!\" answered the old sailor. \"They\\'ve been looking all over for you, and only a little while ago I noticed that your boat was gone. I thought maybe you had gone on a voyage down the river, so I said I\\'d come down and look, as far as the island, anyhow. And here you are!'\n",
      " b'\"And the dog did pull her out, and we\\'re going to keep him,\" went on Bunny. \"And will you take us home, Mr. Winkler? \\'Cause we\\'re hungry, and maybe our dog is, too, and it\\'s getting dark, and we couldn\\'t make our boat go, even if we did hitch the dog up to it.\"'\n",
      " b'\"Bless your hearts!\" Mrs. Brown cried. \"She was very glad the children had been found, and Mr. Brown told Bunny and Sue they must not get in the boat again, unless some older person was with them, even if the boat was tied to the dock. Then it was supper time, and the big, shaggy dog ate as much as Bunny and Sue together, which showed how hungry he was.'\n",
      " b'For two or three days after they had gone off in the boat, Bunny Brown and his sister Sue did not go far from home. They remained about the house, playing different games with some of the children who lived near them. Now and then they would go down the street with Aunt Lu, or to the dock, to see the fish boats come in. And, often, as she walked along, Aunt Lu would look down at the ground.'\n",
      " b\"Splash, the big dog, proved to be very gentle and kind. He seemed to love the two children very much, and went everywhere with them. No one came to claim him. There was only one place Bunny and Sue could not take him, and that was to Mr. Winkler's house, and it was on account of the monkey.\"\n",
      " b'\"We won\\'t,\" promised Bunny and Sue. So, whenever they paid a little visit to their friend, the old sailor, Splash was chained outside the gate, and the poor dog did not seem to understand why this was done. But he would lie down and wait until Bunny and Sue came out. Then how glad he was to see them!'\n",
      " b\"But Bunny and Sue did not buy the toy balloons. They were on their way to get them, with Splash, the dog, walking along the street behind them, when a trolley car came along. The trolley ran from Bellemere, where Bunny and Sue lived, to Wayville, the next town. In Wayville lived Uncle Henry, who was a brother of Mrs. Brown's.\"\n",
      " b'Hand in hand, never thinking that it was in the least wrong, Bunny and Sue ran for the trolley. The conductor, though perhaps he thought it strange to see two such small children traveling alone, said nothing, but helped them up the high step. Often the people of Wayville or Bellemere would put their children on the car, and ask the conductor to look out for them, and put them off at a certain place. But no one was with Bunny and Sue.'\n",
      " b'Bunny and Sue leaned back in the trolley car seat, and felt very happy. They loved to ride and travel, and they did not think they were doing wrong to take a trolley ride without asking their mother or father. If they had asked, of course, Mrs. Brown would not have let them go alone. But that is the way matters generally went with Bunny and Sue.'\n",
      " b'Faster and faster went the trolley car. Bunny looked at Sue and smiled, and she smiled at him. The conductor came along the step of the car, which was an open one, to collect the fares. Bunny and Sue each handed him a five cent piece, and he handed them each back two pennies.'\n",
      " b'\"All right,\" agreed the conductor. \"I\\'m sorry, for I\\'d like to do you the favor, but I\\'m not allowed.\" He rang the bell, and the car slowed up. Splash barked joyfully, for he Was very tired from running after his little friends, who went so fast and so far ahead of him.'\n",
      " b'\"Here, youngsters,\" went on the trolley man, while Splash rushed up to Bunny and Sue, barking happily, \"here, youngsters, take your money back. You didn\\'t ride three cents\\' worth, hardly, and I\\'ll fix it up all right with the company. You\\'d better take the next car back home. Your dog can find his way all right.\"'\n",
      " b'And, as it was not much more fan than looking at a stone, to watch the closed-up turtle, Bunny and Sue soon grew tired of watching the slow-moving creature. Splash, too, seemed to think he was wasting time barking at such a thing, so he ran off to find something new.'\n",
      " b'But the road, too, seemed to have disappeared. Bunny and Sue went this way and that, but no road could they find. They listened, but they could not hear the clanging of the trolley car gong. It was very still and quiet in the woods, except, now and then, when Splash would run through the dried leaves, looking for another mud-turtle, perhaps.'\n",
      " b'Back they went. But the next path they tried was no better than the first one. It came to an end in a swamp, in which, on logs, were a number of big frogs and turtles, that jumped, or fell in, with much spattering of water as the children and the dog came near.'\n",
      " b'It was easy to get home now. All the while Bunny and Sue had been only a little way from the road which led to their home, but the trees were so thick they could not find the right path. And Splash had never thought his two little friends were anxious to get home, until Bunny had told him so. Then he led them.'\n",
      " b'On walked Bunny Brown and his sister Sue, happy now that they were no longer lost. Splash seemed to think he had done all that was needed, for now he ran here, there, everywhere -- across the road, back and forth, trying to find something with which to amuse himself. He no longer watched to see that the children followed him. He must have known that they were on the right road at last -- that he had led them there.'\n",
      " b'Bunny Brown was out in the yard, a few days after the funny trolley ride, digging a hole. Bunny had heard his father talk about a queer country called China, which, Mr. Brown said, was right straight down on the other side of the world, so that if one could possibly dig a hole all the way through the earth, one would come to China.'\n",
      " b'A little while before Bunny started to dig the hole his sister Sue had been playing in the yard with her dolls. But, somehow or other, Bunny forgot all about Sue now. He was taking the dirt out of the hole with his sand shovel when his mother came to the door and called:'\n",
      " b'\"To look for Sue,\" explained Mrs. Brown. \"She seems to have wandered off somewhere all by herself, and I don\\'t want her lost again. It isn\\'t so bad when Bunny and Sue both get lost,\" the mother went on, \"for they can help find one another. But if Sue is all alone she may get frightened.\"'\n",
      " b'\"So I got this long chain, and I\\'m going to fasten one end of it to a collar, to go around Wango\\'s neck, and tie the other end of the chain to the porch railing, so he can\\'t get away. Then I can let Wango stay outdoors when the weather is good, and he will get well. At night I will put him in his cage again.\"'\n",
      " b\"Mr. Winkler went on down the street, rattling the monkey-chain, and Mrs. Brown, no longer worried about Sue, turned back into the yard, while Bunny hurried on, as fast as his little legs would take him, to Sadie West's yard, where he found his sister and several of their chums having a good time.\"\n",
      " b'Bunny turned and ran back. Looking through the fence that was built around the lot, he saw a big goat, with long horns, walking toward Sue. And the little girl, who had picked a few daisies, was standing in the tall grass, too frightened to run back and crawl through the fence.'\n",
      " b'But, after he had said this, Bunny did not know exactly what to do. He did not know much about goats, and this was a big one, with long, sharp horns. The goat belonged to an Italian family in town, and the Italian man used to ask those who owned vacant lots to let his goat go into them and eat the grass. That was how the goat happened to be in this lot. If Sue had known the animal was there, she would not have taken the short cut, but would have gone, with her brother, along the street.'\n",
      " b'Afterward Bunny Brown and his sister Sue learned that the goat was a very kind one, and used to playing with children. It would not have hurt Sue at all, and the reason it walked up to her was because it thought she was going to feed it, as the little Italian children often did. So Bunny and Sue had their fright for nothing, though of course, at the time, Bunny thought the goat might hurt his sister.'\n",
      " b'The day of the party for Splash, the dog, came at last, though Bunny Brown and his sister Sue were so anxious for the time to arrive that it seemed very long indeed. But everything comes if you wait long enough, so they say, and finally the time for the party came.'\n",
      " b'\"We can make kites, and fly \\'em,\" Bunny said, and so this was what he and the boys at the party would do while the girls were playing with their dolls. So Bunny was now glad to notice, as he looked from the window, that the wind was blowing; not too hard, but enough to fly kites.'\n",
      " b'Splash, the dog, seemed quite proud of the big bow that Sue tied on his neck, to make him look pretty. But Splash did not care so much for the harness that Bunny made. The little boy took some ropes and straps, and tied them about the dog\\'s neck and front legs. Then some ends of the ropes were made fast to the little express wagon, and Bunny got in it, calling to Splash to \"giddap!\" That was the way Grandpa Brown made his horses go, and so, of course, a dog ought to go when you said that to him.'\n",
      " b'While they were doing this Bunny was trying to make another harness for Splash, so the dog could pull the express wagon with the little boy in it. But Bunny did not have very good luck, or else Splash pulled too strongly, for one harness after another broke, until Bunny gave up.'\n",
      " b'The dog, who was gnawing the bone Sadie had brought him, looked up and wagged his tail. He must have thought it was fine to have so many good things to eat, even though he did not understand about the party. He sniffed at the dog-biscuit, which is a sort of cake, with ground-up meat, and other good things in it that dogs like. Then Splash would gnaw a little on the bone, and, afterward, nibble at the hard biscuit.'\n",
      " b\"Soon after this a number of the boys and girls came. There were ten girls and six boys, though ten boys had been invited. But though all the girls came to the party given for Splash, all the boys did not. It often is that way at parties; isn't it? More girls than boys. But the boys don't know what fun they sometimes miss.\"\n",
      " b'One after the other they played the games, running about on the grassy lawn, and having great fun. Splash dug a hole and hid his bone, after gnawing on it as long as he cared to. He ate all the dog-biscuit, and then Bunny got a ball which Splash would run after when it was thrown.'\n",
      " b'Of course the boys did not want anything like that to happen, so they said they would wait. Down they sat at the tables, the boys at theirs and the girls at the one made ready for them. Aunt Lu, Mrs. Brown and the cook passed the good things, and, for a time, there was not much talking done. The children were too busy eating.'\n",
      " b\"Perhaps this had made George rather angry. At any rate, when the children were thanking Aunt Lu for the nice story she had told them, there was suddenly tossed over the fence, right into the midst of them, a paste-board shoe box. It fell near Bunny's feet, and he jumped back, he was so startled.\"\n",
      " b\"And that is what was in the box that George had tossed over the fence into the midst of the party-guests -- a box of big, green frogs that he had caught at the mill pond. George wanted to scare Bunny and Sue for not asking him to their dog's party. But the little scare was soon over, and the children only laughed at the frogs.\"\n",
      " b'There were enough tarts for each one to have another, and, when they had been passed around, after a lively game of Puss-in-the-corner, the party was over. Everyone said he had had a fine time, and when Bunny Brown and his sister Sue asked their guests to come again, each one said:'\n",
      " b'Splash did not say anything, of course. But he wagged his tail, and walked over to where he had buried the bone Sadie had brought him. So I guess Splash did like the party as much as did the children. And he had several good things to eat, which, after all, is what most parties are for.'\n",
      " b'One day Aunt Lu read a story from a magazine to Bunny and Sue. It told about some boys who, on a warm day, set up a lemonade stand under a shady tree, in front of their house, and sold lemonade at a penny a glass. The money they made they sent to a church society, that took poor children out of the hot city to the cool country for a week or so.'\n",
      " b'\"Old Miss Hollyhock,\" as she was called, was an aged woman who lived in a little house down near the fish dock. Her husband had been a soldier, and when he died the old lady was given money from the government -- a pension, it was called. Still she was very poor, and she was called \"Old Miss Hollyhock,\" because she had so many of those old-fashioned hollyhock flowers in her garden. Her real name was Mrs. Borden.'\n",
      " b'Mrs. Brown said she did not mind if Bunny and Sue did this. A number of the children in Bellemere had done this, at different times, and some of the larger boys and girls had made even as much as five dollars, giving the money to the church, or to the Sunday school.'\n",
      " b'So she gave the children the ice, sugar and lemons, and they made a big pitcher of lemonade. Bunny set up a box under a tree in front of the house, covering the box with a clean white cloth. Then with the pitcher and glasses on a serving tray, he and Sue were ready for business.'\n",
      " b'And, as Bunny Brown and his sister Sue were standing near the box, it fell over on them, and the lemonade pitcher upset, and the lemonade in it splashed all over the little boy and his sister. The glasses bounced off into the grass, and the dog suddenly turned a somersault, and fell on top of Bunny, Sue, the box and the lemonade pitcher.'\n",
      " b'And now the dog stopped howling and barking, for he must have known that Bunny and Sue would be his friends, and he was not afraid any more. And that is the way they were when Aunt Lu and Splash, the big dog, came out to see how the two little lemonade sellers were getting along.'\n",
      " b\"Then Splash saw the little yellow dog in Bunny's arms, and the big dog went up to him, wagging his tail, while the two sort of rubbed noses -- you know the way dogs do instead of shaking hands, or paws, I suppose I should say, and right away they were friends.\"\n",
      " b'\"Oh, of course not! I know you wouldn\\'t do such a thing,\" returned his aunt. \"Here, little dog, I\\'ll cut it off for you,\" and she took her scissors out of her apron pocket, for she had been sewing just before coming out to look at the lemonade stand. \"I\\'ll cut it off for you,\" said Aunt Lu.'\n",
      " b'\"Of course not!\" laughed Aunt Lu. \"I meant I\\'d cut off the tin can. You poor little doggie! No wonder you were frightened. And now tell me all how it happened,\" she went on, as she snipped, with her scissors, the string around the little yellow dog\\'s tail. He seemed very happy to be free of the tin can.'\n",
      " b'But everything was all right, and not a glass was broken, for they fell in soft, grassy places. The lemonade was spilled, of course, a little of it going on Bunny and Sue. But they did not mind that. And, best of all, the little dog no longer had a tin can tied to his tail.'\n",
      " b\"This was only one of the games they played. There was a big spinning wheel up in the attic. It had belonged to Mrs. Brown's grandmother, and in the olden days, before yarn for socks and mittens was made by machinery, it was spun on a spinning wheel. This was a big wheel, as large as one on a wagon, but not so heavy. And it went around and around, very easily.\"\n",
      " b'Bunny and Sue would sit on a trunk, spin the wheel, and make believe they were in a trolley car. They would take turns being the motorman. Sometimes Bunny would have that place, while Sue would be the conductor, and again Bunny would collect the fare and let Sue spin the wheel.'\n",
      " b'Just beyond the corner there was a moving picture theatre, lately opened. Mrs. Brown and Aunt Lu had taken Bunny and his sister there once or twice, when there was a fairy play, or something nice to see, so Bunny and Sue knew what the moving pictures were like.'\n",
      " b'In front of the moving picture place were some big boards, and on them were pasted brightly colored posters, almost like circus ones, telling about the moving pictures that were being shown inside. There was a picture of a man falling in the water, and another of a railroad train. Bunny loved cars and locomotives.'\n",
      " b'No one seemed to notice them, perhaps because the place was dark, except where the brilliant pictures were dancing and flashing on the white screen. And no one heard Bunny and Sue, for not only did they walk very softly, but just then the girl at the piano was playing loudly, and the sound filled the place.'\n",
      " b'\"We\\'ll get up real close, and right in front,\" Bunny went on. Then he saw a little pair of steps leading up to the stage, or platform; only Bunny did not know it was that. He just thought if he and Sue went up the steps they would be better able to see. So up he went.'\n",
      " b'The screen, or big white sheet, on which the moving pictures were shown, stood back some distance from the front of the stage. And it was a real stage, with footlights and all, but it was not used for acting any more, as only moving pictures were given in that theatre now.'\n",
      " b'Sue followed Bunny up the steps. The pictures were ever so much clearer and larger now. She was quite delighted, and so was her brother. They wandered out to the middle of the stage, paying no attention to the audience. And the people in the theatre were so interested in the picture on the screen, that, for a while, they did not see the children who had wandered into the darkened theatre by the side door.'\n",
      " b\"By this time the piano player had stopped making music. She knew that something was wrong. So did the moving picture man up in his little iron box, and so did the usher -- that's the man who shows you where to find a seat. The usher came hurrying down the aisle.\"\n",
      " b'By this time the lights all over the place had been turned up, and Bunny and Sue could see the crowd, while the audience could also see them. Bunny blinked and smiled, but Sue was bashful, and tried to hide behind her brother. This made the people laugh still more.'\n",
      " b'\"I think so myself,\" laughed the usher. \"You can come some other time, youngsters. But bring your aunt, or your mother, with you; and don\\'t come in the side door. I\\'ll have to keep some one there, if it\\'s going to be open, or I\\'ll have more tots walking in without paying.\"'\n",
      " b\"There was much going on at Mr. Brown's, dock that day. Some boats were getting dressed up in new suits of sails, and others were being painted. Then, too, a number of fishing boats came in, well filled with different kinds of fish. Some had lobsters in them and there was one big one, with very large claws.\"\n",
      " b'They looked into the other fishing boats, and then Bunker Blue came along. As he had nothing much to do just then he took Aunt Lu and the children for a little ride in a motor boat, that went by gasoline, the same as does an automobile. Only, of course, a boat goes in the water, and an automobile runs on land.'\n",
      " b\"Mrs. Redden opened the glass show-case in which the candy was kept. As she reached in her hand, to take out the lollypops, Bunny and Sue, standing in front, saw a brown, hairy paw also put into the case. And the brown paw, which was close to Mrs. Redden's hand, caught up a bunch of lollypops and quickly pulled them out.\"\n",
      " b'Wango accidentally dropped one of the lollypops he held. He had so many in his paws that it was hard to hold them all. He quickly reached for the falling candy, but he accidentally hit a glass jar filled with jelly beans. It crashed down to the floor, spilling the candy beans all over.'\n",
      " b'Wango was a queer monkey in more ways than one. He liked to make mischief, or what others called mischief, though to him perhaps it was only fun. And he did not seem to like ladies. He would let boys and girls and men pet him, and make a fuss over him, but he would very seldom allow ladies to do this.'\n",
      " b'Miss Winkler, the sister of the sailor who had brought Wango from a far-off land, was one of the ladies the monkey did not like. But then she did not like Wango, and perhaps he knew this. And now it seemed that Wango was not going to like Mrs. Redden, who kept the candy shop.'\n",
      " b'Wango was certainly making very odd faces just then. But perhaps it was because he liked the taste of the lollypops. He had taken the paper off two of them, and had them both in his mouth at once, while his busy paws were peeling the wax covering off a third one.'\n",
      " b'\"Come down from there! Come down from that shelf!\" cried Mrs. Redden, reaching up and trying to touch the monkey with the broom. I think she did not intend to hit him hard, and, anyhow, a blow from a broom does not hurt very much. Mrs. Redden thought she simply must drive Wango down. He might spoil a lot of candy.'\n",
      " b'\"Have you seen anything of Wango?\" began Mr. Winkler, but there was no need for him to ask such a question. There was Wango, in plain sight, holding some lollypops in one paw, and in the other some jelly beans and coconut candies he had grabbed up from the floor. And in his mouth, with the stick-handles pointing out, were three other lollypops!'\n",
      " b'And where do you think he hid? It was in a queer place -- down in an empty rain-water barrel, that stood back of the house. Bunny climbed up into it by standing on a box, and, once inside, he crouched down on the bottom, where anyone would have had to come very close, and look over the edge, to see him. And there Bunny hid.'\n",
      " b'The cook came out to the back door, near which stood the empty rain-water barrel, into which Bunny had climbed to hide. She took from the open top a large towel which, a little while before, she had thrown over the barrel to dry, and, looking down in, she cried out:'\n",
      " b'And that was the treat Aunt Lu had made for the children. There were two plates of tarts, one with jam coming up through the three little round holes in the top crust, and others in which jelly showed. Both were very good. And the cool lemonade was good also.'\n",
      " b'It did not take Bunker long to make two handles, or \"shafts,\" as they are called, for Bunny\\'s wagon. Then he made a harness for the dog -- a harness strong enough not to break. One day, when all was finished, Splash was hitched to the wagon, and Bunny was given the reins. They went around the neck of Splash, for of course you can not put in a dog\\'s mouth an iron bit, as you can in that of a horse.'\n",
      " b'\"Oh, Bunny, let\\'s go out on the sidewalk, where it\\'s nice and smooth. It will be easier for Splash to pull us then.\" Bunny thought this would be fun, so he guided the dog out through the gate. The wagon did go more smoothly on the sidewalk, and Splash trotted a little faster.'\n",
      " b'\"Whoa! Whoa!\" cried Bunny, pulling on the reins. But Splash would not stop. Faster and faster he ran. He only wanted to see his little yellow dog friend again, and rub noses with him. But I guess the yellow dog was frightened when he saw the express wagon, with the two children in it, following after Splash.'\n",
      " b'Maybe the yellow dog thought the wagon was tied to the tail of Splash, as the tin can had once been to his own. And maybe the little yellow dog thought some one would now tie an express wagon to his tail. At any rate he ran on faster and faster, And Splash, who just wanted to speak to him, in dog language, ran on faster too.'\n",
      " b\"As the wagon rumbled past the house where lived Mr. Jed Winkler, the old sailor, who owned Wango, the monkey, came out to the front gate. I mean Mr. Winkler came out, not Wango, for he had been tightly chained, after the fun he had had in Mrs. Redden's candy shop.\"\n",
      " b'Out he ran from his yard to race after Splash, but there was no need for the old sailor to catch the big dog. For, just then, the little yellow dog stumbled, and turned a somersault. And before he could pick himself up, and run on again, Splash had caught up to him.'\n",
      " b'And as soon as the little yellow dog found that he was not going to be hurt, but that Splash was just going to be friends with him, why the two animals just sat down in the grass find rubbed noses and, I suppose, talked to each other in dog language, if there is any such thing.'\n",
      " b'Splash went back very slowly. Perhaps he was tired, or he may have been sorry that he had run so fast at first, and had upset the wagon. The yellow dog went off by himself, and he was glad, I guess, that he did not have to pull a wagon with two children in it. But Splash seemed to enjoy it.'\n",
      " b'Mrs. Brown and Aunt Lu had not seen the runaway, or they might not have wanted Bunny and Sue to take any more rides in the express wagon. But the two children had lots of fun the rest of the morning, riding up and down, and Splash acted very nicely, stopping when Bunny called \"Whoa!\" and going on again when the little boy said, \"Giddap!\"'\n",
      " b'For several days after that Bunny Brown and his sister Sue had many good times with their dog and express wagon. They gave their playmates rides up and down the sidewalk, and never once again did Splash run away. But then he did not see his friend, the little yellow dog, or he might have raced after him just as at first.'\n",
      " b'\"Yes,\" said Mrs. Gordon. \"One of my hens has strayed off by herself and is laying her eggs in a nest I can\\'t find. I\\'ve looked all over our yard for it, but perhaps it is in your barn,\" she went on to Mrs. Brown. \"And if it is, maybe Bunny and Sue could find it.\"'\n",
      " b\"Mrs. Brown and Aunt Lu were much surprised when Bunny Brown and his sister Sue came in, Sue all white and yellow from the eggs. But Sue's mother knew it was something that could not be helped, so she did not scold. She changed Sue's dress, and then she said:\"\n",
      " b\"When the grocery-store-keeper's wife saw Bunny and Sue coming over to her house she thought perhaps their mother had sent them on an errand, as Mrs. Brown often did. For the time Mrs. Gordon had forgotten about the hidden hen's nest. In fact, she had not thought that Bunny and Sue would really spend much time looking for it. So when Sue said:\"\n",
      " b'\"Well, I\\'m glad you found the nest, anyhow, if you did break the eggs,\" said the storekeeper\\'s wife. \"Maybe now my hen will not go over into your barn, but will make her nest in our coop, where she ought to make it. So it\\'s all right, Sue, and here are some cookies for you and Bunny.\"'\n",
      " b'That afternoon, when Sadie West, Helen Newton, Charlie Star and Harry Bentley came over to play with Bunny and Sue, they had to be shown the place in the hay where Sue \"found\" the eggs. One of Mr. Brown\\'s stable men had taken out the broken shells, for he did not want them to get in the hay that the horses ate. The inside of the eggs did not matter, for horses like them anyhow.'\n",
      " b'Sadie and Helen, who did not live far away, ran home and got their dolls. Sue brought out hers, and the girls had a nice time on the shady side of the porch. Mrs. Brown gave them some cookies, and some crackers, which were cut in the shapes of different animals, and with these, and some lemonade in little cups, Sue and her chums had lots of fun.'\n",
      " b'\"Pooh! I can climb a big tree, too,\" he said. He got down from the one he had picked out, and started up another. He watched how George put first one foot on a branch and then the other foot, at the same time pulling himself up by his hands. Bunny did very well until his foot slipped and went down in a hole in the tree, where the wood had rotted away, leaving a hollow place.'\n",
      " b'And that was what had happened. Bunny\\'s foot had gone so deep down in the hollow place of the tree, and the hollow was so small, that the little boy\\'s foot had become wedged fast. Pull as he did, he could not get it up. \"Wait -- I\\'ll help you!\" called George.'\n",
      " b'So Aunt Lu got ready to go back home. And as she walked about with Bunny and Sue, paying last visits to the fish dock, the river and the other nice places, Aunt Lu seemed sad. She looked down at the ground, and often glanced at her finger on which she had worn the diamond ring.'\n",
      " b'Bunny Brown and his sister Sue had often talked about giving a Punch and Judy show. They had often seen one, at picnics or at church sociables, and Bunny knew by heart a few of the things Mr. Punch had to say. He did not stop to think that perhaps he could not get behind the curtain, and make the little wooden figures do the funny things they were supposed to do. And he did not know where he could get the queer little doll-like figures.'\n",
      " b'\"That\\'s so,\" admitted Bunny, looking puzzled, \"We haven\\'t got a tent. But we can have the Punch and Judy show in our barn,\" he went on quickly, \"and you can stand at the door and take the money, and sell tickets -- that is, when you aren\\'t being Mrs. Punch.\"'\n",
      " b\"Bunker was just the best one Bunny could have thought of to help. For Bunker worked around Mr. Brown's boats, and could get pieces of wood, boards, nails and sail-cloth, to make a little curtain for the tiny theatre where Bunny would pretend to be Mr. Punch.\"\n",
      " b'The day after Bunny and Sue had thought of the plan to make Aunt Lu not so sad, by giving a little entertainment for her, the children went out in the barn to practise. Their playmates came over to help, though there was not much for them to do, since Bunny and Sue (and more especially Bunny) were to be the \"whole show.\"'\n",
      " b'Bunny and Sue had told their mother they were going to have a \"show\" out in the barn, but they did not say what kind, nor tell why they wanted it. But they had to say something, so Mrs. Brown would let them play there, and also let them take some of their old clothes, in which to \"dress-up.\"'\n",
      " b\"Bunny fixed the hollow lobster claw, with a string in a hole on either side of it, so he could tie it on his nose. Bunker bored the holes for him with a knife, and cut the claw so it would fit, and when Bunny put the queer red claw, shaped just like Mr. Punch's nose, on his face, the little boy was so funny that all his playmates laughed.\"\n",
      " b'In a few days Bunker Blue had the little theatre made, and as he brought it up to the Brown barn in a wagon, carefully covered over, no one could see what it was. George Watson had been asked to help, and he had made tickets for the play. The tickets, which George printed with some rubber type, read:'\n",
      " b'And several persons did buy them, paying real money for them. Bunny and the others said they were trying to help Old Miss Hollyhock, which was one reason for giving the show. The other was to make Aunt Lu feel more happy. And when the people heard what Bunny and Sue planned to do, they gladly bought one ticket, and some even more. Though not all of them would really go to the show.'\n",
      " b\"One day Bunny and Sue went down to Mrs. Redden's toy shop. She bought a ticket from them, and Sue and Bunny each bought a penny's worth of candy. Coming out of the store, the children saw an automobile, belonging to Mr. Reinberg, who kept the dry-goods store. He was just getting out of the automobile.\"\n",
      " b'So he and Sue got in the back part of the automobile, the door of which was open. The children sat up on the seat, waiting for Mr. Reinberg to come out of the post-office, but he stayed there for some time. Bunny and Sue thought it would be fun to sit down in the bottom of the car, and pretend they were in a boat. Down they slipped, making a soft nest for themselves with the robes, or blankets, which they pulled from the seat.'\n",
      " b'Mr. Reinberg came out of the post-office. He was in such a hurry that he never thought about Bunny and Sue\\'s having asked him for a ride. He just shut the door of the car, took his place at the steering wheel and away he went. He did not see the children sitting down in the bottom, partly covered with the robe. For Bunny and Sue, just then, were pretending that it was night on their make-believe steamer, and they had \"gone to bed.\"'\n",
      " b'Sue spoke so loudly that Mr. Reinberg, who was at the steering wheel, turned around quickly. Up to now Bunny and Sue had talked in such low voices, and the automobile had rattled so loudly, that the dry-goods man had not heard them. But when he did he turned quickly enough.'\n",
      " b'\"You\\'re not lost,\" Mr. Reinberg said, laughing again. \"You\\'re quite a way from home, though, for I have been going very fast. But I\\'ll take care of you. Now let me see what I had better do. I have to go on to Wayville, and I don\\'t want to turn around and go back with you youngsters. And if I take you with me your folks will worry.'\n",
      " b'The dry-goods man found a house in which there was a telephone, and he was soon talking to Mrs. Brown in her home. He told her just what had happened; how, almost by accident, he had taken Bunny and Sue off in his automobile. Then he asked if he might give them a longer ride, and bring them home later.'\n",
      " b'In three days more the Punch and Judy show would be held in the Brown barn. Everything was ready for it, Bunny had gone over his part again and again until he did very well indeed. Sue, also, was very, very good in what she did, so the other girls said. Sadie West, who was older, helped Sue.'\n",
      " b'By this time, of course, the grown folks knew that some sort of a show was going on in the Brown barn, and they had promised to come. And there were so many children who wanted to see what it was going to be like that Bunny and Sue did not know where they were all going to sit.'\n",
      " b'Then came the day of the show. Bunny was dressed up in some old clothes, and so was Sue. She did not put hers on, though, until after she had helped take tickets, and sell them, at the barn door. Then Bunker Blue took her place, and Sue dressed to help Bunny.'\n",
      " b'Mr. and Mrs. Punch had great times with the \"baby,\" which was the sawdust doll. Then Sue stooped down, out of sight, and turned herself into a make-believe policeman, by putting on a hat, made out of black paper, with a golden star pasted on in front. George Watson had made that for her. Up popped Sue, the pretend policeman, to make Mr. Punch stop hitting the sawdust doll baby.'\n",
      " b'Then Sue sang a little song, that Bunker had made up for her, and he played the mouth organ. And next Bunny and Sue sang together. The children thought it was fine, and the grown folks clapped their hands, and stamped with their feet, which is what people do in a real theatre when they like the play.'\n",
      " b'\"I see how it all happened,\" she said. \"That day when I was helping pick the meat out of the big lobster, my ring must have slipped from my hand, and fallen down inside the empty claw. It went away down to the small end, and there it was held fast, just as Bunny\\'s foot was caught in the hollow tree one day.\"'\n",
      " b'But, before they visited Aunt Lu, the two children had other adventures. I will be glad to tell you about them in the next book, which will be named: \"Bunny Brown and His Sister Sue on Grandpa\\'s Farm.\" In that you may read what the two children did in the country, how they had a long automobile ride, and how they saw the Gypsies.'\n",
      " b'\"This is very strange,\" said the sweet chap, rubbing his eyes again. \"Who ever heard of an egg with a window in it? I wonder if any one lives in that egg? It is not large enough for a house, of course; but still, some very little folk might stay in it. I\\'ll take a look through that window.\"'\n",
      " b'The Candy Rabbit gave three hops and stood closer to the large egg. It glittered and sparkled in the light as newly fallen snow glitters under the moon. The Candy Rabbit looked in through the glass window, and what he saw inside the egg made him wonder more and more.'\n",
      " b'\"Well, I do declare!\" exclaimed the Candy Rabbit. \"Think of all those things inside an egg -- a church, a house and a little boy! I wonder what has happened to me! Yesterday I was on the toy counter, with the Calico Clown and the Monkey on a Stick, and to-day I seem to be in Fairyland. I wonder if this really is Fairyland? I guess I\\'d better look around some more.\"'\n",
      " b'He glanced again through the little glass window in the egg, and he thought he saw the little boy on the bank of the brook smiling at him. And the Candy Rabbit smiled back. Then the Bunny turned around and he saw, near him, a big chocolate egg. It was covered with twists and curlicues of sugar and candy, and in the end of this egg, also, was a glass window.'\n",
      " b'He looked and saw a little duck and a little chicken inside the chocolate egg. The little chicken was on one end of a small seesaw, and the little duck was on the other end. And as the Candy Rabbit looked through the glass window, he saw the seesaw begin to go up and down.'\n",
      " b'\"I have heard of many strange things,\" he said to himself. \"The Sawdust Doll told some of her queer adventures, and so did the White Rocking Horse and the Bold Tin Soldier. But never, in all my life, did I ever see a chocolate egg with a glass window and a little chicken and a duck inside seesawing and teeter-tautering! I think I had better go to the doctor\\'s, something must be the matter with me!\"'\n",
      " b'\"What\\'s the matter with you?\" suddenly asked a voice behind the Candy Rabbit. The sweet chap turned so quickly that he almost cracked one of his sugary ears. He saw, just back of him, a real fuzzy, furry rabbit. At least the rabbit seemed real, for his ears slowly moved backward and forward, his head turned from side to side, and, every now and then, he would rise on his hind legs and then crouch down again.'\n",
      " b'\"Yes, I seem to be,\" said the Candy Rabbit, feeling his head and body as far as he could reach, as if to make sure no part of him was broken, or lost, or out of place. \"But can you tell me this?\" he asked. \"A little while ago I was on the toy counter of this store with the Calico Clown and the Monkey on a Stick. And now I seem to be in Fairyland. Tell me, am I dreaming, or is this really Fairyland, where eggs have windows in them and hold little chickens and ducks who seesaw?\"'\n",
      " b'\"I mean until the clock-work inside me runs down,\" explained the Fuzzy Rabbit. \"You see, I am wound up, and when I am wound I have to rise up and stoop down on my hind legs. I have to twist my head and wiggle my ears. I\\'ll go on this way for half an hour more. But don\\'t let that bother you. I can still talk, and I\\'m glad you\\'re here. You\\'re some company. These eggs never say anything,\" and with his ears he pointed to the chocolate one and the glittery one, each of which had glass windows.'\n",
      " b'The Candy Rabbit gave another look around, and the more he looked the more certain he was that he was in Fairyland. Over at one end of what seemed to be a table he saw a little chicken harnessed to a tiny wagon, made from what appeared to be an egg shell, and a little doll sat in the egg-shell carriage, driving the chicken with little silk ribbon horse reins.'\n",
      " b'Turning around, so that he might not miss anything, the sweet fellow saw a large basket of flowers, and, nestled in among the blossoms, were some Candy Rabbits like himself, only smaller. Over in one corner were piled some cards, with pretty pictures on them, and near them was a small basket, filled with what seemed to be green grass, in which were hidden many small candy eggs.'\n",
      " b'\"He doesn\\'t even know his own store,\" said this dark-complexioned chap. \"Why, my dear fellow,\" he went on, \"the Easter Novelty Counter is just around the corner from the toy section, where you have lived so long. The Calico Clown, the Monkey on a Stick and the other friends you speak of are there. You are not very far away from them.\"'\n",
      " b'\"Goodness me!\" said the sweet chap to himself, as the lady swung him to one side so she might look at his eyes better. \"This is worse than being on a merry-go-round! I am feeling quite dizzy! I hope I am not going to be seasick, as the Lamb on Wheels thought she was going to be when the sailor bought her.\"'\n",
      " b\"She handed him back to the clerk, but something happened. Whether the clerk did not take a good hold of the Candy Rabbit, or whether the lady let go of him too soon, I don't know. But, all of a sudden, the Candy Rabbit slipped from the lady's hand and began falling. Straight toward the floor he fell!\"\n",
      " b'And what did the Candy Rabbit do but fall on the soft, rubber ball! Right down on the squidgy-squdgy ball toppled the sweet chap, and it was like falling on a feather bed. The Candy Rabbit was not hurt a bit, but just bounced straight up, almost as far as he had fallen down, and the girl clerk caught him in her hands.'\n",
      " b'As for the Candy Rabbit, his little sugar heart was beating very fast because of the fright he had got when he thought he was going to be broken to bits. But of course neither the lady nor the girl knew this. They just thought he was made of sugar, and nothing else.'\n",
      " b'\"Well, now I am going on a journey,\" said the Candy Rabbit to himself, as he felt the lady carrying him out of the store. \"I wish I had time to say good-bye to my new friends on the Easter counter, and to the Calico Clown and the Monkey on a Stick. But perhaps I shall see them again, and maybe I shall meet the Sawdust Doll or the Bold Tin Soldier.\"'\n",
      " b'And indeed he was, for the lady who had bought him for an Easter present rode home with him in an automobile, and once, in the street, the fire engines came along and the automobile had to hurry to get out of the way. All that the Candy Rabbit could hear was a great noise, a rumble, a clang, a ringing of bells, and much shouting. Then the automobile went on again, and soon stopped.'\n",
      " b'\"It soon will be,\" said his mother, and then she put away the Candy Rabbit where the children could not find him. And the place where she put him was in a closet in her room. She took the curled wood and the paper wrappings from the Rabbit, and set him on a shelf.'\n",
      " b'And then he saw, standing on the shelf near him, what seemed to be a little doll made of glass. On her head was a funny little cap, ending in a point, like the cap a dunce wears in school in the story books, and as the Candy Rabbit hopped nearer this Glass Doll the sweet smell of perfume became stronger.'\n",
      " b'\"I am it,\" answered the Glass Doll. \"I am made hollow, and inside I am filled with perfume. There is a hole in the top of my head and up through my pointed cap, and whenever the lady stands me on my head and jiggles me up and down some perfume spills out on her handkerchief.\"'\n",
      " b'\"I suppose I might hop around the room and find some one to talk to,\" thought the Candy Rabbit to himself, when he noticed that he was left alone behind the piano with the basket of eggs. \"But perhaps it would be better to wait, since I am a stranger here.\"'\n",
      " b'\"And I\\'ve found another!\" shouted Madeline, as, after rather a long search, she looked behind the piano. \"I\\'ve found a basket and -- and -- Oh, Herbert! look what a lovely Candy Rabbit. Oh, I\\'m so glad!\" and the little girl picked up the Candy Rabbit and fairly hugged him. The Candy Rabbit was very happy. He had now found some one to love him -- some one to whom he could belong, as the Sawdust Doll belonged to the little girl Dorothy.'\n",
      " b\"But Dorothy and Dick were very careful, and, after they had looked at and admired the Rabbit, he was put down on a chair not far from Dorothy's Sawdust Doll. The Candy Rabbit kept wishing that the children would go out of the room for a while, so he might talk to the Doll, whom he had not seen for a long time.\"\n",
      " b'\"Now I have a chance to talk to you!\" exclaimed the Sawdust Doll. \"I\\'ve just been waiting to ask how all my friends are at the toy store. And how are you? How did you get here? Do you like living in a house with children more than in the store? Tell me all about it!\"'\n",
      " b'This was a round table on which stood a bowl of real, live goldfish. The fish swam around in the water, and now and then they stopped swimming to look out through the glass with their big, round eyes. The top of the goldfish globe was open, and sometimes Madeline was allowed to feed the fish when her mother stood by. The fish ate tiny bits of biscuit bought for them at the fish, bird and dog store.'\n",
      " b\"While this was going on a bad cat had sneaked into the room. The cat was a big fellow, and he often got into mischief. He sometimes chased birds, and, more than once, Patrick, the gardener at Dick and Dorothy's house, had driven him away from the coops where the little chickens lived with the old hen.\"\n",
      " b'But Tom was not after a Candy Rabbit. His greedy eyes were on the swimming goldfish in the open glass bowl. Dorothy and Madeline sat with their backs to the little table on which stood the bowl of fish and the Candy Rabbit. The little girls were busy talking.'\n",
      " b'All of a sudden Tom stood up on his hind legs and put his forepaws on the edge of the bowl. As he did this the fish began swimming around swiftly, very much frightened, indeed, just as you may have seen a canary bird flutter in a cage when some cat came too close.'\n",
      " b'Tom was switching his tail to and fro, as cats always do when they are about to catch a bird, a fish or anything alive. The fish were swimming about faster and faster inside their bowl of water. They could make no noise. Some fish, such as catfish, can make a little sound out of water, and so can the fish called grunters, but I never heard of any other fish making any noise. Though of course they may be able to talk among themselves, for all I know.'\n",
      " b'\"It was the Candy Rabbit,\" answered Madeline. \"Look! He fell over against the glass bowl, and, lots of times, when I\\'ve been feeding the fish and have struck the bowl, it has rung like a bell. The Candy Rabbit did that, and that\\'s what made me look around.\"'\n",
      " b\"And, now I come to think of it, maybe the Candy Rabbit did topple over by himself, to strike against the bowl and so cause Dorothy and Madeline to turn around in time to stop the bad cat from getting the goldfish. Mind you, I am not saying for sure that this happened. The cat's tail certainly brushed against the Candy Rabbit, but the sweet chap may have tinkled against the glass globe himself. He surely wanted to save the fish from being eaten.\"\n",
      " b'And because of that very same pink ribbon something dreadful happened a few days later. I will tell you about it. After Easter the weather gradually became warmer and sunnier. Doors and windows could be left open, and the flowers in the yard began to blossom.'\n",
      " b'One day the Candy Rabbit was placed by Madeline on a chair in the dining room, near the bowl of goldfish on their little round table. The Sawdust Doll was not in the room, for Dorothy had her toy out in her own yard playing. The Candy Rabbit was lonesome, for he did not know how to talk to the goldfish.'\n",
      " b\"The grass swished and swashed against the legs and ears of the Candy Rabbit as the cat carried him along. The Rabbit was not hurt any, because the ribbon was not tied very tightly about his neck. And of course the cat's teeth did not touch him. But, for all that, the Candy Rabbit was very angry and somewhat alarmed.\"\n",
      " b'\"Now you stay here a while and see how you like it,\" said the bad cat, and away he trotted, hoping to get a meal of goldfish this time. And there came to the poor Candy Rabbit from the distance the sound of the Cat\\'s voice as he laughed, \"Ha-ha,\" and snarled, \"I\\'ve fixed you all right! Ha-ha!\"'\n",
      " b'Since the Candy Rabbit had left the toy store, after having been put on the Easter novelty counter, so many things had happened that he was beginning to get used to them. But sailing through the air on the tail of a kite was something he had never done before.'\n",
      " b'Up and up, and to and fro, switched the Candy Rabbit on the kite tail. Of course a bunch of grass, a wad of paper, or even a stone would have been just as well for the boys to have used as a weight. But they had happened to see the Candy Rabbit, and had taken him. Boys are sometimes like that, you know.'\n",
      " b'How long Herbert, Dick and Arnold might have let the Candy Rabbit sail about on the end of the kite tail I cannot say, but when the three chums had been having this fun for about half an hour, all of a sudden Madeline and her two friends, Mirabell and Dorothy, came running across the field.'\n",
      " b'\"I didn\\'t drop my Candy Rabbit here,\" went on Madeline. \"I wouldn\\'t do such a thing. I left him in the house, and then I couldn\\'t find him, and I was coming to ask if you had seen him. I thought maybe Carlo had carried him off as he carried Dorothy\\'s doll once.\"'\n",
      " b'\"Well, if you didn\\'t take your Candy Rabbit out and leave him here in the field, maybe Carlo did,\" said Herbert. \"Anyhow, we didn\\'t hurt him and you can have him back again. We can tie a bunch of weeds on the kite tail. They\\'ll be just as good as the Rabbit.\"'\n",
      " b'Down came the kite when the string was wound up, and slowly the Candy Rabbit floated back to earth. Madeline stood under the tail with her dress held out to catch the Bunny in it. And down he came, not being hurt a bit. Quickly Madeline loosened her Easter toy from the kite tail, and she nestled him in her arms.'\n",
      " b'And of course neither Madeline nor any of the others knew that the cat had carried the Bunny away and had dropped him in the grassy field. They all thought Carlo had done it, but of course there was no way of finding out for sure, except by reading this book. In this the true story of the Candy Rabbit is told for the first time.'\n",
      " b'This was one of the pleasures Madeline and Herbert enjoyed on baking day, but Herbert was not on hand then, so Madeline had all the dishes to herself. She set her Candy Rabbit on a shelf, got a spoon, and began to clean the icing dish. Of course you know that means she scraped the dish with the spoon and ate the icing she scraped up. Yes, and I think she even licked the spoon. After she had finished the white icing dish there was a chocolate one to start on.'\n",
      " b'It was only just in time, too, for the poor Rabbit was just beginning to melt. In fact, one of his ears did soften and twist over to one side a little. But Madeline quickly took him out on the cool porch, and the Rabbit felt better. However, that queer twist, or droop, stayed in one ear -- not the one with the grass-stain on, but the other.'\n",
      " b'Happy days followed for the Bunny. The children played sometimes in one house and sometimes in another, taking their toys with them, and sometimes the Rabbit had a chance to talk to the Sawdust Doll, the Bold Tin Soldier, the White Rocking Horse or the Lamb on Wheels, for the children would often leave their toys together, as the boys and girls went out to play in the yards or on the verandas.'\n",
      " b'\"I wonder how the Calico Clown is getting along,\" said the Candy Rabbit to the Sawdust Doll on one of the days when they were together. They were on the porch of Madeline\\'s house, and Madeline, Mirabell and Dorothy were around in the back yard playing in a sand pile.'\n",
      " b'Slowly down the street walked the organ grinder, turning the crank and making music. His little girl, an Italian child, after putting the Candy Rabbit under her apron, looked around the house where Madeline lived to see if any one might be coming out with pennies. But no one came.'\n",
      " b\"Madeline and Dorothy and Mirabell were in the back yard where they had gone to play in the sand pile, after leaving the Sawdust Doll and the Candy Rabbit on the front veranda. Madeline's mother was not at home, and the cook was too busy in the kitchen to bother with giving pennies to organ grinders, though she might have done so if she had had time and had had plenty of pennies.\"\n",
      " b'\"I\\'ll take him home with me. Nobody wants him,\" she said to herself as she went down off the veranda with the candy chap under her apron. And she really thought the Rabbit had been put out because no one wanted him. She slipped the Bunny into a large pocket in the skirt of her dress and hurried on after her father, who had walked down the street grinding out his tunes.'\n",
      " b'With the organ man lived his brother, who was a peddler. He had a big basket in which he carried pins, needles, pin cushions, little looking glasses, court plaster and odds and ends, called \"notions.\" This peddler man went about from house to house selling notions to such as wanted to buy them.'\n",
      " b'\"He is a fine Candy Rabbit,\" said Joe, the peddler, looking at the Bunny. \"He is almost new. I guess he came from an Easter novelty counter. Once I sold Easter toys, but now I sell only pins and needles. Yes, he is a fine Rabbit, Rosa. Are you going to eat him? He is made of candy.\"'\n",
      " b'But of course Madeline wanted her Candy Rabbit very much. And when she and Dorothy and Mirabell came back to the veranda after their play in the sand pile and found the Sawdust Doll there and the Bunny gone, poor Madeline felt very bad indeed. She cried, and she looked all over for her Easter toy, but he was not to be found.'\n",
      " b'Peddler Joe was up early the next morning. He was up before either his brother, Tony, or the little girl, Rosa. Joe cooked himself some breakfast on an old oil stove, and then, taking his basket, he went out. He did not even turn back the oilcloth cover to see that his pins, needles, cushions and other notions were all in place. He felt sure that they were. And of course he did not know the Candy Rabbit was in his basket.'\n",
      " b'\"Dear me! what is happening now?\" thought the Candy Rabbit, as he was suddenly awakened by being jiggled and joggled about in the basket. \"Am I at sea? Have I been taken on a ship, and am I crossing the ocean?\" For that is what the motion was like -- just the same as the Lamb of Wheels felt when she was on the raft.'\n",
      " b\"He had awakened when Peddler Joe picked up the basket. The Candy Rabbit found himself lying on the new pin cushion, where Rosa had placed him. But as the basket was lifted up and swung on Joe's shoulder by means of a strap, it was so tilted that the Candy Rabbit slipped off the cushion and fell down in among a pile of papers of pins.\"\n",
      " b'\"Any pins? Any needles? Any notions to-day?\" asked Joe, as he held his basket out for Madeline\\'s mother to see. And this time, and for the first time that morning, Joe pulled back the oilcloth cover from the other side. That was the reason he had not yet seen the Rabbit.'\n",
      " b\"But now, as the oilcloth was rolled back, the sweet chap, lying on his side among the papers of pins, was shown. Madeline's mother was just going to say she did not care for any needles or sticking-plaster when the little girl, looking into the basket, spied the Bunny.\"\n",
      " b'\"Oh, yes, very sure,\" answered Madeline. \"Look, here is the green spot on his ear, where he fell in the grass the day the boys tied him to the kite tail. And, see! one ear is bent a little. It happened when he was too near the heat, the day I was eating chocolate from the cake dishes. He\\'s my Candy Rabbit, all right!\"'\n",
      " b'\"Well, he has had his bath all right,\" said Mother, with a laugh. \"And I think he is pretty clean. He does not seem to be melting any, but it would be well to let him dry. Here, I\\'ll set him on the window sill and open the window. The breeze will dry him off better than if you wiped him with a towel. Then you will not wipe off any of his sugar.\"'\n",
      " b'\"That was a narrow escape I had,\" he said. \"I was very nearly drowned and melted in the water. I had better keep very still and quiet until I am quite dry again, or I may come apart like the Jack in the Box who jumped off his spring. Yes, I will sit here very quietly until I am dry. I do feel so wet and sticky!\"'\n",
      " b'\"The Calico Clown and the Monkey on a Stick will think it quite wonderful when I tell them what has happened to me,\" said the Candy Rabbit to himself, as he sat there, drying. \"I suppose they must have had some adventures, also, but I don\\'t believe either of them ever fell into a bathtub of water.\"'\n",
      " b'\"I have heard that sponges are animals,\" said the Candy Rabbit. \"I wonder if this one is alive and will speak to me. I\\'ll try. Hello there, Mr. Sponge!\" he called. \"You must be quite a swimmer. Are you as good as a goldfish -- one of those the bad cat tried to get?\"'\n",
      " b'And this was true. He had fallen out instead of falling in, and, in the end, this was a good thing for him. For if he had fallen inside the bathroom he would have toppled down on the hard, tiled floor, and have been broken to pieces. As it was, falling out of the window, he had a better chance.'\n",
      " b\"But, as it happened, just then Patrick, the gardener, was passing along with a wheelbarrow full of freshly cut grass. He had cut the lawn in front of the house where Dorothy lived, and now Patrick was wheeling the loose grass across Madeline's yard to give to a pony in a stable in the house just beyond Madeline's.\"\n",
      " b\"Patrick, the gardener, had set his wheelbarrow down to rest just as he came under the bathroom window of Madeline's house. And Patrick had his back turned, and was looking at Carlo, the little dog, chasing his tail just when the Candy Rabbit fell into the grass. So Patrick did not see what had happened.\"\n",
      " b'\"Oh, that!\" laughed the cook. \"You see, Madeline is going to have a party, and I\\'m so busy making cookies and cakes that it\\'s a wonder flour isn\\'t all over my face as well as on my nose. But what have you there?\" she asked, seeing the Bunny in Patrick\\'s hand.'\n",
      " b'\"Ah, that accounts for it then!\" laughed the gardener. \"The wind must have blown him out of the window, and he fell into my barrow just as I set it down to rest. Well, it\\'s lucky I had grass in the barrow instead of stones. If your rabbit had fallen on them he might have broken off his ears.\"'\n",
      " b'\"Well, goodness knows I am glad to be by myself for a while and keep quiet,\" thought the sugary chap, as he sat down on the shelf in the dark. \"I have had enough of adventures for a day or two. I wonder if there is any one here to whom I can talk. I wish the Sawdust Doll or the Bold Tin Soldier or the Calico Clown were here. They would love to hear me tell of what has happened.\"'\n",
      " b'Madeline and her girl friends spent the rest of that day and part of the next one getting ready for the party, and at last the time came to have it. Madeline was all dressed up, and she brought her Candy Rabbit out of the closet and smoothed the ribbon on his neck.'\n",
      " b'One after another more children came to the party, among them Mirabell and Arnold. Mirabell did not bring her Lamb on Wheels for the same reason that Dick left his Horse at home -- the Lamb was a little too large for a house party, though she would fit very well on the lawn.'\n",
      " b\"But Arnold, who was Mirabell's brother, brought something to the party. It was the Bold Tin Soldier -- the Captain of the Tin Soldiers, of whom Arnold had a whole box. And while the little girls who had come to Madeline's party were smoothing out their dresses and looking at their dolls and talking to one another, Arnold walked off with Dick to a corner of the room.\"\n",
      " b'All sorts of games were played. One was \"hide the thimble,\" and when it was Madeline\\'s turn to hide it she put it right between the front legs of her Candy Rabbit as he sat on the table. Not one of the boys or girls thought of looking there for it, so they had to give up, and it was Madeline\\'s turn to hide it again.'\n",
      " b'\"That golden gleam against the blue of my ribbon is certainly very pretty and becoming,\" she thought. \"I hope Dorothy will notice it and will get a gold ornament for my hair. I like to be a toy, but sometimes it is a great nuisance not to be able to tell your little girl and boy parents what you would like to have them do.\"'\n",
      " b'Pretty soon it was time to eat ice cream and cake. That is one of the nicest times at a party, I think; and Dick, Arnold and Herbert, as well as the other boys and girls, thought the same thing, I am sure. While they were in another room, eating the good things, the Candy Rabbit and the Sawdust Doll were left to themselves.'\n",
      " b'He started to hop across the table, to get nearer to the Sawdust Doll, but he did not see the thimble which the children had been playing with, and which had been left on the table. The Candy Rabbit jumped on the thimble, which rolled out from under his paws.'\n",
      " b\"She set him up straight again, near the Sawdust Doll, and then she helped the other children have fun in more games. After a while Dick and Arnold went off in a corner by themselves, and began playing with Arnold's Bold Tin Soldier. While they were doing this a boy named Tom saw them.\"\n",
      " b\"Tom had many other things in his pocket. There was a small rubber ball, some pieces of string, a broken knife, two or three nails, some round, shiny pieces of tin, a whistle that wouldn't whistle, a red stone, a yellow stone, and many other odds and ends. Down among these objects the Candy Rabbit was pushed and jammed.\"\n",
      " b\"The only ones who saw Tom hurry away with the Candy Rabbit were the little girls' dolls. The Sawdust Doll, a Celluloid Doll belonging to Mirabell, and an old snub-nosed Wooden Doll, that Madeline had brought down from the attic, were on the table when Tom took the Candy Rabbit away in his pocket.\"\n",
      " b'The Candy Rabbit stayed in the closet with the Porcelain Cat all night, and the two were company for one another. The next day Madeline took her Easter toy for a ride in the doll carriage, and Dorothy had her Sawdust pet with her. The little girls talked about the party.'], shape=(512,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for element in raw_val_ds.take(1):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "MOyz780PvqUB"
   },
   "outputs": [],
   "source": [
    "#if there is no val_ds\n",
    "#raw_train_ds, raw_val_ds= keras.utils.split_dataset(raw_train_ds, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x-wQ7nuyl-Z"
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgCxKtV7vK8p"
   },
   "source": [
    "### EITHER train and save a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3FBDxL8jFDY8"
   },
   "outputs": [],
   "source": [
    "# Train tokenizer vocabulary\n",
    "#vocab = keras_hub.tokenizers.compute_word_piece_vocabulary(\n",
    "#    raw_train_ds,\n",
    "#    vocabulary_size=VOCAB_SIZE,\n",
    "#    lowercase=True,\n",
    "#    reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[BOS]\"],\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "BaLkYp9YdQMl"
   },
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#with open(BASE_DIR+'/simplebooks_vocab.pkl', 'wb') as f:\n",
    "#    pickle.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csrixR2kfMPJ"
   },
   "source": [
    "### OR retrieve vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vhEGs5B-fPcu"
   },
   "outputs": [],
   "source": [
    "#insert code to save and retrieve tokenizer\n",
    "import pickle\n",
    "with open('./working/simplebooks_vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7T-JVnoyl-Z",
    "outputId": "18dbffc8-12c0-4376-dc10-f76192f122b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['that',\n",
       " 'it',\n",
       " 'had',\n",
       " '##s',\n",
       " 'his',\n",
       " 'as',\n",
       " 'for',\n",
       " 'with',\n",
       " 'they',\n",
       " 'on',\n",
       " 'but',\n",
       " 'her',\n",
       " 'at',\n",
       " 'she',\n",
       " 'were',\n",
       " 'not',\n",
       " 'you',\n",
       " 'be',\n",
       " 'him',\n",
       " 'all']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[100:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNPdnVdDvfl8"
   },
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Q1JowubPFDY8"
   },
   "outputs": [],
   "source": [
    "tokenizer = keras_hub.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary=vocab,\n",
    "    sequence_length=SEQ_LEN,\n",
    "    lowercase=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "MGM81Hp2FDY8"
   },
   "outputs": [],
   "source": [
    "# packer adds a start token\n",
    "start_packer = keras_hub.layers.StartEndPacker(\n",
    "    sequence_length=SEQ_LEN,\n",
    "    start_value=tokenizer.token_to_id(\"[BOS]\"),\n",
    ")\n",
    "\n",
    "def preprocess(inputs):\n",
    "    outputs = tokenizer(inputs)\n",
    "    features = start_packer(outputs)\n",
    "    labels = outputs\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "# Tokenize and split into train and label sequences.\n",
    "train_ds = raw_train_ds.map(preprocess, num_parallel_calls=tf_data.AUTOTUNE).prefetch(\n",
    "    tf_data.AUTOTUNE\n",
    ")\n",
    "val_ds = raw_val_ds.map(preprocess, num_parallel_calls=tf_data.AUTOTUNE).prefetch(\n",
    "    tf_data.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yh5Jmb2dfbza"
   },
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJhvgUnOfSDV"
   },
   "source": [
    "## LLama additions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqX87u9mjSzK"
   },
   "source": [
    "### Feed-Forward Layer with SwiGLU\n",
    "SwiGLU Layer, i.e. a Dense layer with SwiGLU activation following the formulation per original paper:  \n",
    "FFNSwiGLU=(Swish(xW)*xV)W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "fBWz3GYCOUOs"
   },
   "outputs": [],
   "source": [
    "## This replaces the first Dense layer of the FF block\n",
    "@keras.saving.register_keras_serializable()\n",
    "class FFNSwiGLU(Layer):\n",
    "    def __init__(self, intermediate_dim, **kwargs):\n",
    "        super(FFNSwiGLU, self).__init__(**kwargs)\n",
    "        self.intermediate_dim = intermediate_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        last_dim = input_shape[-1]\n",
    "        self.W = self.add_weight(shape=(last_dim, self.intermediate_dim), initializer='glorot_uniform', trainable=True, name='W')\n",
    "        self.V = self.add_weight(shape=(last_dim, self.intermediate_dim), initializer='glorot_uniform', trainable=True, name='V')\n",
    "        self.W2 = self.add_weight(shape=(self.intermediate_dim,), initializer='glorot_uniform', trainable=True, name='W2')\n",
    "        super(FFNSwiGLU, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        gate = silu(inputs @ self.W)\n",
    "        return (gate * (inputs @ self.V)) * self.W2\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(FFNSwiGLU, self).get_config()\n",
    "        config.update({'intermediate_dim': self.intermediate_dim})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This replaces the first Dense layer of the FF block\n",
    "@keras.saving.register_keras_serializable()\n",
    "class FFNSwiGLU2(Layer):\n",
    "    def __init__(self, intermediate_dim, **kwargs):\n",
    "        super(FFNSwiGLU2, self).__init__(**kwargs)\n",
    "        self.intermediate_dim = intermediate_dim\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        last_dim = input_shape[-1]\n",
    "        self.gate = Dense(self.intermediate_dim, activation=\"silu\", use_bias=False, name=\"swiglu_gate\")\n",
    "        self.linear = Dense(self.intermediate_dim, use_bias=False, name=\"swiglu_linear\")\n",
    "        self.multiply= Multiply(name=\"swiglu_out\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        gated = self.gate(inputs)\n",
    "        linear_out=self.linear(inputs)\n",
    "        #swiglu_out=self.multiply([gated, linear_out])\n",
    "        return gated*linear_out\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(FFNSwiGLU2, self).get_config()\n",
    "        config.update({'intermediate_dim': self.intermediate_dim})\n",
    "        return config\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kREy36UPjGCY"
   },
   "source": [
    "### Grouped Query Attention - the \"formal\" implementation\n",
    "In the RoPE paper, RoPE is applied to the queries Q and keys K, NOT the embeddings. This requires a reworking of the default Grouped Query Attention layer.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "s8OcmYzP4540"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from keras.src import constraints\n",
    "from keras.src import initializers\n",
    "from keras.src import ops\n",
    "from keras.src import regularizers\n",
    "from keras.src.api_export import keras_export\n",
    "from keras.src.backend.config import is_flash_attention_enabled\n",
    "from keras.src.layers.activations.softmax import Softmax\n",
    "from keras.src.layers.core.einsum_dense import EinsumDense\n",
    "from keras.src.layers.layer import Layer\n",
    "from keras.src.layers.regularization.dropout import Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6OUg2G_sqn6"
   },
   "source": [
    "The following was adapted from Keras source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "d2um0YMw5VSw"
   },
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class GQAwithRoPE(Layer):\n",
    "    \"\"\"Grouped Query Attention layer.\n",
    "\n",
    "    This is an implementation of grouped-query attention introduced by\n",
    "    [Ainslie et al., 2023](https://arxiv.org/abs/2305.13245). Here\n",
    "    `num_key_value_heads` denotes number of groups, setting\n",
    "    `num_key_value_heads` to 1 is equivalent to multi-query attention, and\n",
    "    when `num_key_value_heads` is equal to `num_query_heads` it is equivalent\n",
    "    to multi-head attention.\n",
    "\n",
    "    This layer first projects `query`, `key`, and `value` tensors. Then, `key`\n",
    "    and `value` are repeated to match the number of heads of `query`.\n",
    "\n",
    "    Then, the `query` is scaled and dot-producted with `key` tensors. These are\n",
    "    softmaxed to obtain attention probabilities. The value tensors are then\n",
    "    interpolated by these probabilities and concatenated back to a single\n",
    "    tensor.\n",
    "\n",
    "    Args:\n",
    "        head_dim: Size of each attention head.\n",
    "        num_query_heads: Number of query attention heads.\n",
    "        num_key_value_heads: Number of key and value attention heads.\n",
    "        dropout: Dropout probability.\n",
    "        use_bias: Boolean, whether the dense layers use bias vectors/matrices.\n",
    "        flash_attention: If `None`, the layer attempts to use flash\n",
    "            attention for faster and more memory-efficient attention\n",
    "            computations when possible. This behavior can be configured using\n",
    "            `keras.config.enable_flash_attention()` or\n",
    "            `keras.config.disable_flash_attention()`.\n",
    "        kernel_initializer: Initializer for dense layer kernels.\n",
    "        bias_initializer: Initializer for dense layer biases.\n",
    "        kernel_regularizer: Regularizer for dense layer kernels.\n",
    "        bias_regularizer: Regularizer for dense layer biases.\n",
    "        activity_regularizer: Regularizer for dense layer activity.\n",
    "        kernel_constraint: Constraint for dense layer kernels.\n",
    "        bias_constraint: Constraint for dense layer kernels.\n",
    "        seed: Optional integer to seed the dropout layer.\n",
    "\n",
    "    Call arguments:\n",
    "        query: Query tensor of shape `(batch_dim, target_seq_len, feature_dim)`,\n",
    "            where `batch_dim` is batch size, `target_seq_len` is the length of\n",
    "            target sequence, and `feature_dim` is dimension of feature.\n",
    "        value: Value tensor of shape `(batch_dim, source_seq_len, feature_dim)`,\n",
    "            where `batch_dim` is batch size, `source_seq_len` is the length of\n",
    "            source sequence, and `feature_dim` is dimension of feature.\n",
    "        key: Optional key tensor of shape\n",
    "            `(batch_dim, source_seq_len, feature_dim)`. If not given, will use\n",
    "            `value` for both `key` and `value`, which is most common case.\n",
    "        attention_mask: A boolean mask of shape\n",
    "            `(batch_dim, target_seq_len, source_seq_len)`, that prevents\n",
    "            attention to certain positions. The boolean mask specifies which\n",
    "            query elements can attend to which key elements, where 1 indicates\n",
    "            attention and 0 indicates no attention. Broadcasting can happen for\n",
    "            the missing batch dimensions and the head dimension.\n",
    "        return_attention_scores: A boolean to indicate whether the output\n",
    "            should be `(attention_output, attention_scores)` if `True`, or\n",
    "            `attention_output` if `False`. Defaults to `False`.\n",
    "        training: Python boolean indicating whether the layer should behave in\n",
    "            training mode (adding dropout) or in inference mode (no dropout).\n",
    "            Will go with either using the training mode of the parent\n",
    "            layer/model or `False` (inference) if there is no parent layer.\n",
    "        use_causal_mask: A boolean to indicate whether to apply a causal mask to\n",
    "            prevent tokens from attending to future tokens (e.g., used in a\n",
    "            decoder Transformer).\n",
    "\n",
    "    Returns:\n",
    "        attention_output: Result of the computation, of shape\n",
    "            `(batch_dim, target_seq_len, feature_dim)`, where `target_seq_len`\n",
    "            is for target sequence length and `feature_dim` is the query input\n",
    "            last dim.\n",
    "        attention_scores: (Optional) attention coefficients of shape\n",
    "            `(batch_dim, num_query_heads, target_seq_len, source_seq_len)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        head_dim,\n",
    "        num_query_heads,\n",
    "        num_key_value_heads,\n",
    "        dropout=0.0,\n",
    "        use_bias=True,\n",
    "        flash_attention=None,\n",
    "        kernel_initializer=\"glorot_uniform\",\n",
    "        bias_initializer=\"zeros\",\n",
    "        kernel_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        activity_regularizer=None,\n",
    "        kernel_constraint=None,\n",
    "        bias_constraint=None,\n",
    "        seed=None,\n",
    "        use_rope=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.supports_masking = True\n",
    "        self.head_dim = head_dim\n",
    "        self.num_query_heads = num_query_heads\n",
    "        self.num_key_value_heads = num_key_value_heads\n",
    "        if num_query_heads % num_key_value_heads != 0:\n",
    "            raise ValueError(\n",
    "                \"`num_query_heads` must be divisible by `num_key_value_heads`.\"\n",
    "            )\n",
    "        self.num_repeats = num_query_heads // num_key_value_heads\n",
    "        self.dropout = dropout\n",
    "        self.use_bias = use_bias\n",
    "        self._flash_attention = flash_attention or is_flash_attention_enabled()\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "        self.seed = seed\n",
    "        self.use_rope = use_rope\n",
    "\n",
    "        self._inverse_sqrt_head_dim = 1.0 / math.sqrt(float(self.head_dim))\n",
    "        self._return_attention_scores = False\n",
    "\n",
    "        # Check for flash attention constraints\n",
    "        if self._flash_attention and self.dropout > 0.0:\n",
    "            raise ValueError(\n",
    "                \"Dropout is not supported when flash attention is enabled. \"\n",
    "                \"Please set dropout to 0.0 to use flash attention.\"\n",
    "            )\n",
    "\n",
    "    def build(\n",
    "        self,\n",
    "        query_shape,\n",
    "        value_shape,\n",
    "        key_shape=None,\n",
    "    ):\n",
    "        # Einsum variables:\n",
    "        # b = batch size\n",
    "        # q = query length\n",
    "        # k = key/value length\n",
    "        # m = model dim\n",
    "        # u = num query heads\n",
    "        # v = num key/value heads\n",
    "        # h = head dim\n",
    "        key_shape = value_shape if key_shape is None else key_shape\n",
    "        self.feature_dim = query_shape[-1]\n",
    "        self._query_dense = EinsumDense(\n",
    "            \"bqm,muh->bquh\",\n",
    "            output_shape=(None, self.num_query_heads, self.head_dim),\n",
    "            bias_axes=\"uh\" if self.use_bias else None,\n",
    "            name=\"query\",\n",
    "            **self._get_common_kwargs_for_sublayer(),\n",
    "        )\n",
    "        self._query_dense.build(query_shape)\n",
    "\n",
    "        self._key_dense = EinsumDense(\n",
    "            \"bkm,mvh->bkvh\",\n",
    "            output_shape=(None, self.num_key_value_heads, self.head_dim),\n",
    "            bias_axes=\"vh\" if self.use_bias else None,\n",
    "            name=\"key\",\n",
    "            **self._get_common_kwargs_for_sublayer(),\n",
    "        )\n",
    "        self._key_dense.build(key_shape)\n",
    "\n",
    "        self._value_dense = EinsumDense(\n",
    "            \"bkm,mvh->bkvh\",\n",
    "            output_shape=(None, self.num_key_value_heads, self.head_dim),\n",
    "            bias_axes=\"vh\" if self.use_bias else None,\n",
    "            name=\"value\",\n",
    "            **self._get_common_kwargs_for_sublayer(),\n",
    "        )\n",
    "        self._value_dense.build(value_shape)\n",
    "\n",
    "        self._softmax = Softmax(axis=-1, dtype=self.dtype_policy)\n",
    "        self._dropout_layer = Dropout(\n",
    "            rate=self.dropout, dtype=self.dtype_policy, seed=self.seed\n",
    "        )\n",
    "\n",
    "        self._dot_product_equation = \"bquh,bkuh->buqk\"\n",
    "        self._combine_equation = \"buqk,bkuh->bquh\"\n",
    "\n",
    "        self._output_dense = EinsumDense(\n",
    "            \"bquh,uhm->bqm\",\n",
    "            output_shape=(None, self.feature_dim),\n",
    "            bias_axes=\"m\" if self.use_bias else None,\n",
    "            name=\"attention_output\",\n",
    "            **self._get_common_kwargs_for_sublayer(),\n",
    "        )\n",
    "        self._output_dense.build(\n",
    "            (None, None, self.num_query_heads, self.head_dim)\n",
    "        )\n",
    "\n",
    "        self._rope=RotaryEmbedding()\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def _get_common_kwargs_for_sublayer(self):\n",
    "        common_kwargs = dict(\n",
    "            kernel_regularizer=self.kernel_regularizer,\n",
    "            bias_regularizer=self.bias_regularizer,\n",
    "            activity_regularizer=self.activity_regularizer,\n",
    "            kernel_constraint=self.kernel_constraint,\n",
    "            bias_constraint=self.bias_constraint,\n",
    "            dtype=self.dtype_policy,\n",
    "        )\n",
    "        # Create new clone of kernel/bias initializer, so that we don't reuse\n",
    "        # the initializer instance, which could lead to same init value since\n",
    "        # initializer is stateless.\n",
    "        kernel_initializer = self.kernel_initializer.__class__.from_config(\n",
    "            self.kernel_initializer.get_config()\n",
    "        )\n",
    "        bias_initializer = self.bias_initializer.__class__.from_config(\n",
    "            self.bias_initializer.get_config()\n",
    "        )\n",
    "        common_kwargs[\"kernel_initializer\"] = kernel_initializer\n",
    "        common_kwargs[\"bias_initializer\"] = bias_initializer\n",
    "        return common_kwargs\n",
    "\n",
    "    def call(\n",
    "        self,\n",
    "        query,\n",
    "        value,\n",
    "        key=None,\n",
    "        query_mask=None,\n",
    "        value_mask=None,\n",
    "        key_mask=None,\n",
    "        attention_mask=None,\n",
    "        return_attention_scores=False,\n",
    "        training=None,\n",
    "        use_causal_mask=False,\n",
    "    ):\n",
    "        self._return_attention_scores = return_attention_scores\n",
    "        if key is None:\n",
    "            key = value\n",
    "\n",
    "        attention_mask = self._compute_attention_mask(\n",
    "            query,\n",
    "            value,\n",
    "            query_mask=query_mask,\n",
    "            value_mask=value_mask,\n",
    "            key_mask=key_mask,\n",
    "            attention_mask=attention_mask,\n",
    "            use_causal_mask=use_causal_mask,\n",
    "        )\n",
    "\n",
    "        query = self._query_dense(query)\n",
    "        key = self._key_dense(key)\n",
    "        value = self._value_dense(value)\n",
    "\n",
    "        if self.use_rope:\n",
    "          query = self._rope(query)\n",
    "          key = self._rope(key)\n",
    "\n",
    "\n",
    "        key = ops.repeat(\n",
    "            key, self.num_repeats, axis=2\n",
    "        )  # (batch_dim, source_seq_len, query_heads, head_dim)\n",
    "        value = ops.repeat(\n",
    "            value, self.num_repeats, axis=2\n",
    "        )  # (batch_dim, source_seq_len, query_heads, head_dim)\n",
    "\n",
    "        output, scores = self._compute_attention(\n",
    "            query,\n",
    "            key,\n",
    "            value,\n",
    "            attention_mask=attention_mask,\n",
    "            training=training,\n",
    "        )\n",
    "\n",
    "        output = self._output_dense(\n",
    "            output\n",
    "        )  # (batch_dim, target_seq_len, feature_dim)\n",
    "\n",
    "        if return_attention_scores:\n",
    "            return output, scores\n",
    "        return output\n",
    "\n",
    "    def _compute_attention_mask(\n",
    "        self,\n",
    "        query,\n",
    "        value,\n",
    "        query_mask=None,\n",
    "        value_mask=None,\n",
    "        key_mask=None,\n",
    "        attention_mask=None,\n",
    "        use_causal_mask=False,\n",
    "    ):\n",
    "        \"\"\"Computes the attention mask, using the Keras masks of the inputs.\n",
    "\n",
    "        * The `query`'s mask is reshaped from [B, T] to [B, T, 1].\n",
    "        * The `value`'s mask is reshaped from [B, S] to [B, 1, S].\n",
    "        * The `key`'s mask is reshaped from [B, S] to [B, 1, S]. The `key`'s\n",
    "          mask is ignored if `key` is `None` or if `key is value`.\n",
    "        * If `use_causal_mask=True`, then the causal mask is computed. Its shape\n",
    "          is [1, T, S].\n",
    "\n",
    "        All defined masks are merged using a logical AND operation (`&`).\n",
    "\n",
    "        In general, if the `query` and `value` are masked, then there is no need\n",
    "        to define the `attention_mask`.\n",
    "\n",
    "        Args:\n",
    "            query: Projected query tensor of shape `(B, T, N, key_dim)`.\n",
    "            key: Projected key tensor of shape `(B, T, N, key_dim)`.\n",
    "            value: Projected value tensor of shape `(B, T, N, value_dim)`.\n",
    "            attention_mask: a boolean mask of shape `(B, T, S)`, that prevents\n",
    "                attention to certain positions.\n",
    "            use_causal_mask: A boolean to indicate whether to apply a causal\n",
    "                mask to prevent tokens from attending to future tokens (e.g.,\n",
    "                used in a decoder Transformer).\n",
    "\n",
    "        Returns:\n",
    "            attention_mask: a boolean mask of shape `(B, T, S)`, that prevents\n",
    "                attention to certain positions, based on the Keras masks of the\n",
    "                `query`, `key`, `value`, and `attention_mask` tensors, and the\n",
    "                causal mask if `use_causal_mask=True`.\n",
    "        \"\"\"\n",
    "        auto_mask = None\n",
    "        if query_mask is not None:\n",
    "            query_mask = ops.cast(query_mask, \"bool\")  # defensive casting\n",
    "            # B = batch size, T = max query length\n",
    "            auto_mask = ops.expand_dims(query_mask, -1)  # shape is [B, T, 1]\n",
    "        if value_mask is not None:\n",
    "            value_mask = ops.cast(value_mask, \"bool\")  # defensive casting\n",
    "            # B = batch size, S == max value length\n",
    "            mask = ops.expand_dims(value_mask, -2)  # shape is [B, 1, S]\n",
    "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
    "        if key_mask is not None:\n",
    "            key_mask = ops.cast(key_mask, \"bool\")  # defensive casting\n",
    "            # B == batch size, S == max key length == max value length\n",
    "            mask = ops.expand_dims(key_mask, -2)  # shape is [B, 1, S]\n",
    "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
    "        if use_causal_mask:\n",
    "            # the shape of the causal mask is [1, T, S]\n",
    "            mask = self._compute_causal_mask(query, value)\n",
    "            auto_mask = mask if auto_mask is None else auto_mask & mask\n",
    "        if auto_mask is not None:\n",
    "            # merge attention_mask & automatic mask, to shape [B, T, S]\n",
    "            attention_mask = (\n",
    "                auto_mask\n",
    "                if attention_mask is None\n",
    "                else ops.cast(attention_mask, bool) & auto_mask\n",
    "            )\n",
    "        return attention_mask\n",
    "\n",
    "    def _compute_causal_mask(self, query, value=None):\n",
    "        \"\"\"Computes a causal mask (e.g., for masked self-attention layers).\n",
    "\n",
    "        For example, if query and value both contain sequences of length 4,\n",
    "        this function returns a boolean tensor equal to:\n",
    "\n",
    "        ```\n",
    "        [[[True,  False, False, False],\n",
    "          [True,  True,  False, False],\n",
    "          [True,  True,  True,  False],\n",
    "          [True,  True,  True,  True]]]\n",
    "        ```\n",
    "\n",
    "        Args:\n",
    "            query: query tensor of shape `(B, T, ...)`.\n",
    "            value: value tensor of shape `(B, S, ...)` (optional, defaults to\n",
    "                query).\n",
    "\n",
    "        Returns:\n",
    "            mask: a boolean tensor of shape `(1, T, S)` containing a lower\n",
    "                triangular matrix of shape `(T, S)`.\n",
    "        \"\"\"\n",
    "        q_seq_length = ops.shape(query)[1]\n",
    "        v_seq_length = q_seq_length if value is None else ops.shape(value)[1]\n",
    "        ones_mask = ops.ones((1, q_seq_length, v_seq_length), dtype=\"int32\")\n",
    "        row_index = ops.cumsum(ones_mask, axis=-2)\n",
    "        col_index = ops.cumsum(ones_mask, axis=-1)\n",
    "        return ops.greater_equal(row_index, col_index)\n",
    "\n",
    "    def _compute_attention(\n",
    "        self, query, key, value, attention_mask=None, training=None\n",
    "    ):\n",
    "        # Check for flash attention constraints\n",
    "        if self._flash_attention and self._return_attention_scores:\n",
    "            raise ValueError(\n",
    "                \"Returning attention scores is not supported when flash \"\n",
    "                \"attention is enabled. Please disable flash attention to access\"\n",
    "                \" attention scores.\"\n",
    "            )\n",
    "\n",
    "        # Determine whether to use dot-product attention\n",
    "        use_dot_product_attention = not (\n",
    "            self.dropout > 0.0\n",
    "            or self._return_attention_scores\n",
    "            or (len(query.shape) != 4)\n",
    "        )\n",
    "\n",
    "        if use_dot_product_attention:\n",
    "            if attention_mask is not None:\n",
    "                # Ensure attention_mask has the correct shape for broadcasting\n",
    "                # Expected shape: [batch_size, num_heads, query_seq_len,\n",
    "                # key_seq_len].\n",
    "                mask_expansion_axis = -1 * 2 - 1\n",
    "                len_attention_scores_shape = 4  # Only accepts 4D inputs\n",
    "                for _ in range(\n",
    "                    len_attention_scores_shape - len(attention_mask.shape)\n",
    "                ):\n",
    "                    attention_mask = ops.expand_dims(\n",
    "                        attention_mask, axis=mask_expansion_axis\n",
    "                    )\n",
    "                attention_mask = ops.cast(attention_mask, dtype=\"bool\")\n",
    "            # Directly compute the attention output using dot-product attention\n",
    "            attention_output = ops.dot_product_attention(\n",
    "                query=query,\n",
    "                key=key,\n",
    "                value=value,\n",
    "                bias=None,\n",
    "                mask=attention_mask,\n",
    "                scale=self._inverse_sqrt_head_dim,\n",
    "                is_causal=False,\n",
    "                flash_attention=self._flash_attention,\n",
    "            )\n",
    "            return attention_output, None\n",
    "\n",
    "        # Default behavior without flash attention, with explicit attention\n",
    "        # scores\n",
    "        query = ops.multiply(\n",
    "            query, ops.cast(self._inverse_sqrt_head_dim, query.dtype)\n",
    "        )\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw\n",
    "        # attention scores.\n",
    "        scores = ops.einsum(\n",
    "            self._dot_product_equation, query, key\n",
    "        )  # (batch_dim, query_heads, target_seq_len, source_seq_len)\n",
    "        scores = self._masked_softmax(scores, attention_mask=attention_mask)\n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "        if self.dropout > 0.0:\n",
    "            scores_dropout = self._dropout_layer(scores, training=training)\n",
    "        else:\n",
    "            scores_dropout = scores\n",
    "        output = ops.einsum(self._combine_equation, scores_dropout, value)\n",
    "        return output, scores\n",
    "\n",
    "    def _masked_softmax(self, scores, attention_mask=None):\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        # scores = [B, N, T, S]\n",
    "        if attention_mask is not None:\n",
    "            # The expand dim happens starting from the `num_heads` dimension,\n",
    "            # (<batch_dims>, num_heads, <query_attention_dims,\n",
    "            # key_attention_dims>)\n",
    "            mask_expansion_axis = -1 * 2 - 1\n",
    "            for _ in range(len(scores.shape) - len(attention_mask.shape)):\n",
    "                attention_mask = ops.expand_dims(\n",
    "                    attention_mask, axis=mask_expansion_axis\n",
    "                )\n",
    "        return self._softmax(scores, mask=attention_mask)\n",
    "\n",
    "    def compute_output_shape(\n",
    "        self,\n",
    "        query_shape,\n",
    "        value_shape,\n",
    "        key_shape=None,\n",
    "    ):\n",
    "        if key_shape is None:\n",
    "            key_shape = value_shape\n",
    "\n",
    "        if query_shape[-1] != value_shape[-1]:\n",
    "            raise ValueError(\n",
    "                \"The last dimension of `query_shape` and `value_shape` \"\n",
    "                f\"must be equal, but are {query_shape[-1]}, {value_shape[-1]}. \"\n",
    "                \"Received: query_shape={query_shape}, value_shape={value_shape}\"\n",
    "            )\n",
    "\n",
    "        if value_shape[1:-1] != key_shape[1:-1]:\n",
    "            raise ValueError(\n",
    "                \"All dimensions of `value` and `key`, except the last one, \"\n",
    "                f\"must be equal. Received: value_shape={value_shape} and \"\n",
    "                f\"key_shape={key_shape}\"\n",
    "            )\n",
    "\n",
    "        return query_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"head_dim\": self.head_dim,\n",
    "            \"num_query_heads\": self.num_query_heads,\n",
    "            \"num_key_value_heads\": self.num_key_value_heads,\n",
    "            \"use_bias\": self.use_bias,\n",
    "            \"dropout\": self.dropout,\n",
    "            \"kernel_initializer\": initializers.serialize(\n",
    "                self.kernel_initializer\n",
    "            ),\n",
    "            \"bias_initializer\": initializers.serialize(self.bias_initializer),\n",
    "            \"kernel_regularizer\": regularizers.serialize(\n",
    "                self.kernel_regularizer\n",
    "            ),\n",
    "            \"bias_regularizer\": regularizers.serialize(self.bias_regularizer),\n",
    "            \"activity_regularizer\": regularizers.serialize(\n",
    "                self.activity_regularizer\n",
    "            ),\n",
    "            \"kernel_constraint\": constraints.serialize(self.kernel_constraint),\n",
    "            \"bias_constraint\": constraints.serialize(self.bias_constraint),\n",
    "            \"seed\": self.seed,\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, **config}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPKcfFytkaiv"
   },
   "source": [
    "### Transformer Block with GQA and FFNSwiGLU\n",
    "We use GQA with RoPE and FFNSwiGLU. Note that the feed-forward hidden dimension is 4 x EMBEDDING x 2/3 to maintain the same computation complexity as the original GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "69CmfCn1mtQo"
   },
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, num_heads, num_kv_heads, embed_dim, ff_dim, dropout_rate=0.1, **kwargs):\n",
    "        super(TransformerBlock, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.num_kv_heads=num_kv_heads\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.attn = GQAwithRoPE(\n",
    "            num_query_heads=num_heads,\n",
    "            num_key_value_heads=num_kv_heads,\n",
    "            head_dim=embed_dim // num_heads,\n",
    "            use_rope=True,\n",
    "            use_bias=False,\n",
    "            dropout=0.0,\n",
    "            flash_attention=None,\n",
    "            seed=SEED,\n",
    "            name=\"attn\",\n",
    "        )\n",
    "\n",
    "        self.dropout_1 = Dropout(self.dropout_rate, seed=SEED)\n",
    "        self.ln_1 = LayerNormalization()\n",
    "        self.ffn_1 = FFNSwiGLU2(self.ff_dim, name=\"ffnswiglu\",)\n",
    "        self.ffn_2 = Dense(self.embed_dim, use_bias=False, name=\"ffnlinear\",)\n",
    "        self.dropout_2 = Dropout(self.dropout_rate, seed=SEED)\n",
    "        self.ln_2 = LayerNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "      input_shape = keras.ops.shape(inputs)\n",
    "      batch_size = input_shape[0]\n",
    "      seq_len = input_shape[1]\n",
    "      inputs_n=self.ln_1(inputs)\n",
    "      attention_output = self.attn(\n",
    "          query= inputs_n,\n",
    "          #key= inputs_n,\n",
    "          value= inputs_n, #quirk of implementation value is required, key is not and assumed = value\n",
    "          use_causal_mask=True\n",
    "      )\n",
    "      attention_output = self.dropout_1(attention_output)\n",
    "      out1 = self.ln_2(inputs + attention_output)\n",
    "\n",
    "      ffn_1 = self.ffn_1(out1)\n",
    "      ffn_2 = self.ffn_2(ffn_1)\n",
    "\n",
    "      ffn_output = self.dropout_2(ffn_2)\n",
    "      return (out1 + ffn_output)\n",
    "\n",
    "    def get_config(self):\n",
    "      config = super().get_config()\n",
    "      config.update(\n",
    "          {\n",
    "              \"num_kv_heads\": self.num_kv_heads,\n",
    "              \"embed_dim\": self.embed_dim,\n",
    "              \"num_heads\": self.num_heads,\n",
    "              \"ff_dim\": self.ff_dim,\n",
    "              \"dropout_rate\": self.dropout_rate,\n",
    "          }\n",
    "      )\n",
    "      return config\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # Assumes input_shape is [batch_size, sequence_length, hidden_size]\n",
    "        #input_shape = keras.ops.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        sequence_length = input_shape[1]\n",
    "        hidden_size = input_shape[2]\n",
    "        return [batch_size, sequence_length, hidden_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "benWOE24IWzw"
   },
   "source": [
    "### Distribution Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "3S7_BA6t4HcH"
   },
   "outputs": [],
   "source": [
    "DISTRIBUTION=\"fsdp\" #@param {\"type\":\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIBxOGDsZRBe",
    "outputId": "8e192b88-0f0c-48da-9bc6-8df7b58da30e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FSDP\n"
     ]
    }
   ],
   "source": [
    "# If there are multiple GPUs, we pick a data-parallel distribution strategy\n",
    "# aka mirrored strategy in Tensorflow.\n",
    "if num_gpus>=2:\n",
    "  if DISTRIBUTION==\"dp\":\n",
    "    data_parallel = keras.distribution.DataParallel()\n",
    "    keras.distribution.set_distribution(data_parallel)\n",
    "    print(\"Data Parallel\")\n",
    "      \n",
    "  elif DISTRIBUTION==\"fsdp\":\n",
    "    print(\"FSDP\")\n",
    "    # FSDP ##\n",
    "    # Or you can choose to create DataParallel with a 1D `DeviceMesh`.\n",
    "    device_mesh = keras.distribution.DeviceMesh(\n",
    "        shape=(num_gpus,), axis_names=[\"model\"], devices=gpus\n",
    "    )\n",
    "    layout_map = keras.distribution.LayoutMap(device_mesh)\n",
    "\n",
    "    # Partitioning for embeddings (regex)\n",
    "    layout_map[\"embedding/embeddings\"] = (None, \"model\")\n",
    "    # Partitioning (regex) for attention layer weights\n",
    "    layout_map[\"transformer_block.*attn.*(query|key|value).*kernel\"] = (None, \"model\", None)\n",
    "    layout_map[\"transformer_block.*attention_output.*kernel\"] = (None, None, \"model\")\n",
    "    layout_map[\"transformer_block.*swiglu_gate.*kernel\"] = (\"model\", None)\n",
    "    layout_map[\"transformer_block.*swiglu_linear.*kernel\"] = (\"model\", None)\n",
    "    layout_map[\"transformer_block.*ffnlinear.*kernel\"] = (None, \"model\")\n",
    "    #layout_map[\"outputs/kernel\"] = ( None, \"model\")\n",
    "\n",
    "    ##FSDP##\n",
    "    model_parallel = keras.distribution.ModelParallel(layout_map=layout_map, batch_dim_name=\"model\")\n",
    "    keras.distribution.set_distribution(model_parallel)\n",
    "\n",
    "  elif DISTRIBUTION==\"mp\":\n",
    "    print(\"Model Parallel\")\n",
    "    ## MODEL PARALLEL ##\n",
    "    device_mesh=keras.distribution.DeviceMesh(\n",
    "        shape=(1,8),\n",
    "        axis_names=[\"data\", \"model\"],\n",
    "        devices=gpus\n",
    "    )\n",
    "    layout_map = keras.distribution.LayoutMap(device_mesh)\n",
    "    # Partitioning for embeddings (regex)\n",
    "    layout_map[\"embedding/embeddings\"] = (None, \"model\")\n",
    "    # Partitioning (regex) for attention layer weights\n",
    "    layout_map[\"transformer_block.*attn.*(query|key|value).*kernel\"] = (None, \"model\", None)\n",
    "    layout_map[\"transformer_block.*attention_output.*kernel\"] = (None, None, \"model\")\n",
    "    layout_map[\"transformer_block.*swiglu_gate.*kernel\"] = (\"model\", None)\n",
    "    layout_map[\"transformer_block.*swiglu_linear.*kernel\"] = (\"model\", None)\n",
    "    layout_map[\"transformer_block.*ffnlinear.*kernel\"] = (None, \"model\")\n",
    "    #layout_map[\"outputs/kernel\"] = ( None, \"model\")\n",
    "\n",
    "    # Partitioning (regex) for attention layer weights\n",
    "    #layout_map[\"transformer_decoder_\\d+.*self_attention.*(query|key|value).*kernel\"] = (None, \"model\", None)\n",
    "    #layout_map[\"transformer_decoder_\\d+.*self_attention/attention_output.*kernel\"] = (None, None, \"model\")\n",
    "    #layout_map[\"transformer_decoder_\\d+.*feedforward_intermediate_dense.*kernel\"] = (\"model\", None)\n",
    "    #layout_map[\"transformer_decoder_\\d+.*feedforward_output_dense.*kernel\"] = (None, \"model\")\n",
    "    #layout_map[\"outputs/kernel\"] = ( None, \"model\")\n",
    "\n",
    "    ##Hybrid DP/MP\n",
    "    model_parallel = keras.distribution.ModelParallel(layout_map=layout_map, batch_dim_name=\"data\")\n",
    "    keras.distribution.set_distribution(model_parallel)\n",
    "      \n",
    "  else:\n",
    "    print (\"No distribution strategy selected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8eJGGKzIWzw"
   },
   "source": [
    "**Note:** JIT compilation is slow at the beginning and may cause some issues with placement in distributed training. However, it does accelerate the training once the compilation completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFUEK4YZZPss",
    "outputId": "0119a0ad-c5ba-45e6-94df-6702ad6ff25c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_layout_map': OrderedDict([('embedding/embeddings',\n",
       "               <TensorLayout axes=(None, 'model'), device_mesh=<DeviceMesh shape=(8,), axis_names=['model']>>),\n",
       "              ('transformer_block.*attn.*(query|key|value).*kernel',\n",
       "               <TensorLayout axes=(None, 'model', None), device_mesh=<DeviceMesh shape=(8,), axis_names=['model']>>),\n",
       "              ('transformer_block.*attention_output.*kernel',\n",
       "               <TensorLayout axes=(None, None, 'model'), device_mesh=<DeviceMesh shape=(8,), axis_names=['model']>>),\n",
       "              ('transformer_block.*swiglu_gate.*kernel',\n",
       "               <TensorLayout axes=('model', None), device_mesh=<DeviceMesh shape=(8,), axis_names=['model']>>),\n",
       "              ('transformer_block.*swiglu_linear.*kernel',\n",
       "               <TensorLayout axes=('model', None), device_mesh=<DeviceMesh shape=(8,), axis_names=['model']>>),\n",
       "              ('transformer_block.*ffnlinear.*kernel',\n",
       "               <TensorLayout axes=(None, 'model'), device_mesh=<DeviceMesh shape=(8,), axis_names=['model']>>)]),\n",
       " '_device_mesh': <DeviceMesh shape=(8,), axis_names=['model']>}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout_map.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crv2Wt7RRU9k"
   },
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "0oVWtpt_FDY8"
   },
   "outputs": [],
   "source": [
    "## Optimizer with decaying weights\n",
    "optimizer=keras.optimizers.AdamW(learning_rate=1e-5*num_gpus,\n",
    "                            weight_decay=0.2,\n",
    "                            beta_1=0.9,\n",
    "                            beta_2=0.95,\n",
    "                            epsilon=1e-5,\n",
    "                            )\n",
    "\n",
    "\n",
    "## Model definition\n",
    "inputs = keras.layers.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "## From Llama\n",
    "x=layers.Embedding(input_dim=VOCAB_SIZE, output_dim=EMBEDDING_DIM)(inputs)\n",
    "\n",
    "for i in range(NUM_BLOCKS):\n",
    "\n",
    "  # Create a new TransformerBlock instance in each iteration\n",
    "  x = TransformerBlock(\n",
    "      N_HEADS, N_KV_HEADS, EMBEDDING_DIM, FEED_FORWARD_DIM, dropout_rate=0.2,\n",
    "      name=f\"transformer_block_{i}\",\n",
    "  )(x)\n",
    "\n",
    "x=LayerNormalization()(x)\n",
    "\n",
    "outputs = Dense(VOCAB_SIZE,\n",
    "              use_bias=False,\n",
    "              #activation=\"softmax\" #we'll use the logits\n",
    "              dtype=\"float32\",\n",
    "              name=\"output\"\n",
    "              )(x)\n",
    "\n",
    "gpt = keras.Model(inputs=inputs, outputs=[outputs])\n",
    "gpt.compile(optimizer=optimizer,\n",
    "            loss=[losses.SparseCategoricalCrossentropy(from_logits=True)],\n",
    "            metrics=[keras_hub.metrics.Perplexity(from_logits=True, mask_token_id=0)],\n",
    "            jit_compile=True # Disable JIT compilation\n",
    "           )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42JntCDJFpUn",
    "outputId": "9a8f41fd-8d59-44f5-b2e0-e6af09de7297"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 8 8\n"
     ]
    }
   ],
   "source": [
    "print (N_HEADS, N_KV_HEADS, NUM_BLOCKS, num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B23_CHvE9eLh"
   },
   "source": [
    "Model variables and their shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "6S82gDyaTHKp",
    "outputId": "f6b0a241-9ef0-4682-8658-8bedb1cb23b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_0             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m3,840,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_0             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │         \u001b[38;5;34m1,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m)     │     \u001b[38;5;34m3,840,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,329,216</span> (245.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m64,329,216\u001b[0m (245.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,329,216</span> (245.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m64,329,216\u001b[0m (245.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhjkA2Z6IWzw",
    "outputId": "d5b8aa54-614e-48bd-a00f-c6fc008745b5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding/embeddings (5000, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model'), memory_kind=device)\n",
      "transformer_block_0/attn/query/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_0/attn/key/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_0/attn/value/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_0/attn/attention_output/kernel (8, 96, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, None, 'model'), memory_kind=device)\n",
      "seed_generator/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_0/layer_normalization/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_0/layer_normalization/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_0/ffnswiglu/swiglu_gate/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_0/ffnswiglu/swiglu_linear/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_0/ffnlinear/kernel (2048, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model'), memory_kind=device)\n",
      "seed_generator_1/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_0/layer_normalization_1/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_0/layer_normalization_1/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_1/attn/query/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_1/attn/key/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_1/attn/value/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_1/attn/attention_output/kernel (8, 96, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, None, 'model'), memory_kind=device)\n",
      "seed_generator_2/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_1/layer_normalization_2/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_1/layer_normalization_2/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_1/ffnswiglu/swiglu_gate/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_1/ffnswiglu/swiglu_linear/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_1/ffnlinear/kernel (2048, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model'), memory_kind=device)\n",
      "seed_generator_3/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_1/layer_normalization_3/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_1/layer_normalization_3/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_2/attn/query/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_2/attn/key/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_2/attn/value/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_2/attn/attention_output/kernel (8, 96, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, None, 'model'), memory_kind=device)\n",
      "seed_generator_4/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_2/layer_normalization_4/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_2/layer_normalization_4/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_2/ffnswiglu/swiglu_gate/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_2/ffnswiglu/swiglu_linear/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_2/ffnlinear/kernel (2048, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model'), memory_kind=device)\n",
      "seed_generator_5/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_2/layer_normalization_5/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_2/layer_normalization_5/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_3/attn/query/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_3/attn/key/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_3/attn/value/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_3/attn/attention_output/kernel (8, 96, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, None, 'model'), memory_kind=device)\n",
      "seed_generator_6/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_3/layer_normalization_6/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_3/layer_normalization_6/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_3/ffnswiglu/swiglu_gate/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_3/ffnswiglu/swiglu_linear/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_3/ffnlinear/kernel (2048, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model'), memory_kind=device)\n",
      "seed_generator_7/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_3/layer_normalization_7/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_3/layer_normalization_7/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_4/attn/query/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_4/attn/key/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_4/attn/value/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_4/attn/attention_output/kernel (8, 96, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, None, 'model'), memory_kind=device)\n",
      "seed_generator_8/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_4/layer_normalization_8/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_4/layer_normalization_8/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_4/ffnswiglu/swiglu_gate/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_4/ffnswiglu/swiglu_linear/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_4/ffnlinear/kernel (2048, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model'), memory_kind=device)\n",
      "seed_generator_9/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_4/layer_normalization_9/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_4/layer_normalization_9/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_5/attn/query/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_5/attn/key/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_5/attn/value/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_5/attn/attention_output/kernel (8, 96, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, None, 'model'), memory_kind=device)\n",
      "seed_generator_10/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_5/layer_normalization_10/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_5/layer_normalization_10/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_5/ffnswiglu/swiglu_gate/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_5/ffnswiglu/swiglu_linear/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_5/ffnlinear/kernel (2048, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model'), memory_kind=device)\n",
      "seed_generator_11/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_5/layer_normalization_11/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_5/layer_normalization_11/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_6/attn/query/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_6/attn/key/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_6/attn/value/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_6/attn/attention_output/kernel (8, 96, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, None, 'model'), memory_kind=device)\n",
      "seed_generator_12/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_6/layer_normalization_12/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_6/layer_normalization_12/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_6/ffnswiglu/swiglu_gate/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_6/ffnswiglu/swiglu_linear/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_6/ffnlinear/kernel (2048, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model'), memory_kind=device)\n",
      "seed_generator_13/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_6/layer_normalization_13/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_6/layer_normalization_13/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_7/attn/query/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_7/attn/key/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_7/attn/value/kernel (768, 8, 96) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model', None), memory_kind=device)\n",
      "transformer_block_7/attn/attention_output/kernel (8, 96, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, None, 'model'), memory_kind=device)\n",
      "seed_generator_14/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_7/layer_normalization_14/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_7/layer_normalization_14/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_7/ffnswiglu/swiglu_gate/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_7/ffnswiglu/swiglu_linear/kernel (768, 2048) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec('model', None), memory_kind=device)\n",
      "transformer_block_7/ffnlinear/kernel (2048, 768) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, 'model'), memory_kind=device)\n",
      "seed_generator_15/seed_generator_state (2,) uint32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_7/layer_normalization_15/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "transformer_block_7/layer_normalization_15/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "layer_normalization_16/gamma (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "layer_normalization_16/beta (768,) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None,), memory_kind=device)\n",
      "output/kernel (768, 5000) float32 NamedSharding(mesh=Mesh('model': 8, axis_types=(Auto,)), spec=PartitionSpec(None, None), memory_kind=device)\n"
     ]
    }
   ],
   "source": [
    "for v in gpt.variables:\n",
    "    print(v.path, v.shape, v.dtype, v.value.sharding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsTANJMpyl-a"
   },
   "source": [
    "## Compile and Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKuZ3EXfTXdv"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "The4T4o19jxj"
   },
   "source": [
    "Callbacks for checkpointing and tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "N1CNdBfXyb9p"
   },
   "outputs": [],
   "source": [
    "earlystop=keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "TXqnrZZkjLqy"
   },
   "outputs": [],
   "source": [
    "tensorboard=keras.callbacks.TensorBoard(\n",
    "    log_dir=BASE_DIR+\"/logs\",\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=False,\n",
    "    write_steps_per_second=False,\n",
    "    update_freq=\"epoch\",\n",
    "    profile_batch=0,\n",
    "    embeddings_freq=1,\n",
    "    embeddings_metadata=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Uu-KLr1uPxV9"
   },
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=BASE_DIR+\"/models/checkpoints/gpu/colmo-\"+datetime.now().strftime(\"%Y%m%d-%H%M%S\")+\".keras\",\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    save_freq=\"epoch\",\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KPt89Su9qwl"
   },
   "source": [
    "Main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "Yj--H7xOStZd",
    "outputId": "0aab8567-797a-433e-fe5f-e145b55458d8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "    982/Unknown \u001b[1m243s\u001b[0m 185ms/step - loss: 1.5853 - perplexity: 583.7316\n",
      "Epoch 1: val_loss improved from inf to 0.75317, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 221ms/step - loss: 1.5850 - perplexity: 583.3415 - val_loss: 0.7532 - val_perplexity: 95.4172\n",
      "Epoch 2/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 1.1883 - perplexity: 114.9340\n",
      "Epoch 2: val_loss improved from 0.75317 to 0.71147, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 203ms/step - loss: 1.1883 - perplexity: 114.9274 - val_loss: 0.7115 - val_perplexity: 74.0498\n",
      "Epoch 3/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 1.1424 - perplexity: 92.2984\n",
      "Epoch 3: val_loss improved from 0.71147 to 0.66998, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 1.1423 - perplexity: 92.2926 - val_loss: 0.6700 - val_perplexity: 57.5937\n",
      "Epoch 4/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 1.0743 - perplexity: 72.0085\n",
      "Epoch 4: val_loss improved from 0.66998 to 0.63649, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 1.0743 - perplexity: 72.0043 - val_loss: 0.6365 - val_perplexity: 47.0434\n",
      "Epoch 5/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 1.0156 - perplexity: 58.8157\n",
      "Epoch 5: val_loss improved from 0.63649 to 0.61375, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 1.0156 - perplexity: 58.8131 - val_loss: 0.6137 - val_perplexity: 41.0693\n",
      "Epoch 6/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.9892 - perplexity: 51.2699\n",
      "Epoch 6: val_loss improved from 0.61375 to 0.59850, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 0.9892 - perplexity: 51.2685 - val_loss: 0.5985 - val_perplexity: 37.4252\n",
      "Epoch 7/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.9643 - perplexity: 46.8754\n",
      "Epoch 7: val_loss improved from 0.59850 to 0.58892, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 201ms/step - loss: 0.9643 - perplexity: 46.8743 - val_loss: 0.5889 - val_perplexity: 35.2270\n",
      "Epoch 8/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.9486 - perplexity: 43.6310\n",
      "Epoch 8: val_loss improved from 0.58892 to 0.58112, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 201ms/step - loss: 0.9486 - perplexity: 43.6300 - val_loss: 0.5811 - val_perplexity: 33.6433\n",
      "Epoch 9/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.9346 - perplexity: 40.8792\n",
      "Epoch 9: val_loss improved from 0.58112 to 0.57657, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 0.9346 - perplexity: 40.8786 - val_loss: 0.5766 - val_perplexity: 32.6850\n",
      "Epoch 10/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.9188 - perplexity: 39.0029\n",
      "Epoch 10: val_loss improved from 0.57657 to 0.56960, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 0.9188 - perplexity: 39.0024 - val_loss: 0.5696 - val_perplexity: 31.3318\n",
      "Epoch 11/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.9013 - perplexity: 37.3330\n",
      "Epoch 11: val_loss improved from 0.56960 to 0.56146, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 0.9013 - perplexity: 37.3326 - val_loss: 0.5615 - val_perplexity: 29.7645\n",
      "Epoch 12/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8996 - perplexity: 36.2625\n",
      "Epoch 12: val_loss improved from 0.56146 to 0.56100, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 201ms/step - loss: 0.8996 - perplexity: 36.2618 - val_loss: 0.5610 - val_perplexity: 29.7954\n",
      "Epoch 13/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.9005 - perplexity: 35.0290\n",
      "Epoch 13: val_loss improved from 0.56100 to 0.55355, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 0.9005 - perplexity: 35.0284 - val_loss: 0.5536 - val_perplexity: 28.4899\n",
      "Epoch 14/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8834 - perplexity: 33.8199\n",
      "Epoch 14: val_loss improved from 0.55355 to 0.55322, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 201ms/step - loss: 0.8834 - perplexity: 33.8196 - val_loss: 0.5532 - val_perplexity: 28.3714\n",
      "Epoch 15/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8755 - perplexity: 32.9526\n",
      "Epoch 15: val_loss improved from 0.55322 to 0.54455, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 201ms/step - loss: 0.8755 - perplexity: 32.9523 - val_loss: 0.5446 - val_perplexity: 26.9680\n",
      "Epoch 16/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8734 - perplexity: 32.1304\n",
      "Epoch 16: val_loss did not improve from 0.54455\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 193ms/step - loss: 0.8734 - perplexity: 32.1302 - val_loss: 0.5462 - val_perplexity: 27.2103\n",
      "Epoch 17/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8642 - perplexity: 31.3879\n",
      "Epoch 17: val_loss improved from 0.54455 to 0.54145, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 0.8642 - perplexity: 31.3877 - val_loss: 0.5414 - val_perplexity: 26.4286\n",
      "Epoch 18/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8609 - perplexity: 30.9123\n",
      "Epoch 18: val_loss improved from 0.54145 to 0.53912, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 202ms/step - loss: 0.8609 - perplexity: 30.9119 - val_loss: 0.5391 - val_perplexity: 26.1137\n",
      "Epoch 19/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8550 - perplexity: 30.2688\n",
      "Epoch 19: val_loss did not improve from 0.53912\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 193ms/step - loss: 0.8550 - perplexity: 30.2686 - val_loss: 0.5406 - val_perplexity: 26.3156\n",
      "Epoch 20/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8590 - perplexity: 29.7982\n",
      "Epoch 20: val_loss improved from 0.53912 to 0.53273, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 201ms/step - loss: 0.8590 - perplexity: 29.7979 - val_loss: 0.5327 - val_perplexity: 25.1431\n",
      "Epoch 21/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8411 - perplexity: 29.2245\n",
      "Epoch 21: val_loss improved from 0.53273 to 0.53003, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 0.8411 - perplexity: 29.2243 - val_loss: 0.5300 - val_perplexity: 24.6948\n",
      "Epoch 22/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8458 - perplexity: 28.8340\n",
      "Epoch 22: val_loss did not improve from 0.53003\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 193ms/step - loss: 0.8458 - perplexity: 28.8338 - val_loss: 0.5324 - val_perplexity: 25.0366\n",
      "Epoch 23/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8401 - perplexity: 28.4927\n",
      "Epoch 23: val_loss improved from 0.53003 to 0.52886, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 0.8401 - perplexity: 28.4924 - val_loss: 0.5289 - val_perplexity: 24.5199\n",
      "Epoch 24/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8413 - perplexity: 28.1515\n",
      "Epoch 24: val_loss did not improve from 0.52886\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 193ms/step - loss: 0.8413 - perplexity: 28.1512 - val_loss: 0.5299 - val_perplexity: 24.6888\n",
      "Epoch 25/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8216 - perplexity: 27.4218\n",
      "Epoch 25: val_loss improved from 0.52886 to 0.52797, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 203ms/step - loss: 0.8216 - perplexity: 27.4218 - val_loss: 0.5280 - val_perplexity: 24.3898\n",
      "Epoch 26/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8306 - perplexity: 27.2145\n",
      "Epoch 26: val_loss improved from 0.52797 to 0.52392, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 202ms/step - loss: 0.8306 - perplexity: 27.2145 - val_loss: 0.5239 - val_perplexity: 23.7781\n",
      "Epoch 27/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8199 - perplexity: 26.9783\n",
      "Epoch 27: val_loss improved from 0.52392 to 0.52376, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 202ms/step - loss: 0.8199 - perplexity: 26.9782 - val_loss: 0.5238 - val_perplexity: 23.7906\n",
      "Epoch 28/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8165 - perplexity: 26.5204\n",
      "Epoch 28: val_loss improved from 0.52376 to 0.52104, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 202ms/step - loss: 0.8165 - perplexity: 26.5204 - val_loss: 0.5210 - val_perplexity: 23.4130\n",
      "Epoch 29/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8216 - perplexity: 26.3447\n",
      "Epoch 29: val_loss improved from 0.52104 to 0.52097, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 202ms/step - loss: 0.8216 - perplexity: 26.3446 - val_loss: 0.5210 - val_perplexity: 23.3652\n",
      "Epoch 30/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8189 - perplexity: 26.1654\n",
      "Epoch 30: val_loss improved from 0.52097 to 0.51754, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 0.8189 - perplexity: 26.1653 - val_loss: 0.5175 - val_perplexity: 22.8929\n",
      "Epoch 31/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8161 - perplexity: 25.7888\n",
      "Epoch 31: val_loss did not improve from 0.51754\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 193ms/step - loss: 0.8161 - perplexity: 25.7887 - val_loss: 0.5183 - val_perplexity: 23.0164\n",
      "Epoch 32/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8122 - perplexity: 25.6635\n",
      "Epoch 32: val_loss improved from 0.51754 to 0.51660, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 201ms/step - loss: 0.8122 - perplexity: 25.6634 - val_loss: 0.5166 - val_perplexity: 22.7990\n",
      "Epoch 33/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8132 - perplexity: 25.4224\n",
      "Epoch 33: val_loss improved from 0.51660 to 0.51523, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 201ms/step - loss: 0.8132 - perplexity: 25.4223 - val_loss: 0.5152 - val_perplexity: 22.5752\n",
      "Epoch 34/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8086 - perplexity: 25.2848\n",
      "Epoch 34: val_loss did not improve from 0.51523\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 193ms/step - loss: 0.8086 - perplexity: 25.2847 - val_loss: 0.5180 - val_perplexity: 22.9363\n",
      "Epoch 35/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8132 - perplexity: 25.1909\n",
      "Epoch 35: val_loss did not improve from 0.51523\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 193ms/step - loss: 0.8132 - perplexity: 25.1906 - val_loss: 0.5170 - val_perplexity: 22.8418\n",
      "Epoch 36/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8051 - perplexity: 24.7833\n",
      "Epoch 36: val_loss did not improve from 0.51523\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 194ms/step - loss: 0.8051 - perplexity: 24.7832 - val_loss: 0.5155 - val_perplexity: 22.6071\n",
      "Epoch 37/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8030 - perplexity: 24.6384\n",
      "Epoch 37: val_loss improved from 0.51523 to 0.51500, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 0.8030 - perplexity: 24.6383 - val_loss: 0.5150 - val_perplexity: 22.5732\n",
      "Epoch 38/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7988 - perplexity: 24.5285\n",
      "Epoch 38: val_loss improved from 0.51500 to 0.51349, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 0.7988 - perplexity: 24.5283 - val_loss: 0.5135 - val_perplexity: 22.3397\n",
      "Epoch 39/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7953 - perplexity: 24.2608\n",
      "Epoch 39: val_loss improved from 0.51349 to 0.51171, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 202ms/step - loss: 0.7953 - perplexity: 24.2607 - val_loss: 0.5117 - val_perplexity: 22.0845\n",
      "Epoch 40/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7963 - perplexity: 24.0508\n",
      "Epoch 40: val_loss did not improve from 0.51171\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 193ms/step - loss: 0.7963 - perplexity: 24.0507 - val_loss: 0.5126 - val_perplexity: 22.2150\n",
      "Epoch 41/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7975 - perplexity: 23.9929\n",
      "Epoch 41: val_loss improved from 0.51171 to 0.51120, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 201ms/step - loss: 0.7975 - perplexity: 23.9928 - val_loss: 0.5112 - val_perplexity: 22.0236\n",
      "Epoch 42/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.8001 - perplexity: 23.7699\n",
      "Epoch 42: val_loss improved from 0.51120 to 0.50695, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 202ms/step - loss: 0.8000 - perplexity: 23.7699 - val_loss: 0.5070 - val_perplexity: 21.4979\n",
      "Epoch 43/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7957 - perplexity: 23.6379\n",
      "Epoch 43: val_loss did not improve from 0.50695\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 193ms/step - loss: 0.7957 - perplexity: 23.6378 - val_loss: 0.5092 - val_perplexity: 21.7889\n",
      "Epoch 44/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7981 - perplexity: 23.6159\n",
      "Epoch 44: val_loss did not improve from 0.50695\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 193ms/step - loss: 0.7980 - perplexity: 23.6158 - val_loss: 0.5078 - val_perplexity: 21.5476\n",
      "Epoch 45/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7909 - perplexity: 23.4310\n",
      "Epoch 45: val_loss improved from 0.50695 to 0.50653, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 202ms/step - loss: 0.7909 - perplexity: 23.4309 - val_loss: 0.5065 - val_perplexity: 21.4569\n",
      "Epoch 46/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7942 - perplexity: 23.2691\n",
      "Epoch 46: val_loss improved from 0.50653 to 0.50593, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 0.7942 - perplexity: 23.2690 - val_loss: 0.5059 - val_perplexity: 21.3392\n",
      "Epoch 47/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7877 - perplexity: 23.1053\n",
      "Epoch 47: val_loss did not improve from 0.50593\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 193ms/step - loss: 0.7877 - perplexity: 23.1052 - val_loss: 0.5071 - val_perplexity: 21.5052\n",
      "Epoch 48/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7813 - perplexity: 22.9799\n",
      "Epoch 48: val_loss improved from 0.50593 to 0.50498, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 201ms/step - loss: 0.7813 - perplexity: 22.9799 - val_loss: 0.5050 - val_perplexity: 21.2395\n",
      "Epoch 49/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7803 - perplexity: 22.9429\n",
      "Epoch 49: val_loss did not improve from 0.50498\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 193ms/step - loss: 0.7803 - perplexity: 22.9428 - val_loss: 0.5053 - val_perplexity: 21.2705\n",
      "Epoch 50/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7836 - perplexity: 22.7588\n",
      "Epoch 50: val_loss did not improve from 0.50498\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 193ms/step - loss: 0.7836 - perplexity: 22.7588 - val_loss: 0.5058 - val_perplexity: 21.3590\n",
      "Epoch 51/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7832 - perplexity: 22.7380\n",
      "Epoch 51: val_loss improved from 0.50498 to 0.50482, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 202ms/step - loss: 0.7832 - perplexity: 22.7379 - val_loss: 0.5048 - val_perplexity: 21.1995\n",
      "Epoch 52/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7789 - perplexity: 22.4879\n",
      "Epoch 52: val_loss improved from 0.50482 to 0.50384, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 202ms/step - loss: 0.7789 - perplexity: 22.4880 - val_loss: 0.5038 - val_perplexity: 21.0970\n",
      "Epoch 53/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7782 - perplexity: 22.5487\n",
      "Epoch 53: val_loss did not improve from 0.50384\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 193ms/step - loss: 0.7782 - perplexity: 22.5486 - val_loss: 0.5093 - val_perplexity: 21.7876\n",
      "Epoch 54/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7769 - perplexity: 22.5080\n",
      "Epoch 54: val_loss improved from 0.50384 to 0.50189, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 202ms/step - loss: 0.7769 - perplexity: 22.5079 - val_loss: 0.5019 - val_perplexity: 20.8550\n",
      "Epoch 55/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7814 - perplexity: 22.1860\n",
      "Epoch 55: val_loss did not improve from 0.50189\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 193ms/step - loss: 0.7814 - perplexity: 22.1860 - val_loss: 0.5035 - val_perplexity: 21.0240\n",
      "Epoch 56/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7797 - perplexity: 22.2202\n",
      "Epoch 56: val_loss improved from 0.50189 to 0.50121, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 0.7797 - perplexity: 22.2201 - val_loss: 0.5012 - val_perplexity: 20.7688\n",
      "Epoch 57/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7722 - perplexity: 22.0721\n",
      "Epoch 57: val_loss improved from 0.50121 to 0.49863, saving model to ./working/models/checkpoints/gpu/colmo-20250525-065056.keras\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 201ms/step - loss: 0.7722 - perplexity: 22.0721 - val_loss: 0.4986 - val_perplexity: 20.4336\n",
      "Epoch 58/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7737 - perplexity: 22.0276\n",
      "Epoch 58: val_loss did not improve from 0.49863\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 193ms/step - loss: 0.7737 - perplexity: 22.0275 - val_loss: 0.5035 - val_perplexity: 21.0488\n",
      "Epoch 59/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7753 - perplexity: 21.9079\n",
      "Epoch 59: val_loss did not improve from 0.49863\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 192ms/step - loss: 0.7753 - perplexity: 21.9079 - val_loss: 0.5033 - val_perplexity: 21.0268\n",
      "Epoch 60/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7776 - perplexity: 21.9261\n",
      "Epoch 60: val_loss did not improve from 0.49863\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 193ms/step - loss: 0.7776 - perplexity: 21.9259 - val_loss: 0.5021 - val_perplexity: 20.8234\n",
      "Epoch 61/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7737 - perplexity: 21.7229\n",
      "Epoch 61: val_loss did not improve from 0.49863\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 193ms/step - loss: 0.7737 - perplexity: 21.7229 - val_loss: 0.5009 - val_perplexity: 20.6696\n",
      "Epoch 62/500\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - loss: 0.7731 - perplexity: 21.7530\n",
      "Epoch 62: val_loss did not improve from 0.49863\n",
      "\u001b[1m982/982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 193ms/step - loss: 0.7731 - perplexity: 21.7528 - val_loss: 0.5030 - val_perplexity: 20.9719\n",
      "Epoch 62: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "CPU times: user 4h 47min 14s, sys: 56min 12s, total: 5h 43min 27s\n",
      "Wall time: 3h 41min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history=gpt.fit(train_ds,\n",
    "                validation_data=val_ds,\n",
    "                epochs=500,\n",
    "                callbacks=[earlystop, tensorboard, checkpoint],\n",
    "                verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "hkuOoDYnSUA-",
    "outputId": "bc4bf038-4296-461c-c1e8-b4f62c01bbd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.4986 - perplexity: 20.4336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4986252784729004, 20.43361473083496]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyQOJE31gvi_"
   },
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "gHY4p-1dgz4N"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_0             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,080,960</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m3,840,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_0             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │     \u001b[38;5;34m7,080,960\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │         \u001b[38;5;34m1,536\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m)     │     \u001b[38;5;34m3,840,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192,987,650</span> (736.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m192,987,650\u001b[0m (736.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,329,216</span> (245.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m64,329,216\u001b[0m (245.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128,658,434</span> (490.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m128,658,434\u001b[0m (490.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpt.summary()\n",
    "gpt.save(BASE_DIR+'/models/colmo-simplebooks-pt.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AucPt9JgaSNq"
   },
   "source": [
    "## Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "YA5Q0GCueWSD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f13479049a0>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['perplexity'])\n",
    "plt.plot(history.history['val_perplexity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8oMXHjhFkyI"
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension if available\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBknA2_NF3nQ"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir $BASE_DIR/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI2Q0SkMGfdE"
   },
   "source": [
    "## Inference with pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "znPUvmQaXb-E"
   },
   "outputs": [],
   "source": [
    "prompt_tokens = start_packer(tokenizer([\"\"]))\n",
    "prompt_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znnw6VE_9xKR"
   },
   "source": [
    "Function to compute next token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ktqqBIrZh5L"
   },
   "outputs": [],
   "source": [
    "def next(prompt, cache, index):\n",
    "    logits = gpt(prompt)[:, index - 1, :]\n",
    "    # Ignore hidden states for now\n",
    "    hidden_states = None\n",
    "    return logits, hidden_states, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nhim3CmHGqwm"
   },
   "source": [
    "### Test different kinds of samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDOF0mkGZqNb"
   },
   "outputs": [],
   "source": [
    "sampler = keras_hub.samplers.GreedySampler()\n",
    "output_tokens = sampler(\n",
    "    next=next,\n",
    "    prompt=prompt_tokens,\n",
    "    index=1,  # Start sampling immediately after the [BOS] token.\n",
    ")\n",
    "txt = tokenizer.detokenize(output_tokens)\n",
    "print(f\"Greedy search generated text: \\n{txt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHGkN_ZiZtD_"
   },
   "outputs": [],
   "source": [
    "sampler = keras_hub.samplers.BeamSampler(num_beams=2)\n",
    "output_tokens = sampler(\n",
    "    next=next,\n",
    "    prompt=prompt_tokens,\n",
    "    index=1,\n",
    ")\n",
    "txt = tokenizer.detokenize(output_tokens)\n",
    "print(f\"Beam search generated text: \\n{txt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3TpdDQNragzB"
   },
   "outputs": [],
   "source": [
    "sampler = keras_hub.samplers.TopKSampler(k=5, temperature=1.0)\n",
    "output_tokens = sampler(\n",
    "    next=next,\n",
    "    prompt=prompt_tokens,\n",
    "    index=1,\n",
    ")\n",
    "txt = tokenizer.detokenize(output_tokens)\n",
    "print(f\"Top-K search generated text: \\n{txt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FXB7u5draoNa"
   },
   "outputs": [],
   "source": [
    "sampler = keras_hub.samplers.TopPSampler(p=0.9, k=10, temperature=1.0)\n",
    "output_tokens = sampler(\n",
    "    next=next,\n",
    "    prompt=prompt_tokens,\n",
    "    index=1,\n",
    ")\n",
    "txt = tokenizer.detokenize(output_tokens)\n",
    "print(f\"Top-P search generated text: \\n{txt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHRt5e7BarQi"
   },
   "outputs": [],
   "source": [
    "class TopKTextGenerator(keras.callbacks.Callback):\n",
    "    \"\"\"A callback to generate text from a trained model using top-k.\"\"\"\n",
    "\n",
    "    def __init__(self, k, temperature):\n",
    "        self.sampler = keras_hub.samplers.TopKSampler(k=k, temperature=temperature)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        output_tokens = self.sampler(\n",
    "            next=next,\n",
    "            prompt=prompt_tokens,\n",
    "            index=1,\n",
    "        )\n",
    "        txt = tokenizer.detokenize(output_tokens)\n",
    "        print(f\"\\nTop-K search generated text: \\n{txt}\\n\")\n",
    "\n",
    "\n",
    "text_generation_callback = TopKTextGenerator(k=5, temperature=1.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKu1gEoohLys"
   },
   "outputs": [],
   "source": [
    "class TopPTextGenerator(keras.callbacks.Callback):\n",
    "    \"\"\"A callback to generate text from a trained model using top-p.\"\"\"\n",
    "\n",
    "    def __init__(self, p, k, temperature):\n",
    "        self.sampler = keras_hub.samplers.TopPSampler(p=p, k=k, temperature=temperature)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        output_tokens = self.sampler(\n",
    "            next=next,\n",
    "            prompt=prompt_tokens,\n",
    "            index=1,\n",
    "        )\n",
    "        txt = tokenizer.detokenize(output_tokens)\n",
    "        print(f\"\\nTop-P search generated text: \\n{txt}\\n\")\n",
    "\n",
    "\n",
    "text_generation_callback = TopPTextGenerator(p=0.8, k=5, temperature=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTGuHfkoIFXh"
   },
   "source": [
    "### Optional: keep training with callbacks VERY SLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8FcHr7FghJ2"
   },
   "outputs": [],
   "source": [
    "# Dummy training loop to demonstrate callback.\n",
    "gpt.fit(train_ds.take(1), verbose=1, epochs=1, callbacks=[text_generation_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7LBxaGMzDSQ"
   },
   "outputs": [],
   "source": [
    "# Training loop with callbacks\n",
    "#gpt.fit(train_ds, validation_data=val_ds, epochs=100, callbacks=[earlystop, tensorboard, text_generation_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8TUxiA7XAfE"
   },
   "outputs": [],
   "source": [
    "gpt.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bs4is4t6mVWK"
   },
   "outputs": [],
   "source": [
    "gpt.save(BASE_DIR+'/models/pseudollam2-simplebooks-pt.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoNB09QigFoB"
   },
   "source": [
    "## Instruction tuning\n",
    "Read and preprocess Q&A dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdiaHHUigKO2"
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/vicgalle/alpaca-gpt4/data/train-00000-of-00001-6ef3991c06080e14.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzIwaI8egPcZ"
   },
   "outputs": [],
   "source": [
    "ds=tf_data.Dataset.from_tensor_slices(df[\"text\"]).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8D-zMrOKpVk"
   },
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obreWO-fgXov"
   },
   "outputs": [],
   "source": [
    "ids=ds.map(preprocess, num_parallel_calls=tf_data.AUTOTUNE).prefetch(tf_data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YW4I9SL5ggRc"
   },
   "outputs": [],
   "source": [
    "train_ids, val_ids=keras.utils.split_dataset(ids, left_size=0.8, shuffle=True, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ChzbTGZKXSw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for element in ds.take(1):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3eDpYi1kg33w"
   },
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "larEMatagkJk"
   },
   "outputs": [],
   "source": [
    "text_generation_callback = TopKTextGenerator(k=5, temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1SMRBwMguOE"
   },
   "outputs": [],
   "source": [
    "# Training loop with callbacks\n",
    "it_history= gpt.fit(train_ids,\n",
    "                    validation_data=val_ids,\n",
    "                    epochs=100,\n",
    "                    callbacks=[earlystop,\n",
    "                               #text_generation_callback, ## very slow so comment out\n",
    "                               tensorboard],\n",
    "                    verbose=1,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDV3TXUPocoW"
   },
   "outputs": [],
   "source": [
    "plt.plot(it_history.history['perplexity'])\n",
    "plt.plot(it_history.history['val_perplexity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZBYweDCop3P"
   },
   "outputs": [],
   "source": [
    "gpt.evaluate(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rGruQ6RdoheH"
   },
   "outputs": [],
   "source": [
    "gpt.save(BASE_DIR+'/models/colmo-simplebooks-it.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VwFMsG4Fn0wl"
   },
   "source": [
    "## Inference with I.T. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETJDmmB2IWzz"
   },
   "outputs": [],
   "source": [
    "# Don't want to wait for jit every single time we call predict\n",
    "gpt.jit_compile=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUlMW_qTn46m"
   },
   "outputs": [],
   "source": [
    "prompt_tokens = start_packer(tokenizer([\"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
    "Write a response that appropriately completes the request.\\n\\n\n",
    "Instruction:\\nWrite a list of 3 ingredients for a sandwich.\\n\\n\n",
    "Input:\\nno ham\\n\\n\n",
    "Response: \"\"\" ]))\n",
    "prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(prompt_tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2ZlJYgQn5_A"
   },
   "outputs": [],
   "source": [
    "np.where(np.array(prompt_tokens).flatten()==0)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8CA3aFPn9Fq"
   },
   "outputs": [],
   "source": [
    "sampler = keras_hub.samplers.TopPSampler(k=10,\n",
    "                                         p=0.5,\n",
    "                                         seed=SEED,\n",
    "                                         temperature=1.0\n",
    ")\n",
    "output_tokens = sampler(\n",
    "    next=next,\n",
    "    prompt=prompt_tokens,\n",
    "    index=np.where(np.array(prompt_tokens).flatten()==0)[0][0],\n",
    ")\n",
    "txt = tokenizer.detokenize(output_tokens)\n",
    "print(f\"Top-P search generated text: \\n{txt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alRWNr2FXpmB"
   },
   "outputs": [],
   "source": [
    "prompt_tokens = start_packer(tokenizer([\"\"\"Below is an instruction that describes a task, paired with an input that provides further context.\n",
    "Write a response that appropriately completes the request.\\n\\n\n",
    "Instruction:\\nWrite a short story about a fair maiden.\\n\\n\n",
    "Input:\\n no princes\\n\\n\n",
    "Response: \"\"\" ]))\n",
    "prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nh3zIqZ9Zes9"
   },
   "outputs": [],
   "source": [
    "output_tokens = sampler(\n",
    "    next=next,\n",
    "    prompt=prompt_tokens,\n",
    "    index=np.where(np.array(prompt_tokens).flatten()==0)[0][0],\n",
    ")\n",
    "txt = tokenizer.detokenize(output_tokens)\n",
    "print(f\"Top-K search generated text: \\n{txt}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNft_rKUZg_U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "HTGuHfkoIFXh"
   ],
   "gpuType": "L4",
   "name": "colmo-tpu.ipynb",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 6789798,
     "sourceId": 10921230,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31042,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
